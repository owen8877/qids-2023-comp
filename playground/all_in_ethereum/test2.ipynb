{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1169974401.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['log_avg_price'] = np.log(new_df['avg_price'])\n"
     ]
    },
    {
     "data": {
      "text/plain": "           turnoverRatio        pe      pb       pcf  volatility  mean_volume  \\\nday asset                                                                       \n1   0             3.6794   32.3029  4.9425 -578.7700    0.861989    454075.84   \n    1             2.5150   27.2726  5.0552   23.8260    0.804576    176868.36   \n    2             1.2858   41.9279  4.8083  -58.2185    0.351893    361648.66   \n    3             2.2007   13.8032  2.1904   61.0491    0.250697    351809.54   \n    4             0.8627 -433.1736  3.0714  -25.2279    0.270981    338476.86   \n...                  ...       ...     ...       ...         ...          ...   \n998 49            0.3720   41.1121  2.8312   73.1850    0.511882    108894.60   \n    50            0.4780   19.4678  2.5076  -38.0915    0.701618     82457.26   \n    51            1.1501   14.5922  1.4130   19.5205    0.323547    390835.44   \n    52            0.5684   28.9922  5.7855 -582.4621    0.803932     97800.88   \n    53            1.2933   10.6513  1.9956  134.5467    0.542088    252827.46   \n\n           return_0  log_avg_price  previous_return    return  \nday asset                                                      \n1   0     -0.025231       3.200863         0.000000 -0.026877  \n    1     -0.011895       2.783144         0.000000 -0.052674  \n    2     -0.018466       2.203778         0.000000 -0.002691  \n    3      0.002644       2.210959         0.000000 -0.018515  \n    4     -0.023423       1.620262         0.000000 -0.019184  \n...             ...            ...              ...       ...  \n998 49    -0.014577       2.632819        -0.007664 -0.014799  \n    50    -0.013801       2.417723         0.085252  0.012921  \n    51    -0.040754       1.319995        -0.024464 -0.052286  \n    52     0.004224       3.361956         0.005946 -0.015559  \n    53     0.019924       2.284526         0.042851 -0.003662  \n\n[53892 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>turnoverRatio</th>\n      <th>pe</th>\n      <th>pb</th>\n      <th>pcf</th>\n      <th>volatility</th>\n      <th>mean_volume</th>\n      <th>return_0</th>\n      <th>log_avg_price</th>\n      <th>previous_return</th>\n      <th>return</th>\n    </tr>\n    <tr>\n      <th>day</th>\n      <th>asset</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">1</th>\n      <th>0</th>\n      <td>3.6794</td>\n      <td>32.3029</td>\n      <td>4.9425</td>\n      <td>-578.7700</td>\n      <td>0.861989</td>\n      <td>454075.84</td>\n      <td>-0.025231</td>\n      <td>3.200863</td>\n      <td>0.000000</td>\n      <td>-0.026877</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.5150</td>\n      <td>27.2726</td>\n      <td>5.0552</td>\n      <td>23.8260</td>\n      <td>0.804576</td>\n      <td>176868.36</td>\n      <td>-0.011895</td>\n      <td>2.783144</td>\n      <td>0.000000</td>\n      <td>-0.052674</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.2858</td>\n      <td>41.9279</td>\n      <td>4.8083</td>\n      <td>-58.2185</td>\n      <td>0.351893</td>\n      <td>361648.66</td>\n      <td>-0.018466</td>\n      <td>2.203778</td>\n      <td>0.000000</td>\n      <td>-0.002691</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.2007</td>\n      <td>13.8032</td>\n      <td>2.1904</td>\n      <td>61.0491</td>\n      <td>0.250697</td>\n      <td>351809.54</td>\n      <td>0.002644</td>\n      <td>2.210959</td>\n      <td>0.000000</td>\n      <td>-0.018515</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.8627</td>\n      <td>-433.1736</td>\n      <td>3.0714</td>\n      <td>-25.2279</td>\n      <td>0.270981</td>\n      <td>338476.86</td>\n      <td>-0.023423</td>\n      <td>1.620262</td>\n      <td>0.000000</td>\n      <td>-0.019184</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">998</th>\n      <th>49</th>\n      <td>0.3720</td>\n      <td>41.1121</td>\n      <td>2.8312</td>\n      <td>73.1850</td>\n      <td>0.511882</td>\n      <td>108894.60</td>\n      <td>-0.014577</td>\n      <td>2.632819</td>\n      <td>-0.007664</td>\n      <td>-0.014799</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>0.4780</td>\n      <td>19.4678</td>\n      <td>2.5076</td>\n      <td>-38.0915</td>\n      <td>0.701618</td>\n      <td>82457.26</td>\n      <td>-0.013801</td>\n      <td>2.417723</td>\n      <td>0.085252</td>\n      <td>0.012921</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>1.1501</td>\n      <td>14.5922</td>\n      <td>1.4130</td>\n      <td>19.5205</td>\n      <td>0.323547</td>\n      <td>390835.44</td>\n      <td>-0.040754</td>\n      <td>1.319995</td>\n      <td>-0.024464</td>\n      <td>-0.052286</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>0.5684</td>\n      <td>28.9922</td>\n      <td>5.7855</td>\n      <td>-582.4621</td>\n      <td>0.803932</td>\n      <td>97800.88</td>\n      <td>0.004224</td>\n      <td>3.361956</td>\n      <td>0.005946</td>\n      <td>-0.015559</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>1.2933</td>\n      <td>10.6513</td>\n      <td>1.9956</td>\n      <td>134.5467</td>\n      <td>0.542088</td>\n      <td>252827.46</td>\n      <td>0.019924</td>\n      <td>2.284526</td>\n      <td>0.042851</td>\n      <td>-0.003662</td>\n    </tr>\n  </tbody>\n</table>\n<p>53892 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from datatools import extract_market_data\n",
    "from pipeline import Dataset\n",
    "\n",
    "\"\"\"load data\"\"\"\n",
    "dataset = Dataset.load('../../data/parsed')\n",
    "df = pd.concat([dataset.fundamental, extract_market_data(dataset.market)], axis=1).dropna()\n",
    "return_df = dataset.ref_return\n",
    "df_with_return = pd.concat([df, return_df], axis=1).dropna()\n",
    "new_df = df[(df.index.get_level_values('day') != 999) & (df.index.get_level_values('day') != 1000)]\n",
    "new_df['log_avg_price'] = np.log(new_df['avg_price'])\n",
    "df_with_return = df_with_return.drop(columns=['transactionAmount', 'pe_ttm'])\n",
    "df_with_return['log_avg_price'] = np.log(df_with_return['avg_price'])\n",
    "df_with_return = df_with_return.drop(columns = ['avg_price'])\n",
    "df_with_return = df_with_return.drop(columns = ['ps'])\n",
    "df_with_return['previous_return'] = np.zeros(len(df_with_return))\n",
    "df_with_return = df_with_return[[c for c in df_with_return if c not in ['return']] + ['return']]\n",
    "for h in range(54):\n",
    "    df_with_return['previous_return']  = df_with_return.groupby(level = 'asset').shift(3)['return'].fillna(0)\n",
    "df_with_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "           turnoverRatio       pe      pb       pcf  volatility  mean_volume  \\\nday asset                                                                      \n1   0             3.6794  32.3029  4.9425 -578.7700    0.861989    454075.84   \n2   0             3.2535  31.2498  4.7814 -559.9031    2.243321    401517.02   \n3   0             2.4947  23.3887  4.3823  -42.8676    0.522122    307969.24   \n4   0             4.5625  23.9187  4.4816  -43.8390    2.372700    563240.50   \n5   0            18.2257  25.9119  4.8551  -47.4923    4.485819   2249971.94   \n...                  ...      ...     ...       ...         ...          ...   \n994 0             1.6115  64.3030  1.6555  -41.3480    0.333513    330810.62   \n995 0             1.4651  63.6287  1.6382  -40.9144    0.455761    300758.86   \n996 0             1.7045  62.5867  1.6113  -40.2444    0.556307    349902.24   \n997 0             1.5138  63.5674  1.6366  -40.8750    0.577969    310766.68   \n998 0             1.7493  62.8318  1.6177  -40.4020    0.878734    359105.86   \n\n           return_0  log_avg_price  previous_return    return  \nday asset                                                      \n1   0     -0.025231       3.200863         0.000000 -0.026877  \n2   0     -0.032352       3.174435         0.000000  0.028805  \n3   0      0.005658       3.162331         0.000000  0.107928  \n4   0      0.023017       3.172805        -0.026877  0.068998  \n5   0      0.083000       3.263191         0.028805 -0.027238  \n...             ...            ...              ...       ...  \n994 0     -0.008667       2.516958         0.001931 -0.026212  \n995 0     -0.009702       2.516232        -0.018119 -0.000985  \n996 0     -0.016671       2.515440        -0.018285  0.003992  \n997 0      0.015952       2.517939        -0.026212 -0.023552  \n998 0     -0.011772       2.488368        -0.000985 -0.018874  \n\n[998 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>turnoverRatio</th>\n      <th>pe</th>\n      <th>pb</th>\n      <th>pcf</th>\n      <th>volatility</th>\n      <th>mean_volume</th>\n      <th>return_0</th>\n      <th>log_avg_price</th>\n      <th>previous_return</th>\n      <th>return</th>\n    </tr>\n    <tr>\n      <th>day</th>\n      <th>asset</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <th>0</th>\n      <td>3.6794</td>\n      <td>32.3029</td>\n      <td>4.9425</td>\n      <td>-578.7700</td>\n      <td>0.861989</td>\n      <td>454075.84</td>\n      <td>-0.025231</td>\n      <td>3.200863</td>\n      <td>0.000000</td>\n      <td>-0.026877</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <th>0</th>\n      <td>3.2535</td>\n      <td>31.2498</td>\n      <td>4.7814</td>\n      <td>-559.9031</td>\n      <td>2.243321</td>\n      <td>401517.02</td>\n      <td>-0.032352</td>\n      <td>3.174435</td>\n      <td>0.000000</td>\n      <td>0.028805</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <th>0</th>\n      <td>2.4947</td>\n      <td>23.3887</td>\n      <td>4.3823</td>\n      <td>-42.8676</td>\n      <td>0.522122</td>\n      <td>307969.24</td>\n      <td>0.005658</td>\n      <td>3.162331</td>\n      <td>0.000000</td>\n      <td>0.107928</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <th>0</th>\n      <td>4.5625</td>\n      <td>23.9187</td>\n      <td>4.4816</td>\n      <td>-43.8390</td>\n      <td>2.372700</td>\n      <td>563240.50</td>\n      <td>0.023017</td>\n      <td>3.172805</td>\n      <td>-0.026877</td>\n      <td>0.068998</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <th>0</th>\n      <td>18.2257</td>\n      <td>25.9119</td>\n      <td>4.8551</td>\n      <td>-47.4923</td>\n      <td>4.485819</td>\n      <td>2249971.94</td>\n      <td>0.083000</td>\n      <td>3.263191</td>\n      <td>0.028805</td>\n      <td>-0.027238</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>994</th>\n      <th>0</th>\n      <td>1.6115</td>\n      <td>64.3030</td>\n      <td>1.6555</td>\n      <td>-41.3480</td>\n      <td>0.333513</td>\n      <td>330810.62</td>\n      <td>-0.008667</td>\n      <td>2.516958</td>\n      <td>0.001931</td>\n      <td>-0.026212</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <th>0</th>\n      <td>1.4651</td>\n      <td>63.6287</td>\n      <td>1.6382</td>\n      <td>-40.9144</td>\n      <td>0.455761</td>\n      <td>300758.86</td>\n      <td>-0.009702</td>\n      <td>2.516232</td>\n      <td>-0.018119</td>\n      <td>-0.000985</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <th>0</th>\n      <td>1.7045</td>\n      <td>62.5867</td>\n      <td>1.6113</td>\n      <td>-40.2444</td>\n      <td>0.556307</td>\n      <td>349902.24</td>\n      <td>-0.016671</td>\n      <td>2.515440</td>\n      <td>-0.018285</td>\n      <td>0.003992</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <th>0</th>\n      <td>1.5138</td>\n      <td>63.5674</td>\n      <td>1.6366</td>\n      <td>-40.8750</td>\n      <td>0.577969</td>\n      <td>310766.68</td>\n      <td>0.015952</td>\n      <td>2.517939</td>\n      <td>-0.026212</td>\n      <td>-0.023552</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <th>0</th>\n      <td>1.7493</td>\n      <td>62.8318</td>\n      <td>1.6177</td>\n      <td>-40.4020</td>\n      <td>0.878734</td>\n      <td>359105.86</td>\n      <td>-0.011772</td>\n      <td>2.488368</td>\n      <td>-0.000985</td>\n      <td>-0.018874</td>\n    </tr>\n  </tbody>\n</table>\n<p>998 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_return.query(\"asset==0\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['turnoverRatio', 'pe', 'pb', 'pcf', 'volatility', 'mean_volume', 'return_0', 'log_avg_price', 'previous_return', 'return']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"implement a function that use ridge kernel regression\"\"\"\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\"\"\"use lasso linear regression model to predict the return\"\"\"\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "class KernelModel:\n",
    "    def __init__(self, alpha, kernel, gamma):\n",
    "        self.reg = Lasso(alpha = 0)\n",
    "\n",
    "    def fit_predict(self, X, y):\n",
    "        #X = X.copy()\n",
    "        #X['log_avg_price'] = np.log(X['avg_price'])\n",
    "        #X['previous_return'] = X['return_0'] + X['return_1'] + X['return_0'] * X['return_1']\n",
    "        #features = ['turnoverRatio', 'pe', 'pb', 'pcf', 'volatility', 'mean_volume', 'return_0', 'log_avg_price', 'previous_return']\n",
    "        #X = X[features]\n",
    "        self.reg.fit(X, y)\n",
    "        y_pred = self.reg.predict(X)\n",
    "        return y_pred\n",
    "\n",
    "    def predict(self, X):\n",
    "        #X = X.copy()\n",
    "        #X['log_avg_price'] = np.log(X['avg_price'])\n",
    "        #X['previous_return'] = X['return_0'] + X['return_1'] + X['return_0'] * X['return_1']\n",
    "        #features = ['turnoverRatio', 'pe', 'pb', 'pcf', 'volatility', 'mean_volume', 'return_0', 'log_avg_price', 'previous_return']\n",
    "        #X = X[features]\n",
    "        return self.reg.predict(X)\n",
    "\n",
    "\n",
    "features = list(df_with_return.columns)\n",
    "print(features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/996 [00:00<?, ?it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 3, train_r2=1.0000, val_r2=-317.3414, val_cum_r2=-317.3414, val_cum_pearson=-0.3140:   0%|          | 1/996 [00:01<28:45,  1.73s/it]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.747e-04, tolerance: 1.295e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 4, train_r2=0.8804, val_r2=-17504.2300, val_cum_r2=-6055.3386, val_cum_pearson=0.3171:   0%|          | 1/996 [00:01<28:45,  1.73s/it]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.929e-03, tolerance: 2.336e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 5, train_r2=0.7492, val_r2=-203.5772, val_cum_r2=-3875.4571, val_cum_pearson=0.1336:   0%|          | 1/996 [00:01<28:45,  1.73s/it]  C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.395e-03, tolerance: 3.312e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 6, train_r2=0.6138, val_r2=-67.0356, val_cum_r2=-3170.7837, val_cum_pearson=0.0499:   0%|          | 1/996 [00:01<28:45,  1.73s/it] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.746e-03, tolerance: 4.407e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 7, train_r2=0.6030, val_r2=-13.0515, val_cum_r2=-2733.9760, val_cum_pearson=0.0080:   0%|          | 1/996 [00:01<28:45,  1.73s/it]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e-02, tolerance: 5.278e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 8, train_r2=0.5042, val_r2=-4.0180, val_cum_r2=-2466.2451, val_cum_pearson=0.0127:   0%|          | 1/996 [00:01<28:45,  1.73s/it] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e-02, tolerance: 6.090e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 9, train_r2=0.3000, val_r2=-3.8222, val_cum_r2=-2332.8212, val_cum_pearson=0.0070:   0%|          | 1/996 [00:01<28:45,  1.73s/it]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.354e-02, tolerance: 6.566e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 10, train_r2=0.2829, val_r2=-24.1841, val_cum_r2=-2302.5286, val_cum_pearson=0.0012:   0%|          | 1/996 [00:01<28:45,  1.73s/it]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.694e-02, tolerance: 6.898e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 11, train_r2=0.2188, val_r2=-3.4081, val_cum_r2=-2218.7237, val_cum_pearson=0.0112:   0%|          | 1/996 [00:01<28:45,  1.73s/it] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.871e-02, tolerance: 7.026e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 12, train_r2=0.1827, val_r2=-22.5814, val_cum_r2=-1730.0259, val_cum_pearson=-0.0145:   0%|          | 1/996 [00:01<28:45,  1.73s/it]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.952e-02, tolerance: 7.148e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 13, train_r2=0.1742, val_r2=-11.1921, val_cum_r2=-1630.7434, val_cum_pearson=-0.0241:   0%|          | 1/996 [00:01<28:45,  1.73s/it]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.867e-02, tolerance: 8.926e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 14, train_r2=0.1336, val_r2=-1.1132, val_cum_r2=-1234.4466, val_cum_pearson=0.0003:   0%|          | 1/996 [00:01<28:45,  1.73s/it]  C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.068e-02, tolerance: 9.485e-06 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 15, train_r2=0.1423, val_r2=-42.2986, val_cum_r2=-1193.0087, val_cum_pearson=0.0066:   0%|          | 1/996 [00:01<28:45,  1.73s/it]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.354e-02, tolerance: 1.156e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 16, train_r2=0.2470, val_r2=-17.3935, val_cum_r2=-1178.2234, val_cum_pearson=0.0030:   0%|          | 1/996 [00:01<28:45,  1.73s/it]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.644e-02, tolerance: 1.181e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 17, train_r2=0.2138, val_r2=-22.8106, val_cum_r2=-1175.5747, val_cum_pearson=0.0037:   2%|▏         | 15/996 [00:01<01:28, 11.11it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.705e-02, tolerance: 1.200e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 18, train_r2=0.2157, val_r2=-3.0132, val_cum_r2=-1158.7139, val_cum_pearson=0.0067:   2%|▏         | 15/996 [00:01<01:28, 11.11it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.835e-02, tolerance: 1.201e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 19, train_r2=0.1951, val_r2=-0.9975, val_cum_r2=-1128.2183, val_cum_pearson=0.0030:   2%|▏         | 15/996 [00:01<01:28, 11.11it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.881e-02, tolerance: 1.212e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 20, train_r2=0.1948, val_r2=-21.9382, val_cum_r2=-1078.4420, val_cum_pearson=-0.0030:   2%|▏         | 15/996 [00:01<01:28, 11.11it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.962e-02, tolerance: 1.246e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 21, train_r2=0.2035, val_r2=-8.5076, val_cum_r2=-1042.6537, val_cum_pearson=-0.0074:   2%|▏         | 15/996 [00:01<01:28, 11.11it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.354e-02, tolerance: 1.303e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 22, train_r2=0.1785, val_r2=-5.4617, val_cum_r2=-1015.6484, val_cum_pearson=-0.0108:   2%|▏         | 15/996 [00:01<01:28, 11.11it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.615e-02, tolerance: 1.349e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 23, train_r2=0.1673, val_r2=-1.8080, val_cum_r2=-1011.5793, val_cum_pearson=-0.0109:   2%|▏         | 15/996 [00:01<01:28, 11.11it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.831e-02, tolerance: 1.385e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 24, train_r2=0.1580, val_r2=0.1749, val_cum_r2=-1008.0321, val_cum_pearson=-0.0102:   2%|▏         | 15/996 [00:01<01:28, 11.11it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.865e-02, tolerance: 1.391e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 25, train_r2=0.1564, val_r2=-9.0654, val_cum_r2=-990.1252, val_cum_pearson=-0.0126:   2%|▏         | 15/996 [00:01<01:28, 11.11it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.876e-02, tolerance: 1.394e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 26, train_r2=0.1568, val_r2=-0.9401, val_cum_r2=-933.2864, val_cum_pearson=-0.0154:   2%|▏         | 15/996 [00:01<01:28, 11.11it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.936e-02, tolerance: 1.421e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 27, train_r2=0.1643, val_r2=-2.4650, val_cum_r2=-924.5650, val_cum_pearson=-0.0166:   2%|▏         | 15/996 [00:01<01:28, 11.11it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.238e-02, tolerance: 1.501e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 28, train_r2=0.1687, val_r2=0.5105, val_cum_r2=-875.2398, val_cum_pearson=-0.0138:   2%|▏         | 15/996 [00:01<01:28, 11.11it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.334e-02, tolerance: 1.516e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 29, train_r2=0.1642, val_r2=-0.9174, val_cum_r2=-851.8725, val_cum_pearson=-0.0119:   2%|▏         | 15/996 [00:01<01:28, 11.11it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.482e-02, tolerance: 1.585e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 30, train_r2=0.1820, val_r2=-5.6235, val_cum_r2=-844.3046, val_cum_pearson=-0.0110:   3%|▎         | 28/996 [00:01<00:42, 22.64it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.662e-02, tolerance: 1.619e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 31, train_r2=0.1768, val_r2=-14.5165, val_cum_r2=-835.7652, val_cum_pearson=-0.0098:   3%|▎         | 28/996 [00:01<00:42, 22.64it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.834e-02, tolerance: 1.629e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 32, train_r2=0.1609, val_r2=-6.9122, val_cum_r2=-821.8362, val_cum_pearson=-0.0081:   3%|▎         | 28/996 [00:01<00:42, 22.64it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.019e-02, tolerance: 1.641e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 33, train_r2=0.1443, val_r2=-1.5912, val_cum_r2=-788.7735, val_cum_pearson=-0.0060:   3%|▎         | 28/996 [00:01<00:42, 22.64it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.197e-02, tolerance: 1.661e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 34, train_r2=0.1335, val_r2=-0.0194, val_cum_r2=-756.8675, val_cum_pearson=-0.0051:   3%|▎         | 28/996 [00:01<00:42, 22.64it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.566e-02, tolerance: 1.718e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 35, train_r2=0.1191, val_r2=-1.1009, val_cum_r2=-747.0617, val_cum_pearson=-0.0038:   3%|▎         | 28/996 [00:01<00:42, 22.64it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.836e-02, tolerance: 1.780e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 36, train_r2=0.1196, val_r2=-1.8221, val_cum_r2=-727.6017, val_cum_pearson=-0.0020:   3%|▎         | 28/996 [00:02<00:42, 22.64it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.934e-02, tolerance: 1.798e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 37, train_r2=0.1177, val_r2=-1.1090, val_cum_r2=-715.0085, val_cum_pearson=-0.0015:   3%|▎         | 28/996 [00:02<00:42, 22.64it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.144e-02, tolerance: 1.838e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 38, train_r2=0.1136, val_r2=-0.7762, val_cum_r2=-706.0753, val_cum_pearson=-0.0016:   3%|▎         | 28/996 [00:02<00:42, 22.64it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.383e-02, tolerance: 1.865e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 39, train_r2=0.1012, val_r2=-3.0318, val_cum_r2=-694.4076, val_cum_pearson=-0.0004:   3%|▎         | 28/996 [00:02<00:42, 22.64it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.548e-02, tolerance: 1.886e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 40, train_r2=0.0937, val_r2=-3.1332, val_cum_r2=-682.4919, val_cum_pearson=0.0011:   3%|▎         | 28/996 [00:02<00:42, 22.64it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.748e-02, tolerance: 1.912e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 41, train_r2=0.0851, val_r2=-1.1351, val_cum_r2=-669.2178, val_cum_pearson=-0.0002:   4%|▍         | 39/996 [00:02<00:28, 33.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.873e-02, tolerance: 1.939e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 42, train_r2=0.0850, val_r2=-0.5994, val_cum_r2=-667.6298, val_cum_pearson=-0.0001:   4%|▍         | 39/996 [00:02<00:28, 33.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.001e-02, tolerance: 1.977e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 43, train_r2=0.0893, val_r2=-1.2713, val_cum_r2=-658.2631, val_cum_pearson=0.0011:   4%|▍         | 39/996 [00:02<00:28, 33.19it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.032e-02, tolerance: 1.981e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 44, train_r2=0.0881, val_r2=-0.1952, val_cum_r2=-656.6986, val_cum_pearson=0.0008:   4%|▍         | 39/996 [00:02<00:28, 33.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.126e-02, tolerance: 2.004e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 45, train_r2=0.0893, val_r2=-1.6506, val_cum_r2=-654.9815, val_cum_pearson=0.0010:   4%|▍         | 39/996 [00:02<00:28, 33.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.142e-02, tolerance: 2.009e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 46, train_r2=0.0900, val_r2=-0.6131, val_cum_r2=-614.6619, val_cum_pearson=0.0025:   4%|▍         | 39/996 [00:02<00:28, 33.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.195e-02, tolerance: 2.014e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 47, train_r2=0.0868, val_r2=-1.0685, val_cum_r2=-539.9892, val_cum_pearson=0.0047:   4%|▍         | 39/996 [00:02<00:28, 33.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.808e-02, tolerance: 2.130e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 48, train_r2=0.0789, val_r2=-4.7182, val_cum_r2=-527.6774, val_cum_pearson=0.0057:   4%|▍         | 39/996 [00:02<00:28, 33.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e-01, tolerance: 2.392e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 49, train_r2=0.0606, val_r2=-0.3592, val_cum_r2=-522.5646, val_cum_pearson=0.0064:   4%|▍         | 39/996 [00:02<00:28, 33.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e-01, tolerance: 2.441e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 50, train_r2=0.0486, val_r2=-1.6359, val_cum_r2=-512.6524, val_cum_pearson=0.0077:   4%|▍         | 39/996 [00:02<00:28, 33.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e-01, tolerance: 2.462e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 51, train_r2=0.0505, val_r2=-0.2779, val_cum_r2=-500.7221, val_cum_pearson=0.0081:   4%|▍         | 39/996 [00:02<00:28, 33.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e-01, tolerance: 2.504e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 52, train_r2=0.0550, val_r2=-4.4548, val_cum_r2=-500.1724, val_cum_pearson=0.0083:   5%|▌         | 50/996 [00:02<00:21, 43.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.211e-01, tolerance: 2.558e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 53, train_r2=0.0531, val_r2=-0.1784, val_cum_r2=-474.6684, val_cum_pearson=0.0093:   5%|▌         | 50/996 [00:02<00:21, 43.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.215e-01, tolerance: 2.560e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 54, train_r2=0.0509, val_r2=-0.2286, val_cum_r2=-441.0523, val_cum_pearson=0.0097:   5%|▌         | 50/996 [00:02<00:21, 43.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e-01, tolerance: 2.686e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 55, train_r2=0.0544, val_r2=-0.3528, val_cum_r2=-436.8437, val_cum_pearson=0.0095:   5%|▌         | 50/996 [00:02<00:21, 43.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e-01, tolerance: 2.876e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 56, train_r2=0.0500, val_r2=-0.3247, val_cum_r2=-432.1578, val_cum_pearson=0.0093:   5%|▌         | 50/996 [00:02<00:21, 43.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e-01, tolerance: 2.902e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 57, train_r2=0.0485, val_r2=0.2665, val_cum_r2=-429.0271, val_cum_pearson=0.0097:   5%|▌         | 50/996 [00:02<00:21, 43.96it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.398e-01, tolerance: 2.932e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 58, train_r2=0.0465, val_r2=0.0275, val_cum_r2=-425.3769, val_cum_pearson=0.0095:   5%|▌         | 50/996 [00:02<00:21, 43.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.404e-01, tolerance: 2.952e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 59, train_r2=0.0489, val_r2=-0.3164, val_cum_r2=-408.0643, val_cum_pearson=0.0098:   5%|▌         | 50/996 [00:02<00:21, 43.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.415e-01, tolerance: 2.976e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 60, train_r2=0.0493, val_r2=-2.8626, val_cum_r2=-392.1469, val_cum_pearson=0.0104:   5%|▌         | 50/996 [00:02<00:21, 43.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.482e-01, tolerance: 3.093e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 61, train_r2=0.0420, val_r2=-1.4588, val_cum_r2=-388.3028, val_cum_pearson=0.0109:   5%|▌         | 50/996 [00:02<00:21, 43.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.562e-01, tolerance: 3.210e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 62, train_r2=0.0268, val_r2=-0.2646, val_cum_r2=-366.4144, val_cum_pearson=0.0118:   5%|▌         | 50/996 [00:02<00:21, 43.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.576e-01, tolerance: 3.239e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 63, train_r2=0.0269, val_r2=-0.3903, val_cum_r2=-351.5105, val_cum_pearson=0.0126:   6%|▌         | 61/996 [00:02<00:17, 53.03it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.659e-01, tolerance: 3.420e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 64, train_r2=0.0301, val_r2=-0.5527, val_cum_r2=-343.3360, val_cum_pearson=0.0120:   6%|▌         | 61/996 [00:02<00:17, 53.03it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.719e-01, tolerance: 3.556e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 65, train_r2=0.0333, val_r2=-0.3493, val_cum_r2=-336.9660, val_cum_pearson=0.0128:   6%|▌         | 61/996 [00:02<00:17, 53.03it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.773e-01, tolerance: 3.637e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 66, train_r2=0.0251, val_r2=-2.0211, val_cum_r2=-317.5703, val_cum_pearson=0.0142:   6%|▌         | 61/996 [00:02<00:17, 53.03it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.794e-01, tolerance: 3.701e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 67, train_r2=0.0309, val_r2=-1.1123, val_cum_r2=-292.0169, val_cum_pearson=0.0150:   6%|▌         | 61/996 [00:02<00:17, 53.03it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.881e-01, tolerance: 3.914e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 68, train_r2=0.0387, val_r2=-3.0006, val_cum_r2=-284.6105, val_cum_pearson=0.0134:   6%|▌         | 61/996 [00:02<00:17, 53.03it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.048e-01, tolerance: 4.239e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 69, train_r2=0.0337, val_r2=-1.2567, val_cum_r2=-277.1920, val_cum_pearson=0.0122:   6%|▌         | 61/996 [00:02<00:17, 53.03it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.122e-01, tolerance: 4.347e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 70, train_r2=0.0238, val_r2=-0.2156, val_cum_r2=-274.4281, val_cum_pearson=0.0125:   6%|▌         | 61/996 [00:02<00:17, 53.03it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e-01, tolerance: 4.461e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 71, train_r2=0.0215, val_r2=-4.7648, val_cum_r2=-255.2362, val_cum_pearson=0.0099:   6%|▌         | 61/996 [00:02<00:17, 53.03it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e-01, tolerance: 4.504e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 72, train_r2=0.0226, val_r2=-7.8798, val_cum_r2=-254.7980, val_cum_pearson=0.0096:   6%|▌         | 61/996 [00:02<00:17, 53.03it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.353e-01, tolerance: 4.834e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 73, train_r2=0.0265, val_r2=-13.3798, val_cum_r2=-245.6778, val_cum_pearson=0.0112:   7%|▋         | 71/996 [00:02<00:15, 60.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.360e-01, tolerance: 4.843e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 74, train_r2=0.0254, val_r2=-3.6881, val_cum_r2=-244.9202, val_cum_pearson=0.0113:   7%|▋         | 71/996 [00:02<00:15, 60.90it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.414e-01, tolerance: 5.013e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 75, train_r2=0.0368, val_r2=-0.6741, val_cum_r2=-241.6667, val_cum_pearson=0.0107:   7%|▋         | 71/996 [00:02<00:15, 60.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.434e-01, tolerance: 5.028e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 76, train_r2=0.0316, val_r2=-1.7650, val_cum_r2=-240.8999, val_cum_pearson=0.0104:   7%|▋         | 71/996 [00:02<00:15, 60.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.467e-01, tolerance: 5.095e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 77, train_r2=0.0315, val_r2=-0.3303, val_cum_r2=-232.6580, val_cum_pearson=0.0096:   7%|▋         | 71/996 [00:02<00:15, 60.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e-01, tolerance: 5.111e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 78, train_r2=0.0313, val_r2=-0.2095, val_cum_r2=-225.8936, val_cum_pearson=0.0089:   7%|▋         | 71/996 [00:02<00:15, 60.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.558e-01, tolerance: 5.288e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 79, train_r2=0.0323, val_r2=-1.9850, val_cum_r2=-224.3172, val_cum_pearson=0.0085:   7%|▋         | 71/996 [00:02<00:15, 60.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.632e-01, tolerance: 5.442e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 80, train_r2=0.0329, val_r2=-1.8536, val_cum_r2=-221.7336, val_cum_pearson=0.0079:   7%|▋         | 71/996 [00:02<00:15, 60.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.667e-01, tolerance: 5.480e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 81, train_r2=0.0267, val_r2=-8.6074, val_cum_r2=-217.1665, val_cum_pearson=0.0068:   7%|▋         | 71/996 [00:02<00:15, 60.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.693e-01, tolerance: 5.544e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 82, train_r2=0.0284, val_r2=-10.5898, val_cum_r2=-207.8804, val_cum_pearson=0.0056:   7%|▋         | 71/996 [00:02<00:15, 60.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.751e-01, tolerance: 5.659e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 83, train_r2=0.0276, val_r2=-9.8716, val_cum_r2=-205.4901, val_cum_pearson=0.0049:   8%|▊         | 81/996 [00:02<00:14, 64.13it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.853e-01, tolerance: 5.907e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 84, train_r2=0.0340, val_r2=-1.7737, val_cum_r2=-203.7053, val_cum_pearson=0.0052:   8%|▊         | 81/996 [00:02<00:14, 64.13it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.889e-01, tolerance: 5.976e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 85, train_r2=0.0331, val_r2=-5.0223, val_cum_r2=-196.2151, val_cum_pearson=0.0058:   8%|▊         | 81/996 [00:02<00:14, 64.13it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.923e-01, tolerance: 6.026e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 86, train_r2=0.0298, val_r2=-4.5609, val_cum_r2=-194.9603, val_cum_pearson=0.0061:   8%|▊         | 81/996 [00:02<00:14, 64.13it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.048e-01, tolerance: 6.246e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 87, train_r2=0.0241, val_r2=-0.0450, val_cum_r2=-194.5986, val_cum_pearson=0.0060:   8%|▊         | 81/996 [00:02<00:14, 64.13it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.077e-01, tolerance: 6.284e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 88, train_r2=0.0208, val_r2=-1.1768, val_cum_r2=-193.6815, val_cum_pearson=0.0057:   8%|▊         | 81/996 [00:02<00:14, 64.13it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.082e-01, tolerance: 6.296e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 89, train_r2=0.0209, val_r2=-14.1099, val_cum_r2=-190.2558, val_cum_pearson=0.0050:   8%|▊         | 81/996 [00:02<00:14, 64.13it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e-01, tolerance: 6.326e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 90, train_r2=0.0221, val_r2=-3.2469, val_cum_r2=-188.9270, val_cum_pearson=0.0046:   8%|▊         | 81/996 [00:02<00:14, 64.13it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.137e-01, tolerance: 6.438e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 91, train_r2=0.0255, val_r2=-4.5502, val_cum_r2=-187.7592, val_cum_pearson=0.0049:   8%|▊         | 81/996 [00:02<00:14, 64.13it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.158e-01, tolerance: 6.484e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 92, train_r2=0.0260, val_r2=-12.1476, val_cum_r2=-186.5836, val_cum_pearson=0.0053:   9%|▉         | 90/996 [00:02<00:13, 67.92it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.180e-01, tolerance: 6.522e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 93, train_r2=0.0248, val_r2=-5.6681, val_cum_r2=-183.7419, val_cum_pearson=0.0056:   9%|▉         | 90/996 [00:02<00:13, 67.92it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.206e-01, tolerance: 6.561e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 94, train_r2=0.0225, val_r2=-29.3457, val_cum_r2=-181.1499, val_cum_pearson=0.0061:   9%|▉         | 90/996 [00:02<00:13, 67.92it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.270e-01, tolerance: 6.658e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 95, train_r2=0.0177, val_r2=-3.9614, val_cum_r2=-176.1332, val_cum_pearson=0.0067:   9%|▉         | 90/996 [00:02<00:13, 67.92it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.324e-01, tolerance: 6.749e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 96, train_r2=0.0149, val_r2=-3.0966, val_cum_r2=-171.2256, val_cum_pearson=0.0074:   9%|▉         | 90/996 [00:02<00:13, 67.92it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.429e-01, tolerance: 6.934e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 97, train_r2=0.0110, val_r2=-5.7820, val_cum_r2=-169.0108, val_cum_pearson=0.0079:   9%|▉         | 90/996 [00:02<00:13, 67.92it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.523e-01, tolerance: 7.125e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 98, train_r2=0.0112, val_r2=-0.2873, val_cum_r2=-165.8149, val_cum_pearson=0.0074:   9%|▉         | 90/996 [00:02<00:13, 67.92it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.564e-01, tolerance: 7.215e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 99, train_r2=0.0120, val_r2=-0.0691, val_cum_r2=-160.5775, val_cum_pearson=0.0072:   9%|▉         | 90/996 [00:02<00:13, 67.92it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.644e-01, tolerance: 7.352e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 100, train_r2=0.0086, val_r2=-7.0668, val_cum_r2=-150.2519, val_cum_pearson=0.0087:   9%|▉         | 90/996 [00:02<00:13, 67.92it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.758e-01, tolerance: 7.586e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 101, train_r2=0.0094, val_r2=-4.3577, val_cum_r2=-146.6973, val_cum_pearson=0.0095:  10%|▉         | 99/996 [00:02<00:12, 69.05it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.945e-01, tolerance: 8.092e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 102, train_r2=0.0249, val_r2=-0.9396, val_cum_r2=-146.1966, val_cum_pearson=0.0093:  10%|▉         | 99/996 [00:02<00:12, 69.05it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.020e-01, tolerance: 8.282e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 103, train_r2=0.0291, val_r2=-1.9891, val_cum_r2=-144.1732, val_cum_pearson=0.0086:  10%|▉         | 99/996 [00:02<00:12, 69.05it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.039e-01, tolerance: 8.310e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 104, train_r2=0.0279, val_r2=-2.4675, val_cum_r2=-144.0576, val_cum_pearson=0.0085:  10%|▉         | 99/996 [00:02<00:12, 69.05it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.107e-01, tolerance: 8.426e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 105, train_r2=0.0251, val_r2=-0.1932, val_cum_r2=-143.1279, val_cum_pearson=0.0086:  10%|▉         | 99/996 [00:02<00:12, 69.05it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.115e-01, tolerance: 8.433e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 106, train_r2=0.0240, val_r2=-1.5179, val_cum_r2=-142.7335, val_cum_pearson=0.0084:  10%|▉         | 99/996 [00:02<00:12, 69.05it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.142e-01, tolerance: 8.486e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 107, train_r2=0.0239, val_r2=-0.1123, val_cum_r2=-141.5715, val_cum_pearson=0.0083:  10%|▉         | 99/996 [00:02<00:12, 69.05it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.161e-01, tolerance: 8.510e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 108, train_r2=0.0220, val_r2=0.2552, val_cum_r2=-140.9732, val_cum_pearson=0.0083:  10%|▉         | 99/996 [00:02<00:12, 69.05it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.195e-01, tolerance: 8.579e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 109, train_r2=0.0220, val_r2=-0.2158, val_cum_r2=-140.1192, val_cum_pearson=0.0085:  10%|▉         | 99/996 [00:02<00:12, 69.05it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.208e-01, tolerance: 8.614e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 110, train_r2=0.0231, val_r2=-1.2254, val_cum_r2=-139.7697, val_cum_pearson=0.0086:  11%|█         | 108/996 [00:02<00:12, 69.85it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.231e-01, tolerance: 8.665e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 111, train_r2=0.0235, val_r2=-5.6049, val_cum_r2=-135.8410, val_cum_pearson=0.0077:  11%|█         | 108/996 [00:02<00:12, 69.85it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.245e-01, tolerance: 8.686e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 112, train_r2=0.0226, val_r2=-12.6958, val_cum_r2=-134.0733, val_cum_pearson=0.0069:  11%|█         | 108/996 [00:02<00:12, 69.85it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.372e-01, tolerance: 8.935e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 113, train_r2=0.0214, val_r2=-3.1334, val_cum_r2=-133.4699, val_cum_pearson=0.0065:  11%|█         | 108/996 [00:02<00:12, 69.85it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.440e-01, tolerance: 9.052e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 114, train_r2=0.0190, val_r2=-37.9287, val_cum_r2=-126.1828, val_cum_pearson=0.0051:  11%|█         | 108/996 [00:02<00:12, 69.85it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.471e-01, tolerance: 9.094e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 115, train_r2=0.0166, val_r2=-1.0066, val_cum_r2=-124.7356, val_cum_pearson=0.0047:  11%|█         | 108/996 [00:02<00:12, 69.85it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.720e-01, tolerance: 9.613e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 116, train_r2=0.0179, val_r2=-2.3502, val_cum_r2=-122.0510, val_cum_pearson=0.0055:  11%|█         | 108/996 [00:02<00:12, 69.85it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.770e-01, tolerance: 9.724e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 117, train_r2=0.0189, val_r2=-2.6008, val_cum_r2=-121.2585, val_cum_pearson=0.0053:  11%|█         | 108/996 [00:02<00:12, 69.85it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.853e-01, tolerance: 9.931e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 118, train_r2=0.0228, val_r2=-100.7072, val_cum_r2=-109.3529, val_cum_pearson=0.0041:  12%|█▏        | 116/996 [00:03<00:12, 70.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.873e-01, tolerance: 9.996e-05 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 119, train_r2=0.0250, val_r2=-15.2180, val_cum_r2=-99.7748, val_cum_pearson=0.0023:  12%|█▏        | 116/996 [00:03<00:12, 70.66it/s]  C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.338e-01, tolerance: 1.107e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 120, train_r2=0.0355, val_r2=0.2579, val_cum_r2=-99.1260, val_cum_pearson=0.0028:  12%|█▏        | 116/996 [00:03<00:12, 70.66it/s]  C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.883e-01, tolerance: 1.212e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 121, train_r2=0.0294, val_r2=-0.3777, val_cum_r2=-98.8507, val_cum_pearson=0.0027:  12%|█▏        | 116/996 [00:03<00:12, 70.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.904e-01, tolerance: 1.220e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 122, train_r2=0.0320, val_r2=-9.4813, val_cum_r2=-90.5507, val_cum_pearson=0.0015:  12%|█▏        | 116/996 [00:03<00:12, 70.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.927e-01, tolerance: 1.223e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 123, train_r2=0.0310, val_r2=-8.9786, val_cum_r2=-82.5000, val_cum_pearson=-0.0002:  12%|█▏        | 116/996 [00:03<00:12, 70.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.310e-01, tolerance: 1.334e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 124, train_r2=0.0542, val_r2=-2.2736, val_cum_r2=-80.5751, val_cum_pearson=-0.0009:  12%|█▏        | 116/996 [00:03<00:12, 70.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.949e-01, tolerance: 1.464e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 125, train_r2=0.0504, val_r2=-0.6596, val_cum_r2=-78.5543, val_cum_pearson=-0.0010:  12%|█▏        | 116/996 [00:03<00:12, 70.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.099e-01, tolerance: 1.498e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 126, train_r2=0.0525, val_r2=-8.8620, val_cum_r2=-72.7628, val_cum_pearson=-0.0003:  12%|█▏        | 124/996 [00:03<00:12, 67.41it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.226e-01, tolerance: 1.537e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 127, train_r2=0.0596, val_r2=-0.2507, val_cum_r2=-72.3454, val_cum_pearson=-0.0002:  12%|█▏        | 124/996 [00:03<00:12, 67.41it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.567e-01, tolerance: 1.658e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 128, train_r2=0.0870, val_r2=-943323.7197, val_cum_r2=-63.9461, val_cum_pearson=-0.0001:  12%|█▏        | 124/996 [00:03<00:12, 67.41it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.633e-01, tolerance: 1.667e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 129, train_r2=0.0842, val_r2=-69.2084, val_cum_r2=-58.2956, val_cum_pearson=-0.0014:  12%|█▏        | 124/996 [00:03<00:12, 67.41it/s]    C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.676e-01, tolerance: 1.883e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 130, train_r2=0.0784, val_r2=-2.4388, val_cum_r2=-57.5205, val_cum_pearson=-0.0012:  12%|█▏        | 124/996 [00:03<00:12, 67.41it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.784e-01, tolerance: 2.064e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 131, train_r2=0.0519, val_r2=-80.7733, val_cum_r2=-56.1639, val_cum_pearson=-0.0018:  12%|█▏        | 124/996 [00:03<00:12, 67.41it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.892e-01, tolerance: 2.091e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 132, train_r2=0.0541, val_r2=-5.7100, val_cum_r2=-55.7822, val_cum_pearson=-0.0021:  12%|█▏        | 124/996 [00:03<00:12, 67.41it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.013e+00, tolerance: 2.142e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 133, train_r2=0.0538, val_r2=-10.7629, val_cum_r2=-54.6645, val_cum_pearson=-0.0021:  12%|█▏        | 124/996 [00:03<00:12, 67.41it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+00, tolerance: 2.157e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 134, train_r2=0.0559, val_r2=-3.0021, val_cum_r2=-54.4073, val_cum_pearson=-0.0020:  13%|█▎        | 132/996 [00:03<00:12, 67.37it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+00, tolerance: 2.200e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 135, train_r2=0.0479, val_r2=-1.3023, val_cum_r2=-54.3441, val_cum_pearson=-0.0021:  13%|█▎        | 132/996 [00:03<00:12, 67.37it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e+00, tolerance: 2.211e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 136, train_r2=0.0468, val_r2=-0.2765, val_cum_r2=-54.2710, val_cum_pearson=-0.0020:  13%|█▎        | 132/996 [00:03<00:12, 67.37it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.055e+00, tolerance: 2.213e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 137, train_r2=0.0467, val_r2=-2.1644, val_cum_r2=-54.0477, val_cum_pearson=-0.0018:  13%|█▎        | 132/996 [00:03<00:12, 67.37it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+00, tolerance: 2.216e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 138, train_r2=0.0463, val_r2=-2.7755, val_cum_r2=-54.0226, val_cum_pearson=-0.0018:  13%|█▎        | 132/996 [00:03<00:12, 67.37it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+00, tolerance: 2.225e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 139, train_r2=0.0463, val_r2=-1983.8747, val_cum_r2=-52.4043, val_cum_pearson=-0.0024:  13%|█▎        | 132/996 [00:03<00:12, 67.37it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+00, tolerance: 2.226e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 140, train_r2=0.0457, val_r2=-22.6396, val_cum_r2=-51.3113, val_cum_pearson=-0.0029:  13%|█▎        | 132/996 [00:03<00:12, 67.37it/s]  C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.096e+00, tolerance: 2.295e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 141, train_r2=0.0445, val_r2=-9.6960, val_cum_r2=-50.9798, val_cum_pearson=-0.0029:  13%|█▎        | 132/996 [00:03<00:12, 67.37it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e+00, tolerance: 2.344e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 142, train_r2=0.0422, val_r2=-0.5198, val_cum_r2=-50.8907, val_cum_pearson=-0.0028:  14%|█▍        | 140/996 [00:03<00:12, 66.26it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e+00, tolerance: 2.359e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 143, train_r2=0.0386, val_r2=-0.6903, val_cum_r2=-50.7758, val_cum_pearson=-0.0029:  14%|█▍        | 140/996 [00:03<00:12, 66.26it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+00, tolerance: 2.363e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 144, train_r2=0.0383, val_r2=-0.4613, val_cum_r2=-50.4160, val_cum_pearson=-0.0028:  14%|█▍        | 140/996 [00:03<00:12, 66.26it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+00, tolerance: 2.368e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 145, train_r2=0.0382, val_r2=-7.6617, val_cum_r2=-49.9197, val_cum_pearson=-0.0026:  14%|█▍        | 140/996 [00:03<00:12, 66.26it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+00, tolerance: 2.385e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 146, train_r2=0.0373, val_r2=-0.1899, val_cum_r2=-49.7294, val_cum_pearson=-0.0024:  14%|█▍        | 140/996 [00:03<00:12, 66.26it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.161e+00, tolerance: 2.408e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 147, train_r2=0.0361, val_r2=-0.9059, val_cum_r2=-49.5580, val_cum_pearson=-0.0024:  14%|█▍        | 140/996 [00:03<00:12, 66.26it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+00, tolerance: 2.417e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 148, train_r2=0.0364, val_r2=0.2603, val_cum_r2=-49.5287, val_cum_pearson=-0.0024:  14%|█▍        | 140/996 [00:03<00:12, 66.26it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+00, tolerance: 2.426e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 149, train_r2=0.0379, val_r2=-14.2436, val_cum_r2=-49.1551, val_cum_pearson=-0.0022:  15%|█▍        | 147/996 [00:03<00:13, 63.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.167e+00, tolerance: 2.427e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 150, train_r2=0.0381, val_r2=-3.9889, val_cum_r2=-49.0285, val_cum_pearson=-0.0020:  15%|█▍        | 147/996 [00:03<00:13, 63.19it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.177e+00, tolerance: 2.445e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 151, train_r2=0.0371, val_r2=-5.2787, val_cum_r2=-48.8682, val_cum_pearson=-0.0021:  15%|█▍        | 147/996 [00:03<00:13, 63.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.180e+00, tolerance: 2.451e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 152, train_r2=0.0374, val_r2=-0.9626, val_cum_r2=-48.8053, val_cum_pearson=-0.0022:  15%|█▍        | 147/996 [00:03<00:13, 63.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+00, tolerance: 2.459e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 153, train_r2=0.0382, val_r2=-0.4434, val_cum_r2=-48.7360, val_cum_pearson=-0.0021:  15%|█▍        | 147/996 [00:03<00:13, 63.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.184e+00, tolerance: 2.463e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 154, train_r2=0.0383, val_r2=-0.2875, val_cum_r2=-48.6822, val_cum_pearson=-0.0021:  15%|█▍        | 147/996 [00:03<00:13, 63.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.186e+00, tolerance: 2.466e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 155, train_r2=0.0381, val_r2=-20.6015, val_cum_r2=-48.1922, val_cum_pearson=-0.0024:  15%|█▍        | 147/996 [00:03<00:13, 63.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e+00, tolerance: 2.469e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 156, train_r2=0.0381, val_r2=-1.6684, val_cum_r2=-48.0718, val_cum_pearson=-0.0025:  15%|█▌        | 154/996 [00:03<00:13, 61.04it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.201e+00, tolerance: 2.494e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 157, train_r2=0.0368, val_r2=-1.8723, val_cum_r2=-47.9832, val_cum_pearson=-0.0024:  15%|█▌        | 154/996 [00:03<00:13, 61.04it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.203e+00, tolerance: 2.500e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 158, train_r2=0.0373, val_r2=-20.3146, val_cum_r2=-47.2120, val_cum_pearson=-0.0025:  15%|█▌        | 154/996 [00:03<00:13, 61.04it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.206e+00, tolerance: 2.505e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 159, train_r2=0.0371, val_r2=-998.0024, val_cum_r2=-45.0073, val_cum_pearson=-0.0034:  15%|█▌        | 154/996 [00:03<00:13, 61.04it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.223e+00, tolerance: 2.545e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 160, train_r2=0.0392, val_r2=-277.6684, val_cum_r2=-42.3400, val_cum_pearson=-0.0041:  15%|█▌        | 154/996 [00:03<00:13, 61.04it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.291e+00, tolerance: 2.670e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 161, train_r2=0.0332, val_r2=-5.3660, val_cum_r2=-41.7051, val_cum_pearson=-0.0046:  15%|█▌        | 154/996 [00:03<00:13, 61.04it/s]  C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+00, tolerance: 2.838e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 162, train_r2=0.0318, val_r2=-4.6701, val_cum_r2=-41.2033, val_cum_pearson=-0.0043:  15%|█▌        | 154/996 [00:03<00:13, 61.04it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.397e+00, tolerance: 2.881e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 163, train_r2=0.0303, val_r2=-22.3466, val_cum_r2=-40.2029, val_cum_pearson=-0.0039:  16%|█▌        | 161/996 [00:03<00:14, 59.38it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e+00, tolerance: 2.916e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 164, train_r2=0.0300, val_r2=-5.9599, val_cum_r2=-40.1523, val_cum_pearson=-0.0039:  16%|█▌        | 161/996 [00:03<00:14, 59.38it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.446e+00, tolerance: 2.987e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 165, train_r2=0.0318, val_r2=-0.6055, val_cum_r2=-39.8196, val_cum_pearson=-0.0039:  16%|█▌        | 161/996 [00:03<00:14, 59.38it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.448e+00, tolerance: 2.991e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 166, train_r2=0.0316, val_r2=-0.0539, val_cum_r2=-39.7319, val_cum_pearson=-0.0039:  16%|█▌        | 161/996 [00:03<00:14, 59.38it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.459e+00, tolerance: 3.016e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 167, train_r2=0.0327, val_r2=0.0603, val_cum_r2=-39.6794, val_cum_pearson=-0.0039:  16%|█▌        | 161/996 [00:03<00:14, 59.38it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.461e+00, tolerance: 3.023e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 168, train_r2=0.0333, val_r2=-0.1179, val_cum_r2=-39.5740, val_cum_pearson=-0.0037:  16%|█▌        | 161/996 [00:03<00:14, 59.38it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.463e+00, tolerance: 3.027e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 169, train_r2=0.0333, val_r2=-12.9534, val_cum_r2=-39.2782, val_cum_pearson=-0.0036:  16%|█▌        | 161/996 [00:03<00:14, 59.38it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.466e+00, tolerance: 3.035e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 170, train_r2=0.0337, val_r2=-10.1165, val_cum_r2=-39.2717, val_cum_pearson=-0.0036:  17%|█▋        | 168/996 [00:03<00:14, 58.31it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.479e+00, tolerance: 3.057e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 171, train_r2=0.0324, val_r2=-11.0769, val_cum_r2=-39.1791, val_cum_pearson=-0.0037:  17%|█▋        | 168/996 [00:03<00:14, 58.31it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e+00, tolerance: 3.058e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 172, train_r2=0.0320, val_r2=-3.2283, val_cum_r2=-38.9344, val_cum_pearson=-0.0038:  17%|█▋        | 168/996 [00:03<00:14, 58.31it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.483e+00, tolerance: 3.065e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 173, train_r2=0.0322, val_r2=-2.7620, val_cum_r2=-38.5390, val_cum_pearson=-0.0039:  17%|█▋        | 168/996 [00:03<00:14, 58.31it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.492e+00, tolerance: 3.084e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 174, train_r2=0.0328, val_r2=-3.0007, val_cum_r2=-38.4174, val_cum_pearson=-0.0038:  17%|█▋        | 168/996 [00:03<00:14, 58.31it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.505e+00, tolerance: 3.116e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 175, train_r2=0.0337, val_r2=-2.9116, val_cum_r2=-38.2770, val_cum_pearson=-0.0036:  17%|█▋        | 168/996 [00:03<00:14, 58.31it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.511e+00, tolerance: 3.126e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 176, train_r2=0.0332, val_r2=-1.0949, val_cum_r2=-38.2293, val_cum_pearson=-0.0036:  17%|█▋        | 174/996 [00:04<00:14, 55.21it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.515e+00, tolerance: 3.137e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 177, train_r2=0.0338, val_r2=-5.1932, val_cum_r2=-38.1841, val_cum_pearson=-0.0036:  17%|█▋        | 174/996 [00:04<00:14, 55.21it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.516e+00, tolerance: 3.141e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 178, train_r2=0.0344, val_r2=-13.3830, val_cum_r2=-38.1470, val_cum_pearson=-0.0036:  17%|█▋        | 174/996 [00:04<00:14, 55.21it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.519e+00, tolerance: 3.144e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 179, train_r2=0.0341, val_r2=-0.7601, val_cum_r2=-38.1245, val_cum_pearson=-0.0036:  17%|█▋        | 174/996 [00:04<00:14, 55.21it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.521e+00, tolerance: 3.147e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 180, train_r2=0.0333, val_r2=-0.4370, val_cum_r2=-38.1149, val_cum_pearson=-0.0036:  17%|█▋        | 174/996 [00:04<00:14, 55.21it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.522e+00, tolerance: 3.149e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 181, train_r2=0.0333, val_r2=-1.2956, val_cum_r2=-38.0487, val_cum_pearson=-0.0037:  17%|█▋        | 174/996 [00:04<00:14, 55.21it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.522e+00, tolerance: 3.150e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 182, train_r2=0.0334, val_r2=-3.5426, val_cum_r2=-37.9621, val_cum_pearson=-0.0037:  18%|█▊        | 180/996 [00:04<00:14, 55.12it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e+00, tolerance: 3.156e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 183, train_r2=0.0336, val_r2=-0.6094, val_cum_r2=-37.9301, val_cum_pearson=-0.0038:  18%|█▊        | 180/996 [00:04<00:14, 55.12it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.528e+00, tolerance: 3.163e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 184, train_r2=0.0336, val_r2=-1.9277, val_cum_r2=-37.9097, val_cum_pearson=-0.0038:  18%|█▊        | 180/996 [00:04<00:14, 55.12it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.529e+00, tolerance: 3.165e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 185, train_r2=0.0338, val_r2=-9.6078, val_cum_r2=-37.7360, val_cum_pearson=-0.0037:  18%|█▊        | 180/996 [00:04<00:14, 55.12it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+00, tolerance: 3.167e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 186, train_r2=0.0338, val_r2=-36.3284, val_cum_r2=-37.5451, val_cum_pearson=-0.0035:  18%|█▊        | 180/996 [00:04<00:14, 55.12it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.537e+00, tolerance: 3.182e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 187, train_r2=0.0336, val_r2=-12.3402, val_cum_r2=-37.4231, val_cum_pearson=-0.0033:  18%|█▊        | 180/996 [00:04<00:14, 55.12it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.544e+00, tolerance: 3.197e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 188, train_r2=0.0341, val_r2=-6.3986, val_cum_r2=-37.3144, val_cum_pearson=-0.0032:  19%|█▊        | 186/996 [00:04<00:15, 52.93it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.548e+00, tolerance: 3.208e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 189, train_r2=0.0345, val_r2=-1.8731, val_cum_r2=-37.3025, val_cum_pearson=-0.0032:  19%|█▊        | 186/996 [00:04<00:15, 52.93it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+00, tolerance: 3.217e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 190, train_r2=0.0340, val_r2=-0.8736, val_cum_r2=-37.2951, val_cum_pearson=-0.0032:  19%|█▊        | 186/996 [00:04<00:15, 52.93it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+00, tolerance: 3.218e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 191, train_r2=0.0341, val_r2=-62.4935, val_cum_r2=-37.2164, val_cum_pearson=-0.0031:  19%|█▊        | 186/996 [00:04<00:15, 52.93it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+00, tolerance: 3.219e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 192, train_r2=0.0341, val_r2=-0.2898, val_cum_r2=-37.2011, val_cum_pearson=-0.0031:  19%|█▊        | 186/996 [00:04<00:15, 52.93it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.558e+00, tolerance: 3.225e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 193, train_r2=0.0341, val_r2=0.0563, val_cum_r2=-37.1855, val_cum_pearson=-0.0031:  19%|█▊        | 186/996 [00:04<00:15, 52.93it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.558e+00, tolerance: 3.226e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 194, train_r2=0.0341, val_r2=-3.2472, val_cum_r2=-37.0759, val_cum_pearson=-0.0032:  19%|█▉        | 192/996 [00:04<00:15, 53.45it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.559e+00, tolerance: 3.228e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 195, train_r2=0.0342, val_r2=-0.7218, val_cum_r2=-37.0175, val_cum_pearson=-0.0032:  19%|█▉        | 192/996 [00:04<00:15, 53.45it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.564e+00, tolerance: 3.237e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 196, train_r2=0.0340, val_r2=-24.8663, val_cum_r2=-36.8314, val_cum_pearson=-0.0031:  19%|█▉        | 192/996 [00:04<00:15, 53.45it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.566e+00, tolerance: 3.243e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 197, train_r2=0.0338, val_r2=-0.4194, val_cum_r2=-36.7453, val_cum_pearson=-0.0029:  19%|█▉        | 192/996 [00:04<00:15, 53.45it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.574e+00, tolerance: 3.259e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 198, train_r2=0.0337, val_r2=-0.4754, val_cum_r2=-36.7319, val_cum_pearson=-0.0029:  19%|█▉        | 192/996 [00:04<00:15, 53.45it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.577e+00, tolerance: 3.266e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 199, train_r2=0.0344, val_r2=-0.8403, val_cum_r2=-36.6712, val_cum_pearson=-0.0030:  19%|█▉        | 192/996 [00:04<00:15, 53.45it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.578e+00, tolerance: 3.267e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 200, train_r2=0.0342, val_r2=-0.5344, val_cum_r2=-36.6531, val_cum_pearson=-0.0030:  20%|█▉        | 198/996 [00:04<00:15, 51.75it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+00, tolerance: 3.273e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 201, train_r2=0.0339, val_r2=-0.0895, val_cum_r2=-36.6094, val_cum_pearson=-0.0030:  20%|█▉        | 198/996 [00:04<00:15, 51.75it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+00, tolerance: 3.274e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 202, train_r2=0.0337, val_r2=-0.1659, val_cum_r2=-36.5756, val_cum_pearson=-0.0030:  20%|█▉        | 198/996 [00:04<00:15, 51.75it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.584e+00, tolerance: 3.278e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 203, train_r2=0.0338, val_r2=-0.6969, val_cum_r2=-36.5600, val_cum_pearson=-0.0030:  20%|█▉        | 198/996 [00:04<00:15, 51.75it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.585e+00, tolerance: 3.281e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 204, train_r2=0.0337, val_r2=-14.5413, val_cum_r2=-36.4838, val_cum_pearson=-0.0028:  20%|█▉        | 198/996 [00:04<00:15, 51.75it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.587e+00, tolerance: 3.283e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 205, train_r2=0.0334, val_r2=-6.4437, val_cum_r2=-36.3643, val_cum_pearson=-0.0027:  20%|█▉        | 198/996 [00:04<00:15, 51.75it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+00, tolerance: 3.289e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 206, train_r2=0.0337, val_r2=-1.0199, val_cum_r2=-36.3425, val_cum_pearson=-0.0026:  20%|██        | 204/996 [00:04<00:16, 48.72it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.593e+00, tolerance: 3.300e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 207, train_r2=0.0345, val_r2=-0.8854, val_cum_r2=-36.3103, val_cum_pearson=-0.0026:  20%|██        | 204/996 [00:04<00:16, 48.72it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.594e+00, tolerance: 3.302e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 208, train_r2=0.0346, val_r2=-0.6505, val_cum_r2=-36.2976, val_cum_pearson=-0.0026:  20%|██        | 204/996 [00:04<00:16, 48.72it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.595e+00, tolerance: 3.305e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 209, train_r2=0.0345, val_r2=0.1175, val_cum_r2=-36.2549, val_cum_pearson=-0.0026:  20%|██        | 204/996 [00:04<00:16, 48.72it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.596e+00, tolerance: 3.306e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 210, train_r2=0.0343, val_r2=0.0156, val_cum_r2=-36.1961, val_cum_pearson=-0.0025:  20%|██        | 204/996 [00:04<00:16, 48.72it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.598e+00, tolerance: 3.310e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 211, train_r2=0.0345, val_r2=-0.7166, val_cum_r2=-36.1460, val_cum_pearson=-0.0025:  21%|██        | 209/996 [00:04<00:16, 47.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.600e+00, tolerance: 3.315e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 212, train_r2=0.0347, val_r2=-0.1266, val_cum_r2=-36.1111, val_cum_pearson=-0.0025:  21%|██        | 209/996 [00:04<00:16, 47.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.603e+00, tolerance: 3.320e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 213, train_r2=0.0342, val_r2=-0.4315, val_cum_r2=-36.0802, val_cum_pearson=-0.0025:  21%|██        | 209/996 [00:04<00:16, 47.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.605e+00, tolerance: 3.323e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 214, train_r2=0.0341, val_r2=-1.1152, val_cum_r2=-35.9907, val_cum_pearson=-0.0026:  21%|██        | 209/996 [00:04<00:16, 47.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e+00, tolerance: 3.326e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 215, train_r2=0.0343, val_r2=-0.1396, val_cum_r2=-35.9339, val_cum_pearson=-0.0026:  21%|██        | 209/996 [00:04<00:16, 47.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+00, tolerance: 3.334e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 216, train_r2=0.0336, val_r2=-4.3053, val_cum_r2=-35.9062, val_cum_pearson=-0.0025:  21%|██        | 209/996 [00:04<00:16, 47.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.614e+00, tolerance: 3.339e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 217, train_r2=0.0333, val_r2=-1.4314, val_cum_r2=-35.8837, val_cum_pearson=-0.0025:  22%|██▏       | 215/996 [00:04<00:16, 47.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.615e+00, tolerance: 3.342e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 218, train_r2=0.0336, val_r2=-1.2166, val_cum_r2=-35.8645, val_cum_pearson=-0.0026:  22%|██▏       | 215/996 [00:04<00:16, 47.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.616e+00, tolerance: 3.344e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 219, train_r2=0.0335, val_r2=-0.0770, val_cum_r2=-35.8449, val_cum_pearson=-0.0025:  22%|██▏       | 215/996 [00:04<00:16, 47.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.617e+00, tolerance: 3.346e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 220, train_r2=0.0332, val_r2=-0.2177, val_cum_r2=-35.7869, val_cum_pearson=-0.0025:  22%|██▏       | 215/996 [00:04<00:16, 47.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.618e+00, tolerance: 3.347e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 221, train_r2=0.0332, val_r2=-4.8214, val_cum_r2=-35.6025, val_cum_pearson=-0.0027:  22%|██▏       | 215/996 [00:04<00:16, 47.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.621e+00, tolerance: 3.353e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 222, train_r2=0.0330, val_r2=-4.6314, val_cum_r2=-35.5142, val_cum_pearson=-0.0029:  22%|██▏       | 220/996 [00:04<00:16, 47.26it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.632e+00, tolerance: 3.370e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 223, train_r2=0.0318, val_r2=-1.5863, val_cum_r2=-35.3554, val_cum_pearson=-0.0027:  22%|██▏       | 220/996 [00:04<00:16, 47.26it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.637e+00, tolerance: 3.379e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 224, train_r2=0.0309, val_r2=-3.4288, val_cum_r2=-35.2135, val_cum_pearson=-0.0025:  22%|██▏       | 220/996 [00:05<00:16, 47.26it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.644e+00, tolerance: 3.394e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 225, train_r2=0.0314, val_r2=-3.8215, val_cum_r2=-35.1640, val_cum_pearson=-0.0024:  22%|██▏       | 220/996 [00:05<00:16, 47.26it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.649e+00, tolerance: 3.407e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 226, train_r2=0.0322, val_r2=0.2577, val_cum_r2=-35.1451, val_cum_pearson=-0.0024:  22%|██▏       | 220/996 [00:05<00:16, 47.26it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.650e+00, tolerance: 3.412e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 227, train_r2=0.0327, val_r2=-0.4825, val_cum_r2=-35.0957, val_cum_pearson=-0.0023:  23%|██▎       | 225/996 [00:05<00:16, 46.82it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.651e+00, tolerance: 3.414e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 228, train_r2=0.0328, val_r2=0.0317, val_cum_r2=-34.7141, val_cum_pearson=-0.0022:  23%|██▎       | 225/996 [00:05<00:16, 46.82it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.654e+00, tolerance: 3.418e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 229, train_r2=0.0325, val_r2=-0.3738, val_cum_r2=-34.5930, val_cum_pearson=-0.0023:  23%|██▎       | 225/996 [00:05<00:16, 46.82it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.671e+00, tolerance: 3.456e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 230, train_r2=0.0331, val_r2=-0.4092, val_cum_r2=-34.5676, val_cum_pearson=-0.0023:  23%|██▎       | 225/996 [00:05<00:16, 46.82it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.679e+00, tolerance: 3.468e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 231, train_r2=0.0319, val_r2=-0.6926, val_cum_r2=-34.5467, val_cum_pearson=-0.0023:  23%|██▎       | 225/996 [00:05<00:16, 46.82it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e+00, tolerance: 3.470e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 232, train_r2=0.0317, val_r2=-0.2524, val_cum_r2=-34.4790, val_cum_pearson=-0.0023:  23%|██▎       | 230/996 [00:05<00:17, 44.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.682e+00, tolerance: 3.473e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 233, train_r2=0.0313, val_r2=0.2349, val_cum_r2=-34.4022, val_cum_pearson=-0.0021:  23%|██▎       | 230/996 [00:05<00:17, 44.66it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.685e+00, tolerance: 3.479e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 234, train_r2=0.0314, val_r2=0.1184, val_cum_r2=-34.3533, val_cum_pearson=-0.0021:  23%|██▎       | 230/996 [00:05<00:17, 44.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.687e+00, tolerance: 3.487e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 235, train_r2=0.0323, val_r2=-0.7358, val_cum_r2=-34.2973, val_cum_pearson=-0.0020:  23%|██▎       | 230/996 [00:05<00:17, 44.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+00, tolerance: 3.492e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 236, train_r2=0.0325, val_r2=-0.4926, val_cum_r2=-34.1639, val_cum_pearson=-0.0019:  23%|██▎       | 230/996 [00:05<00:17, 44.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.692e+00, tolerance: 3.497e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 237, train_r2=0.0326, val_r2=-3.7504, val_cum_r2=-33.8604, val_cum_pearson=-0.0017:  24%|██▎       | 235/996 [00:05<00:16, 44.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+00, tolerance: 3.511e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 238, train_r2=0.0330, val_r2=-4.1555, val_cum_r2=-33.6527, val_cum_pearson=-0.0016:  24%|██▎       | 235/996 [00:05<00:16, 44.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.713e+00, tolerance: 3.542e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 239, train_r2=0.0327, val_r2=-1.9942, val_cum_r2=-33.6187, val_cum_pearson=-0.0017:  24%|██▎       | 235/996 [00:05<00:16, 44.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.724e+00, tolerance: 3.564e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 240, train_r2=0.0324, val_r2=-1.6964, val_cum_r2=-33.5581, val_cum_pearson=-0.0017:  24%|██▎       | 235/996 [00:05<00:16, 44.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.727e+00, tolerance: 3.567e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 241, train_r2=0.0318, val_r2=-1.1155, val_cum_r2=-33.5013, val_cum_pearson=-0.0018:  24%|██▎       | 235/996 [00:05<00:16, 44.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.730e+00, tolerance: 3.574e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 242, train_r2=0.0316, val_r2=-1.8496, val_cum_r2=-33.4150, val_cum_pearson=-0.0019:  24%|██▍       | 240/996 [00:05<00:16, 45.17it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.733e+00, tolerance: 3.580e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 243, train_r2=0.0318, val_r2=-0.0129, val_cum_r2=-33.3508, val_cum_pearson=-0.0019:  24%|██▍       | 240/996 [00:05<00:16, 45.17it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.739e+00, tolerance: 3.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 244, train_r2=0.0312, val_r2=0.1479, val_cum_r2=-33.3348, val_cum_pearson=-0.0018:  24%|██▍       | 240/996 [00:05<00:16, 45.17it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.742e+00, tolerance: 3.596e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 245, train_r2=0.0313, val_r2=-0.0615, val_cum_r2=-33.2613, val_cum_pearson=-0.0018:  24%|██▍       | 240/996 [00:05<00:16, 45.17it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.742e+00, tolerance: 3.598e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 246, train_r2=0.0317, val_r2=-6.2095, val_cum_r2=-32.9628, val_cum_pearson=-0.0020:  24%|██▍       | 240/996 [00:05<00:16, 45.17it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.746e+00, tolerance: 3.606e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 247, train_r2=0.0318, val_r2=-4.6717, val_cum_r2=-32.3978, val_cum_pearson=-0.0021:  25%|██▍       | 245/996 [00:05<00:17, 43.53it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.764e+00, tolerance: 3.638e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 248, train_r2=0.0303, val_r2=0.0097, val_cum_r2=-32.3081, val_cum_pearson=-0.0021:  25%|██▍       | 245/996 [00:05<00:17, 43.53it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.794e+00, tolerance: 3.702e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 249, train_r2=0.0307, val_r2=-19.8837, val_cum_r2=-32.1006, val_cum_pearson=-0.0024:  25%|██▍       | 245/996 [00:05<00:17, 43.53it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.799e+00, tolerance: 3.712e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 250, train_r2=0.0308, val_r2=-7.1854, val_cum_r2=-31.8983, val_cum_pearson=-0.0028:  25%|██▍       | 245/996 [00:05<00:17, 43.53it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.815e+00, tolerance: 3.736e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 251, train_r2=0.0283, val_r2=-1.7835, val_cum_r2=-31.7724, val_cum_pearson=-0.0029:  25%|██▍       | 245/996 [00:05<00:17, 43.53it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.832e+00, tolerance: 3.760e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 252, train_r2=0.0255, val_r2=-3.5681, val_cum_r2=-31.6583, val_cum_pearson=-0.0031:  25%|██▌       | 250/996 [00:05<00:17, 42.42it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.841e+00, tolerance: 3.775e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 253, train_r2=0.0249, val_r2=-1.8952, val_cum_r2=-31.6412, val_cum_pearson=-0.0031:  25%|██▌       | 250/996 [00:05<00:17, 42.42it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.850e+00, tolerance: 3.789e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 254, train_r2=0.0237, val_r2=-1.3116, val_cum_r2=-31.6342, val_cum_pearson=-0.0032:  25%|██▌       | 250/996 [00:05<00:17, 42.42it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e+00, tolerance: 3.791e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 255, train_r2=0.0233, val_r2=-1.8641, val_cum_r2=-31.6168, val_cum_pearson=-0.0032:  25%|██▌       | 250/996 [00:05<00:17, 42.42it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e+00, tolerance: 3.792e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 256, train_r2=0.0231, val_r2=-3.6689, val_cum_r2=-31.5698, val_cum_pearson=-0.0032:  25%|██▌       | 250/996 [00:05<00:17, 42.42it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.854e+00, tolerance: 3.794e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 257, train_r2=0.0227, val_r2=-13.0876, val_cum_r2=-31.4963, val_cum_pearson=-0.0032:  26%|██▌       | 255/996 [00:05<00:17, 42.29it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.856e+00, tolerance: 3.800e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 258, train_r2=0.0229, val_r2=-0.3689, val_cum_r2=-31.4886, val_cum_pearson=-0.0031:  26%|██▌       | 255/996 [00:05<00:17, 42.29it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+00, tolerance: 3.809e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 259, train_r2=0.0230, val_r2=-4.7482, val_cum_r2=-31.2766, val_cum_pearson=-0.0032:  26%|██▌       | 255/996 [00:05<00:17, 42.29it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.861e+00, tolerance: 3.810e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 260, train_r2=0.0231, val_r2=-1.7630, val_cum_r2=-31.2031, val_cum_pearson=-0.0032:  26%|██▌       | 255/996 [00:05<00:17, 42.29it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e+00, tolerance: 3.835e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 261, train_r2=0.0233, val_r2=-2.9605, val_cum_r2=-31.1565, val_cum_pearson=-0.0032:  26%|██▌       | 255/996 [00:05<00:17, 42.29it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.877e+00, tolerance: 3.844e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 262, train_r2=0.0234, val_r2=-3.9095, val_cum_r2=-31.0295, val_cum_pearson=-0.0033:  26%|██▌       | 260/996 [00:05<00:17, 42.52it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.880e+00, tolerance: 3.850e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 263, train_r2=0.0234, val_r2=-3.9432, val_cum_r2=-30.8294, val_cum_pearson=-0.0034:  26%|██▌       | 260/996 [00:05<00:17, 42.52it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.889e+00, tolerance: 3.866e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 264, train_r2=0.0227, val_r2=-0.8861, val_cum_r2=-30.7587, val_cum_pearson=-0.0034:  26%|██▌       | 260/996 [00:05<00:17, 42.52it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.902e+00, tolerance: 3.891e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 265, train_r2=0.0224, val_r2=-0.2446, val_cum_r2=-30.7540, val_cum_pearson=-0.0034:  26%|██▌       | 260/996 [00:05<00:17, 42.52it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.906e+00, tolerance: 3.900e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 266, train_r2=0.0224, val_r2=-0.9490, val_cum_r2=-30.6854, val_cum_pearson=-0.0034:  26%|██▌       | 260/996 [00:05<00:17, 42.52it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e+00, tolerance: 3.901e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 267, train_r2=0.0223, val_r2=-1.1682, val_cum_r2=-30.6641, val_cum_pearson=-0.0033:  27%|██▋       | 265/996 [00:06<00:17, 41.73it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.910e+00, tolerance: 3.909e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 268, train_r2=0.0227, val_r2=-2.2625, val_cum_r2=-30.6560, val_cum_pearson=-0.0033:  27%|██▋       | 265/996 [00:06<00:17, 41.73it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.912e+00, tolerance: 3.912e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 269, train_r2=0.0227, val_r2=-1.2689, val_cum_r2=-30.6461, val_cum_pearson=-0.0033:  27%|██▋       | 265/996 [00:06<00:17, 41.73it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.912e+00, tolerance: 3.913e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 270, train_r2=0.0227, val_r2=-0.6559, val_cum_r2=-30.5912, val_cum_pearson=-0.0033:  27%|██▋       | 265/996 [00:06<00:17, 41.73it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.913e+00, tolerance: 3.914e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 271, train_r2=0.0226, val_r2=0.0346, val_cum_r2=-30.4935, val_cum_pearson=-0.0032:  27%|██▋       | 265/996 [00:06<00:17, 41.73it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.916e+00, tolerance: 3.921e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 272, train_r2=0.0227, val_r2=-2.9520, val_cum_r2=-30.4728, val_cum_pearson=-0.0033:  27%|██▋       | 270/996 [00:06<00:17, 41.20it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.922e+00, tolerance: 3.933e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 273, train_r2=0.0227, val_r2=-1.5004, val_cum_r2=-30.4233, val_cum_pearson=-0.0032:  27%|██▋       | 270/996 [00:06<00:17, 41.20it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.924e+00, tolerance: 3.936e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 274, train_r2=0.0223, val_r2=0.1456, val_cum_r2=-30.4064, val_cum_pearson=-0.0032:  27%|██▋       | 270/996 [00:06<00:17, 41.20it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.927e+00, tolerance: 3.942e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 275, train_r2=0.0224, val_r2=-0.7347, val_cum_r2=-30.4046, val_cum_pearson=-0.0032:  27%|██▋       | 270/996 [00:06<00:17, 41.20it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.928e+00, tolerance: 3.945e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 276, train_r2=0.0225, val_r2=-1.4002, val_cum_r2=-30.3745, val_cum_pearson=-0.0032:  27%|██▋       | 270/996 [00:06<00:17, 41.20it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.928e+00, tolerance: 3.945e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 277, train_r2=0.0225, val_r2=-0.2911, val_cum_r2=-30.3527, val_cum_pearson=-0.0031:  28%|██▊       | 275/996 [00:06<00:18, 39.87it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.930e+00, tolerance: 3.949e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 278, train_r2=0.0224, val_r2=-0.6770, val_cum_r2=-30.3384, val_cum_pearson=-0.0032:  28%|██▊       | 275/996 [00:06<00:18, 39.87it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.931e+00, tolerance: 3.951e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 279, train_r2=0.0224, val_r2=-12.9872, val_cum_r2=-30.1438, val_cum_pearson=-0.0033:  28%|██▊       | 275/996 [00:06<00:18, 39.87it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.933e+00, tolerance: 3.953e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 280, train_r2=0.0223, val_r2=-17.5687, val_cum_r2=-30.0313, val_cum_pearson=-0.0033:  28%|██▊       | 275/996 [00:06<00:18, 39.87it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.946e+00, tolerance: 3.979e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 281, train_r2=0.0221, val_r2=-0.8427, val_cum_r2=-29.9931, val_cum_pearson=-0.0033:  28%|██▊       | 275/996 [00:06<00:18, 39.87it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.953e+00, tolerance: 3.994e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 282, train_r2=0.0220, val_r2=-4.7823, val_cum_r2=-29.9678, val_cum_pearson=-0.0034:  28%|██▊       | 280/996 [00:06<00:18, 39.17it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.955e+00, tolerance: 3.999e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 283, train_r2=0.0222, val_r2=-6.7147, val_cum_r2=-29.7962, val_cum_pearson=-0.0032:  28%|██▊       | 280/996 [00:06<00:18, 39.17it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.958e+00, tolerance: 4.002e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 284, train_r2=0.0218, val_r2=-4.6789, val_cum_r2=-29.6907, val_cum_pearson=-0.0032:  28%|██▊       | 280/996 [00:06<00:18, 39.17it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.967e+00, tolerance: 4.025e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 285, train_r2=0.0225, val_r2=-0.6358, val_cum_r2=-29.6780, val_cum_pearson=-0.0032:  28%|██▊       | 280/996 [00:06<00:18, 39.17it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.975e+00, tolerance: 4.039e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 286, train_r2=0.0223, val_r2=-3.8508, val_cum_r2=-29.6484, val_cum_pearson=-0.0032:  28%|██▊       | 280/996 [00:06<00:18, 39.17it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.976e+00, tolerance: 4.041e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 287, train_r2=0.0223, val_r2=-0.6787, val_cum_r2=-29.6257, val_cum_pearson=-0.0032:  29%|██▊       | 285/996 [00:06<00:17, 39.56it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.978e+00, tolerance: 4.045e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 288, train_r2=0.0220, val_r2=-2.3773, val_cum_r2=-29.6054, val_cum_pearson=-0.0032:  29%|██▊       | 285/996 [00:06<00:17, 39.56it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.980e+00, tolerance: 4.048e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 289, train_r2=0.0219, val_r2=-8.4481, val_cum_r2=-29.5609, val_cum_pearson=-0.0032:  29%|██▊       | 285/996 [00:06<00:17, 39.56it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.981e+00, tolerance: 4.051e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 290, train_r2=0.0218, val_r2=-3.2373, val_cum_r2=-29.5368, val_cum_pearson=-0.0032:  29%|██▊       | 285/996 [00:06<00:17, 39.56it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.984e+00, tolerance: 4.057e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 291, train_r2=0.0220, val_r2=-0.5619, val_cum_r2=-29.4836, val_cum_pearson=-0.0032:  29%|██▉       | 289/996 [00:06<00:18, 38.75it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.986e+00, tolerance: 4.060e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 292, train_r2=0.0219, val_r2=-0.3388, val_cum_r2=-29.4591, val_cum_pearson=-0.0031:  29%|██▉       | 289/996 [00:06<00:18, 38.75it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.989e+00, tolerance: 4.068e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 293, train_r2=0.0221, val_r2=-0.3161, val_cum_r2=-29.4265, val_cum_pearson=-0.0032:  29%|██▉       | 289/996 [00:06<00:18, 38.75it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.990e+00, tolerance: 4.071e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 294, train_r2=0.0222, val_r2=-2.8054, val_cum_r2=-29.4116, val_cum_pearson=-0.0031:  29%|██▉       | 289/996 [00:06<00:18, 38.75it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.993e+00, tolerance: 4.075e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 295, train_r2=0.0221, val_r2=-1.5945, val_cum_r2=-29.3648, val_cum_pearson=-0.0031:  29%|██▉       | 293/996 [00:06<00:18, 38.15it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.994e+00, tolerance: 4.077e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 296, train_r2=0.0221, val_r2=-1.8707, val_cum_r2=-29.3255, val_cum_pearson=-0.0031:  29%|██▉       | 293/996 [00:06<00:18, 38.15it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.997e+00, tolerance: 4.084e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 297, train_r2=0.0221, val_r2=-0.6136, val_cum_r2=-29.3111, val_cum_pearson=-0.0030:  29%|██▉       | 293/996 [00:06<00:18, 38.15it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.999e+00, tolerance: 4.089e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 298, train_r2=0.0223, val_r2=-0.1398, val_cum_r2=-29.2997, val_cum_pearson=-0.0030:  29%|██▉       | 293/996 [00:06<00:18, 38.15it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.000e+00, tolerance: 4.091e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 299, train_r2=0.0222, val_r2=-10.4360, val_cum_r2=-29.2866, val_cum_pearson=-0.0031:  30%|██▉       | 297/996 [00:06<00:18, 37.34it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.001e+00, tolerance: 4.093e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 300, train_r2=0.0222, val_r2=-0.0090, val_cum_r2=-29.2846, val_cum_pearson=-0.0031:  30%|██▉       | 297/996 [00:06<00:18, 37.34it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.002e+00, tolerance: 4.095e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 301, train_r2=0.0222, val_r2=-0.6468, val_cum_r2=-29.2613, val_cum_pearson=-0.0030:  30%|██▉       | 297/996 [00:06<00:18, 37.34it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.002e+00, tolerance: 4.095e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 302, train_r2=0.0222, val_r2=-4.1975, val_cum_r2=-29.2509, val_cum_pearson=-0.0030:  30%|██▉       | 297/996 [00:06<00:18, 37.34it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.003e+00, tolerance: 4.098e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 303, train_r2=0.0224, val_r2=-0.2292, val_cum_r2=-29.2357, val_cum_pearson=-0.0030:  30%|███       | 301/996 [00:06<00:18, 37.13it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.004e+00, tolerance: 4.100e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 304, train_r2=0.0223, val_r2=-12.1603, val_cum_r2=-29.1982, val_cum_pearson=-0.0030:  30%|███       | 301/996 [00:07<00:18, 37.13it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.005e+00, tolerance: 4.102e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 305, train_r2=0.0224, val_r2=-1.6539, val_cum_r2=-29.1872, val_cum_pearson=-0.0030:  30%|███       | 301/996 [00:07<00:18, 37.13it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.007e+00, tolerance: 4.107e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 306, train_r2=0.0225, val_r2=-0.3766, val_cum_r2=-29.1853, val_cum_pearson=-0.0030:  30%|███       | 301/996 [00:07<00:18, 37.13it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.008e+00, tolerance: 4.108e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 307, train_r2=0.0224, val_r2=-1.4538, val_cum_r2=-29.1609, val_cum_pearson=-0.0030:  31%|███       | 305/996 [00:07<00:18, 36.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.008e+00, tolerance: 4.109e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 308, train_r2=0.0224, val_r2=-0.6965, val_cum_r2=-29.1540, val_cum_pearson=-0.0030:  31%|███       | 305/996 [00:07<00:18, 36.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.010e+00, tolerance: 4.112e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 309, train_r2=0.0224, val_r2=-6.6542, val_cum_r2=-29.1217, val_cum_pearson=-0.0030:  31%|███       | 305/996 [00:07<00:18, 36.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.011e+00, tolerance: 4.113e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 310, train_r2=0.0223, val_r2=-0.1246, val_cum_r2=-29.1178, val_cum_pearson=-0.0030:  31%|███       | 305/996 [00:07<00:18, 36.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.013e+00, tolerance: 4.118e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 311, train_r2=0.0221, val_r2=0.1349, val_cum_r2=-29.1125, val_cum_pearson=-0.0030:  31%|███       | 309/996 [00:07<00:18, 36.84it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.014e+00, tolerance: 4.118e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 312, train_r2=0.0221, val_r2=-1.0150, val_cum_r2=-29.1116, val_cum_pearson=-0.0030:  31%|███       | 309/996 [00:07<00:18, 36.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.014e+00, tolerance: 4.119e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 313, train_r2=0.0222, val_r2=-0.4948, val_cum_r2=-29.1033, val_cum_pearson=-0.0030:  31%|███       | 309/996 [00:07<00:18, 36.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.014e+00, tolerance: 4.119e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 314, train_r2=0.0221, val_r2=-0.0584, val_cum_r2=-29.1005, val_cum_pearson=-0.0030:  31%|███       | 309/996 [00:07<00:18, 36.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+00, tolerance: 4.120e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 315, train_r2=0.0221, val_r2=-10.5757, val_cum_r2=-29.0831, val_cum_pearson=-0.0030:  31%|███▏      | 313/996 [00:07<00:19, 35.23it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.015e+00, tolerance: 4.121e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 316, train_r2=0.0221, val_r2=-13.5869, val_cum_r2=-29.0706, val_cum_pearson=-0.0031:  31%|███▏      | 313/996 [00:07<00:19, 35.23it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.016e+00, tolerance: 4.123e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 317, train_r2=0.0220, val_r2=-5.4591, val_cum_r2=-29.0025, val_cum_pearson=-0.0031:  31%|███▏      | 313/996 [00:07<00:19, 35.23it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.017e+00, tolerance: 4.125e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 318, train_r2=0.0219, val_r2=-10.5629, val_cum_r2=-28.9191, val_cum_pearson=-0.0032:  31%|███▏      | 313/996 [00:07<00:19, 35.23it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.023e+00, tolerance: 4.135e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 319, train_r2=0.0215, val_r2=-0.1313, val_cum_r2=-28.9121, val_cum_pearson=-0.0032:  32%|███▏      | 317/996 [00:07<00:19, 35.62it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.030e+00, tolerance: 4.147e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 320, train_r2=0.0211, val_r2=-0.0753, val_cum_r2=-28.8569, val_cum_pearson=-0.0032:  32%|███▏      | 317/996 [00:07<00:19, 35.62it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.030e+00, tolerance: 4.148e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 321, train_r2=0.0211, val_r2=-0.0219, val_cum_r2=-28.8297, val_cum_pearson=-0.0032:  32%|███▏      | 317/996 [00:07<00:19, 35.62it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.034e+00, tolerance: 4.156e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 322, train_r2=0.0210, val_r2=0.4401, val_cum_r2=-28.8260, val_cum_pearson=-0.0032:  32%|███▏      | 317/996 [00:07<00:19, 35.62it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.036e+00, tolerance: 4.159e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 323, train_r2=0.0210, val_r2=0.1894, val_cum_r2=-28.8208, val_cum_pearson=-0.0032:  32%|███▏      | 321/996 [00:07<00:19, 34.47it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.036e+00, tolerance: 4.160e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 324, train_r2=0.0211, val_r2=-0.5982, val_cum_r2=-28.8136, val_cum_pearson=-0.0031:  32%|███▏      | 321/996 [00:07<00:19, 34.47it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.036e+00, tolerance: 4.161e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 325, train_r2=0.0211, val_r2=-1.7079, val_cum_r2=-28.6155, val_cum_pearson=-0.0031:  32%|███▏      | 321/996 [00:07<00:19, 34.47it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.037e+00, tolerance: 4.162e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 326, train_r2=0.0212, val_r2=-1.0163, val_cum_r2=-28.4598, val_cum_pearson=-0.0030:  32%|███▏      | 321/996 [00:07<00:19, 34.47it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.051e+00, tolerance: 4.190e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 327, train_r2=0.0210, val_r2=-0.6945, val_cum_r2=-28.4556, val_cum_pearson=-0.0030:  33%|███▎      | 325/996 [00:07<00:19, 33.70it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e+00, tolerance: 4.213e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 328, train_r2=0.0212, val_r2=-9.4824, val_cum_r2=-28.4029, val_cum_pearson=-0.0031:  33%|███▎      | 325/996 [00:07<00:19, 33.70it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e+00, tolerance: 4.214e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 329, train_r2=0.0211, val_r2=-8.8689, val_cum_r2=-28.3223, val_cum_pearson=-0.0031:  33%|███▎      | 325/996 [00:07<00:19, 33.70it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.067e+00, tolerance: 4.222e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 330, train_r2=0.0208, val_r2=0.0997, val_cum_r2=-28.3120, val_cum_pearson=-0.0031:  33%|███▎      | 325/996 [00:07<00:19, 33.70it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.073e+00, tolerance: 4.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 331, train_r2=0.0209, val_r2=-8.8903, val_cum_r2=-28.2783, val_cum_pearson=-0.0030:  33%|███▎      | 329/996 [00:07<00:20, 33.34it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.073e+00, tolerance: 4.235e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 332, train_r2=0.0210, val_r2=-0.1307, val_cum_r2=-28.2580, val_cum_pearson=-0.0030:  33%|███▎      | 329/996 [00:07<00:20, 33.34it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.075e+00, tolerance: 4.240e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 333, train_r2=0.0214, val_r2=-7.1879, val_cum_r2=-28.2460, val_cum_pearson=-0.0030:  33%|███▎      | 329/996 [00:07<00:20, 33.34it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.076e+00, tolerance: 4.243e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 334, train_r2=0.0213, val_r2=-0.2581, val_cum_r2=-28.2097, val_cum_pearson=-0.0030:  33%|███▎      | 329/996 [00:07<00:20, 33.34it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.077e+00, tolerance: 4.245e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 335, train_r2=0.0213, val_r2=0.0271, val_cum_r2=-28.2057, val_cum_pearson=-0.0030:  33%|███▎      | 333/996 [00:07<00:19, 33.29it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.080e+00, tolerance: 4.250e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 336, train_r2=0.0214, val_r2=-3.0364, val_cum_r2=-28.1500, val_cum_pearson=-0.0030:  33%|███▎      | 333/996 [00:07<00:19, 33.29it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.080e+00, tolerance: 4.251e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 337, train_r2=0.0214, val_r2=-4.8822, val_cum_r2=-28.1280, val_cum_pearson=-0.0031:  33%|███▎      | 333/996 [00:07<00:19, 33.29it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.084e+00, tolerance: 4.259e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 338, train_r2=0.0213, val_r2=0.1162, val_cum_r2=-28.1165, val_cum_pearson=-0.0031:  33%|███▎      | 333/996 [00:08<00:19, 33.29it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e+00, tolerance: 4.263e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 339, train_r2=0.0212, val_r2=-0.0741, val_cum_r2=-28.0900, val_cum_pearson=-0.0030:  34%|███▍      | 337/996 [00:08<00:19, 33.74it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.087e+00, tolerance: 4.264e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 340, train_r2=0.0212, val_r2=-0.8482, val_cum_r2=-28.0812, val_cum_pearson=-0.0030:  34%|███▍      | 337/996 [00:08<00:19, 33.74it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.088e+00, tolerance: 4.268e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 341, train_r2=0.0215, val_r2=-0.3143, val_cum_r2=-28.0724, val_cum_pearson=-0.0030:  34%|███▍      | 337/996 [00:08<00:19, 33.74it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e+00, tolerance: 4.270e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 342, train_r2=0.0214, val_r2=-0.7973, val_cum_r2=-28.0499, val_cum_pearson=-0.0030:  34%|███▍      | 337/996 [00:08<00:19, 33.74it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.090e+00, tolerance: 4.271e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 343, train_r2=0.0213, val_r2=0.1855, val_cum_r2=-28.0489, val_cum_pearson=-0.0030:  34%|███▍      | 341/996 [00:08<00:18, 34.54it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.092e+00, tolerance: 4.274e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 344, train_r2=0.0213, val_r2=-0.4045, val_cum_r2=-28.0380, val_cum_pearson=-0.0030:  34%|███▍      | 341/996 [00:08<00:18, 34.54it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.092e+00, tolerance: 4.275e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 345, train_r2=0.0213, val_r2=-10.2901, val_cum_r2=-28.0129, val_cum_pearson=-0.0030:  34%|███▍      | 341/996 [00:08<00:18, 34.54it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+00, tolerance: 4.276e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 346, train_r2=0.0212, val_r2=-3.5515, val_cum_r2=-27.9858, val_cum_pearson=-0.0030:  34%|███▍      | 341/996 [00:08<00:18, 34.54it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.095e+00, tolerance: 4.280e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 347, train_r2=0.0212, val_r2=0.1501, val_cum_r2=-27.9826, val_cum_pearson=-0.0030:  35%|███▍      | 345/996 [00:08<00:19, 32.71it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.096e+00, tolerance: 4.284e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 348, train_r2=0.0213, val_r2=-2.8491, val_cum_r2=-27.9682, val_cum_pearson=-0.0029:  35%|███▍      | 345/996 [00:08<00:19, 32.71it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.097e+00, tolerance: 4.285e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 349, train_r2=0.0213, val_r2=-0.6285, val_cum_r2=-27.9611, val_cum_pearson=-0.0029:  35%|███▍      | 345/996 [00:08<00:19, 32.71it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.097e+00, tolerance: 4.287e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 350, train_r2=0.0214, val_r2=-0.1120, val_cum_r2=-27.9362, val_cum_pearson=-0.0029:  35%|███▍      | 345/996 [00:08<00:19, 32.71it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+00, tolerance: 4.288e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 351, train_r2=0.0215, val_r2=0.0122, val_cum_r2=-27.9102, val_cum_pearson=-0.0029:  35%|███▌      | 349/996 [00:08<00:19, 33.08it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+00, tolerance: 4.292e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 352, train_r2=0.0215, val_r2=-8.2681, val_cum_r2=-27.8259, val_cum_pearson=-0.0030:  35%|███▌      | 349/996 [00:08<00:19, 33.08it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.102e+00, tolerance: 4.296e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 353, train_r2=0.0215, val_r2=-17.7851, val_cum_r2=-27.7966, val_cum_pearson=-0.0030:  35%|███▌      | 349/996 [00:08<00:19, 33.08it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.109e+00, tolerance: 4.309e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 354, train_r2=0.0211, val_r2=-4.0354, val_cum_r2=-27.7542, val_cum_pearson=-0.0029:  35%|███▌      | 349/996 [00:08<00:19, 33.08it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.112e+00, tolerance: 4.313e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 355, train_r2=0.0209, val_r2=-0.8960, val_cum_r2=-27.7182, val_cum_pearson=-0.0029:  35%|███▌      | 353/996 [00:08<00:19, 32.99it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.114e+00, tolerance: 4.320e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 356, train_r2=0.0211, val_r2=-0.0112, val_cum_r2=-27.7109, val_cum_pearson=-0.0029:  35%|███▌      | 353/996 [00:08<00:19, 32.99it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.116e+00, tolerance: 4.325e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 357, train_r2=0.0214, val_r2=-2.4194, val_cum_r2=-27.6901, val_cum_pearson=-0.0029:  35%|███▌      | 353/996 [00:08<00:19, 32.99it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.117e+00, tolerance: 4.326e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 358, train_r2=0.0214, val_r2=-0.0013, val_cum_r2=-27.6871, val_cum_pearson=-0.0029:  35%|███▌      | 353/996 [00:08<00:19, 32.99it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.118e+00, tolerance: 4.330e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 359, train_r2=0.0214, val_r2=-0.3196, val_cum_r2=-27.6838, val_cum_pearson=-0.0028:  36%|███▌      | 357/996 [00:08<00:18, 34.00it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.119e+00, tolerance: 4.330e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 360, train_r2=0.0214, val_r2=-1.6024, val_cum_r2=-27.6750, val_cum_pearson=-0.0028:  36%|███▌      | 357/996 [00:08<00:18, 34.00it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.119e+00, tolerance: 4.330e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 361, train_r2=0.0214, val_r2=-1.3146, val_cum_r2=-27.6546, val_cum_pearson=-0.0028:  36%|███▌      | 357/996 [00:08<00:18, 34.00it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.120e+00, tolerance: 4.332e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 362, train_r2=0.0214, val_r2=0.1389, val_cum_r2=-27.6419, val_cum_pearson=-0.0028:  36%|███▌      | 357/996 [00:08<00:18, 34.00it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+00, tolerance: 4.335e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 363, train_r2=0.0215, val_r2=-1.2454, val_cum_r2=-27.5443, val_cum_pearson=-0.0028:  36%|███▌      | 361/996 [00:08<00:19, 33.36it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.122e+00, tolerance: 4.337e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 364, train_r2=0.0216, val_r2=-0.0463, val_cum_r2=-27.5022, val_cum_pearson=-0.0028:  36%|███▌      | 361/996 [00:08<00:19, 33.36it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+00, tolerance: 4.352e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 365, train_r2=0.0214, val_r2=0.1181, val_cum_r2=-27.4985, val_cum_pearson=-0.0028:  36%|███▌      | 361/996 [00:08<00:19, 33.36it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.133e+00, tolerance: 4.359e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 366, train_r2=0.0214, val_r2=-0.5769, val_cum_r2=-27.4957, val_cum_pearson=-0.0028:  36%|███▌      | 361/996 [00:08<00:19, 33.36it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.133e+00, tolerance: 4.359e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 367, train_r2=0.0215, val_r2=-0.4065, val_cum_r2=-27.4896, val_cum_pearson=-0.0028:  37%|███▋      | 365/996 [00:08<00:19, 31.62it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.133e+00, tolerance: 4.360e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 368, train_r2=0.0214, val_r2=-2.7207, val_cum_r2=-27.4791, val_cum_pearson=-0.0028:  37%|███▋      | 365/996 [00:08<00:19, 31.62it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e+00, tolerance: 4.361e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 369, train_r2=0.0213, val_r2=-1.3592, val_cum_r2=-27.3539, val_cum_pearson=-0.0027:  37%|███▋      | 365/996 [00:08<00:19, 31.62it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e+00, tolerance: 4.363e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 370, train_r2=0.0214, val_r2=-2.3299, val_cum_r2=-27.3088, val_cum_pearson=-0.0026:  37%|███▋      | 365/996 [00:08<00:19, 31.62it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.144e+00, tolerance: 4.382e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 371, train_r2=0.0215, val_r2=-0.1227, val_cum_r2=-27.2914, val_cum_pearson=-0.0026:  37%|███▋      | 369/996 [00:09<00:19, 31.79it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.147e+00, tolerance: 4.389e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 372, train_r2=0.0217, val_r2=-10.5948, val_cum_r2=-27.2448, val_cum_pearson=-0.0026:  37%|███▋      | 369/996 [00:09<00:19, 31.79it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.148e+00, tolerance: 4.392e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 373, train_r2=0.0217, val_r2=-4.5449, val_cum_r2=-27.1241, val_cum_pearson=-0.0025:  37%|███▋      | 369/996 [00:09<00:19, 31.79it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.152e+00, tolerance: 4.400e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 374, train_r2=0.0219, val_r2=-0.4417, val_cum_r2=-27.0803, val_cum_pearson=-0.0025:  37%|███▋      | 369/996 [00:09<00:19, 31.79it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+00, tolerance: 4.419e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 375, train_r2=0.0217, val_r2=-0.1124, val_cum_r2=-27.0710, val_cum_pearson=-0.0025:  37%|███▋      | 373/996 [00:09<00:20, 29.71it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.165e+00, tolerance: 4.426e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 376, train_r2=0.0217, val_r2=0.0289, val_cum_r2=-27.0605, val_cum_pearson=-0.0025:  37%|███▋      | 373/996 [00:09<00:20, 29.71it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.166e+00, tolerance: 4.428e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 377, train_r2=0.0218, val_r2=-0.2580, val_cum_r2=-27.0001, val_cum_pearson=-0.0025:  37%|███▋      | 373/996 [00:09<00:20, 29.71it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.166e+00, tolerance: 4.429e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 378, train_r2=0.0218, val_r2=-4.5903, val_cum_r2=-26.9703, val_cum_pearson=-0.0026:  37%|███▋      | 373/996 [00:09<00:20, 29.71it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+00, tolerance: 4.439e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 379, train_r2=0.0215, val_r2=-1.1338, val_cum_r2=-26.9652, val_cum_pearson=-0.0026:  38%|███▊      | 377/996 [00:09<00:21, 29.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.175e+00, tolerance: 4.444e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 380, train_r2=0.0211, val_r2=-0.9492, val_cum_r2=-26.9633, val_cum_pearson=-0.0026:  38%|███▊      | 377/996 [00:09<00:21, 29.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.176e+00, tolerance: 4.445e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 381, train_r2=0.0210, val_r2=-4.5798, val_cum_r2=-26.9423, val_cum_pearson=-0.0026:  38%|███▊      | 377/996 [00:09<00:21, 29.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.176e+00, tolerance: 4.445e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 382, train_r2=0.0209, val_r2=-0.5762, val_cum_r2=-26.9305, val_cum_pearson=-0.0027:  38%|███▊      | 377/996 [00:09<00:21, 29.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.179e+00, tolerance: 4.449e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 383, train_r2=0.0206, val_r2=-1.4685, val_cum_r2=-26.8837, val_cum_pearson=-0.0026:  38%|███▊      | 381/996 [00:09<00:21, 29.04it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.180e+00, tolerance: 4.451e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 384, train_r2=0.0205, val_r2=-0.6323, val_cum_r2=-26.8729, val_cum_pearson=-0.0026:  38%|███▊      | 381/996 [00:09<00:21, 29.04it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.183e+00, tolerance: 4.459e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 385, train_r2=0.0208, val_r2=-0.2091, val_cum_r2=-26.8407, val_cum_pearson=-0.0026:  38%|███▊      | 381/996 [00:09<00:21, 29.04it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+00, tolerance: 4.460e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 386, train_r2=0.0207, val_r2=-2.2763, val_cum_r2=-26.8231, val_cum_pearson=-0.0026:  39%|███▊      | 384/996 [00:09<00:21, 28.63it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.187e+00, tolerance: 4.466e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 387, train_r2=0.0206, val_r2=-1.1783, val_cum_r2=-26.7042, val_cum_pearson=-0.0027:  39%|███▊      | 384/996 [00:09<00:21, 28.63it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.189e+00, tolerance: 4.469e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 388, train_r2=0.0204, val_r2=-3.5036, val_cum_r2=-26.6180, val_cum_pearson=-0.0027:  39%|███▊      | 384/996 [00:09<00:21, 28.63it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.199e+00, tolerance: 4.489e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 389, train_r2=0.0201, val_r2=-0.1600, val_cum_r2=-26.6089, val_cum_pearson=-0.0027:  39%|███▉      | 387/996 [00:09<00:22, 27.27it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+00, tolerance: 4.503e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 390, train_r2=0.0197, val_r2=-0.2938, val_cum_r2=-26.6049, val_cum_pearson=-0.0027:  39%|███▉      | 387/996 [00:09<00:22, 27.27it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.208e+00, tolerance: 4.505e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 391, train_r2=0.0196, val_r2=-2.5289, val_cum_r2=-26.6007, val_cum_pearson=-0.0028:  39%|███▉      | 387/996 [00:09<00:22, 27.27it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+00, tolerance: 4.505e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 392, train_r2=0.0196, val_r2=-1.4756, val_cum_r2=-26.5984, val_cum_pearson=-0.0028:  39%|███▉      | 390/996 [00:09<00:22, 27.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+00, tolerance: 4.506e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 393, train_r2=0.0195, val_r2=-2.4734, val_cum_r2=-26.5743, val_cum_pearson=-0.0027:  39%|███▉      | 390/996 [00:09<00:22, 27.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+00, tolerance: 4.506e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 394, train_r2=0.0195, val_r2=-0.1025, val_cum_r2=-26.5471, val_cum_pearson=-0.0027:  39%|███▉      | 390/996 [00:09<00:22, 27.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.211e+00, tolerance: 4.510e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 395, train_r2=0.0196, val_r2=-0.0055, val_cum_r2=-26.5217, val_cum_pearson=-0.0027:  39%|███▉      | 393/996 [00:09<00:22, 27.35it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+00, tolerance: 4.515e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 396, train_r2=0.0197, val_r2=-0.0343, val_cum_r2=-26.5103, val_cum_pearson=-0.0027:  39%|███▉      | 393/996 [00:09<00:22, 27.35it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.215e+00, tolerance: 4.519e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 397, train_r2=0.0197, val_r2=-1.7038, val_cum_r2=-26.4651, val_cum_pearson=-0.0026:  39%|███▉      | 393/996 [00:09<00:22, 27.35it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+00, tolerance: 4.521e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 398, train_r2=0.0197, val_r2=-0.5507, val_cum_r2=-26.4630, val_cum_pearson=-0.0026:  40%|███▉      | 396/996 [00:10<00:22, 26.30it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.219e+00, tolerance: 4.529e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 399, train_r2=0.0199, val_r2=-0.1078, val_cum_r2=-26.4531, val_cum_pearson=-0.0026:  40%|███▉      | 396/996 [00:10<00:22, 26.30it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+00, tolerance: 4.529e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 400, train_r2=0.0199, val_r2=-0.2202, val_cum_r2=-26.4364, val_cum_pearson=-0.0026:  40%|███▉      | 396/996 [00:10<00:22, 26.30it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+00, tolerance: 4.531e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 401, train_r2=0.0199, val_r2=-5.0127, val_cum_r2=-26.4282, val_cum_pearson=-0.0027:  40%|████      | 399/996 [00:10<00:22, 26.62it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.222e+00, tolerance: 4.534e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 402, train_r2=0.0197, val_r2=-0.6170, val_cum_r2=-26.4162, val_cum_pearson=-0.0027:  40%|████      | 399/996 [00:10<00:22, 26.62it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.223e+00, tolerance: 4.535e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 403, train_r2=0.0197, val_r2=0.0622, val_cum_r2=-26.3851, val_cum_pearson=-0.0027:  40%|████      | 399/996 [00:10<00:22, 26.62it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.224e+00, tolerance: 4.537e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 404, train_r2=0.0196, val_r2=-0.0117, val_cum_r2=-26.3686, val_cum_pearson=-0.0026:  40%|████      | 399/996 [00:10<00:22, 26.62it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.227e+00, tolerance: 4.543e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 405, train_r2=0.0197, val_r2=-2.2599, val_cum_r2=-26.3445, val_cum_pearson=-0.0027:  40%|████      | 403/996 [00:10<00:21, 27.58it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+00, tolerance: 4.545e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 406, train_r2=0.0197, val_r2=-2.0736, val_cum_r2=-26.3284, val_cum_pearson=-0.0027:  40%|████      | 403/996 [00:10<00:21, 27.58it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.230e+00, tolerance: 4.550e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 407, train_r2=0.0198, val_r2=0.0919, val_cum_r2=-26.3265, val_cum_pearson=-0.0027:  40%|████      | 403/996 [00:10<00:21, 27.58it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+00, tolerance: 4.552e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 408, train_r2=0.0197, val_r2=-0.3782, val_cum_r2=-26.3123, val_cum_pearson=-0.0027:  41%|████      | 406/996 [00:10<00:21, 27.16it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.231e+00, tolerance: 4.553e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 409, train_r2=0.0198, val_r2=-0.4939, val_cum_r2=-26.2963, val_cum_pearson=-0.0027:  41%|████      | 406/996 [00:10<00:21, 27.16it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+00, tolerance: 4.555e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 410, train_r2=0.0197, val_r2=-3.6489, val_cum_r2=-26.2926, val_cum_pearson=-0.0027:  41%|████      | 406/996 [00:10<00:21, 27.16it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.234e+00, tolerance: 4.558e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 411, train_r2=0.0197, val_r2=-2.9203, val_cum_r2=-26.2783, val_cum_pearson=-0.0027:  41%|████      | 409/996 [00:10<00:21, 27.20it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.235e+00, tolerance: 4.559e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 412, train_r2=0.0196, val_r2=-1.1277, val_cum_r2=-26.2741, val_cum_pearson=-0.0027:  41%|████      | 409/996 [00:10<00:21, 27.20it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.236e+00, tolerance: 4.561e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 413, train_r2=0.0195, val_r2=-0.8861, val_cum_r2=-26.2655, val_cum_pearson=-0.0027:  41%|████      | 409/996 [00:10<00:21, 27.20it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.237e+00, tolerance: 4.562e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 414, train_r2=0.0194, val_r2=-0.6228, val_cum_r2=-26.2602, val_cum_pearson=-0.0027:  41%|████▏     | 412/996 [00:10<00:22, 26.20it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.237e+00, tolerance: 4.563e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 415, train_r2=0.0194, val_r2=-0.0850, val_cum_r2=-26.2581, val_cum_pearson=-0.0027:  41%|████▏     | 412/996 [00:10<00:22, 26.20it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.238e+00, tolerance: 4.564e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 416, train_r2=0.0194, val_r2=-4.0812, val_cum_r2=-26.2538, val_cum_pearson=-0.0027:  41%|████▏     | 412/996 [00:10<00:22, 26.20it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.238e+00, tolerance: 4.565e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 417, train_r2=0.0194, val_r2=-47.4887, val_cum_r2=-26.1840, val_cum_pearson=-0.0028:  42%|████▏     | 415/996 [00:10<00:22, 25.49it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.238e+00, tolerance: 4.565e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 418, train_r2=0.0194, val_r2=-12.2820, val_cum_r2=-26.1355, val_cum_pearson=-0.0028:  42%|████▏     | 415/996 [00:10<00:22, 25.49it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.245e+00, tolerance: 4.578e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 419, train_r2=0.0193, val_r2=-22.3819, val_cum_r2=-26.1329, val_cum_pearson=-0.0028:  42%|████▏     | 415/996 [00:10<00:22, 25.49it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.249e+00, tolerance: 4.586e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 420, train_r2=0.0191, val_r2=-0.4869, val_cum_r2=-26.1303, val_cum_pearson=-0.0028:  42%|████▏     | 418/996 [00:10<00:23, 25.03it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.250e+00, tolerance: 4.587e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 421, train_r2=0.0190, val_r2=-1.0204, val_cum_r2=-26.1224, val_cum_pearson=-0.0028:  42%|████▏     | 418/996 [00:10<00:23, 25.03it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.250e+00, tolerance: 4.587e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 422, train_r2=0.0191, val_r2=0.0488, val_cum_r2=-26.1043, val_cum_pearson=-0.0028:  42%|████▏     | 418/996 [00:10<00:23, 25.03it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.250e+00, tolerance: 4.588e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 423, train_r2=0.0192, val_r2=-0.8697, val_cum_r2=-26.0946, val_cum_pearson=-0.0028:  42%|████▏     | 421/996 [00:11<00:23, 24.64it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.252e+00, tolerance: 4.592e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 424, train_r2=0.0193, val_r2=-0.1940, val_cum_r2=-26.0927, val_cum_pearson=-0.0027:  42%|████▏     | 421/996 [00:11<00:23, 24.64it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.252e+00, tolerance: 4.593e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 425, train_r2=0.0193, val_r2=-7.6204, val_cum_r2=-26.0611, val_cum_pearson=-0.0028:  42%|████▏     | 421/996 [00:11<00:23, 24.64it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.252e+00, tolerance: 4.594e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 426, train_r2=0.0193, val_r2=-2.2577, val_cum_r2=-26.0500, val_cum_pearson=-0.0028:  43%|████▎     | 424/996 [00:11<00:23, 24.48it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.255e+00, tolerance: 4.599e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 427, train_r2=0.0192, val_r2=-0.3076, val_cum_r2=-26.0466, val_cum_pearson=-0.0028:  43%|████▎     | 424/996 [00:11<00:23, 24.48it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.257e+00, tolerance: 4.601e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 428, train_r2=0.0191, val_r2=-0.2828, val_cum_r2=-26.0370, val_cum_pearson=-0.0028:  43%|████▎     | 424/996 [00:11<00:23, 24.48it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.257e+00, tolerance: 4.602e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 429, train_r2=0.0192, val_r2=-2.4102, val_cum_r2=-26.0281, val_cum_pearson=-0.0028:  43%|████▎     | 427/996 [00:11<00:23, 24.31it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.257e+00, tolerance: 4.603e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 430, train_r2=0.0192, val_r2=-1.2006, val_cum_r2=-25.9737, val_cum_pearson=-0.0027:  43%|████▎     | 427/996 [00:11<00:23, 24.31it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.258e+00, tolerance: 4.605e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 431, train_r2=0.0193, val_r2=-1.0354, val_cum_r2=-25.9295, val_cum_pearson=-0.0027:  43%|████▎     | 427/996 [00:11<00:23, 24.31it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.263e+00, tolerance: 4.614e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 432, train_r2=0.0192, val_r2=-0.1173, val_cum_r2=-25.9247, val_cum_pearson=-0.0027:  43%|████▎     | 430/996 [00:11<00:23, 24.16it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.267e+00, tolerance: 4.622e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 433, train_r2=0.0192, val_r2=-1.3531, val_cum_r2=-25.9157, val_cum_pearson=-0.0027:  43%|████▎     | 430/996 [00:11<00:23, 24.16it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.267e+00, tolerance: 4.623e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 434, train_r2=0.0192, val_r2=-0.3793, val_cum_r2=-25.9098, val_cum_pearson=-0.0027:  43%|████▎     | 430/996 [00:11<00:23, 24.16it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.268e+00, tolerance: 4.625e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 435, train_r2=0.0192, val_r2=-11.7902, val_cum_r2=-25.9071, val_cum_pearson=-0.0027:  43%|████▎     | 433/996 [00:11<00:23, 24.08it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.268e+00, tolerance: 4.626e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 436, train_r2=0.0192, val_r2=-0.1259, val_cum_r2=-25.9030, val_cum_pearson=-0.0027:  43%|████▎     | 433/996 [00:11<00:23, 24.08it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+00, tolerance: 4.626e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 437, train_r2=0.0192, val_r2=-1.3917, val_cum_r2=-25.8995, val_cum_pearson=-0.0027:  43%|████▎     | 433/996 [00:11<00:23, 24.08it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+00, tolerance: 4.627e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 438, train_r2=0.0192, val_r2=-2.8936, val_cum_r2=-25.8955, val_cum_pearson=-0.0027:  44%|████▍     | 436/996 [00:11<00:23, 23.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.269e+00, tolerance: 4.628e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 439, train_r2=0.0192, val_r2=-14.9094, val_cum_r2=-25.8926, val_cum_pearson=-0.0027:  44%|████▍     | 436/996 [00:11<00:23, 23.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.270e+00, tolerance: 4.628e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 440, train_r2=0.0192, val_r2=-0.3199, val_cum_r2=-25.8899, val_cum_pearson=-0.0027:  44%|████▍     | 436/996 [00:11<00:23, 23.90it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.270e+00, tolerance: 4.629e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 441, train_r2=0.0191, val_r2=-3.9556, val_cum_r2=-25.8753, val_cum_pearson=-0.0027:  44%|████▍     | 439/996 [00:11<00:23, 24.10it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.270e+00, tolerance: 4.629e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 442, train_r2=0.0191, val_r2=-0.4792, val_cum_r2=-25.8546, val_cum_pearson=-0.0027:  44%|████▍     | 439/996 [00:11<00:23, 24.10it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.272e+00, tolerance: 4.632e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 443, train_r2=0.0191, val_r2=0.0682, val_cum_r2=-25.8456, val_cum_pearson=-0.0027:  44%|████▍     | 439/996 [00:11<00:23, 24.10it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.273e+00, tolerance: 4.636e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 444, train_r2=0.0192, val_r2=-5.1115, val_cum_r2=-25.8378, val_cum_pearson=-0.0027:  44%|████▍     | 442/996 [00:11<00:23, 23.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.274e+00, tolerance: 4.637e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 445, train_r2=0.0192, val_r2=-0.4985, val_cum_r2=-25.8234, val_cum_pearson=-0.0027:  44%|████▍     | 442/996 [00:11<00:23, 23.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.275e+00, tolerance: 4.639e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 446, train_r2=0.0192, val_r2=0.0259, val_cum_r2=-25.8118, val_cum_pearson=-0.0027:  44%|████▍     | 442/996 [00:11<00:23, 23.84it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.276e+00, tolerance: 4.641e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 447, train_r2=0.0191, val_r2=-1.5383, val_cum_r2=-25.8089, val_cum_pearson=-0.0027:  45%|████▍     | 445/996 [00:12<00:23, 23.89it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.277e+00, tolerance: 4.643e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 448, train_r2=0.0191, val_r2=-0.0731, val_cum_r2=-25.8038, val_cum_pearson=-0.0027:  45%|████▍     | 445/996 [00:12<00:23, 23.89it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.278e+00, tolerance: 4.644e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 449, train_r2=0.0190, val_r2=0.1469, val_cum_r2=-25.7940, val_cum_pearson=-0.0027:  45%|████▍     | 445/996 [00:12<00:23, 23.89it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.278e+00, tolerance: 4.645e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 450, train_r2=0.0190, val_r2=-2.0786, val_cum_r2=-25.7912, val_cum_pearson=-0.0027:  45%|████▍     | 448/996 [00:12<00:22, 23.92it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.279e+00, tolerance: 4.647e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 451, train_r2=0.0191, val_r2=0.1877, val_cum_r2=-25.7883, val_cum_pearson=-0.0027:  45%|████▍     | 448/996 [00:12<00:22, 23.92it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.279e+00, tolerance: 4.647e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 452, train_r2=0.0191, val_r2=-1.1763, val_cum_r2=-25.7859, val_cum_pearson=-0.0027:  45%|████▍     | 448/996 [00:12<00:22, 23.92it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.279e+00, tolerance: 4.648e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 453, train_r2=0.0191, val_r2=0.2195, val_cum_r2=-25.7852, val_cum_pearson=-0.0027:  45%|████▌     | 451/996 [00:12<00:23, 23.08it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e+00, tolerance: 4.648e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 454, train_r2=0.0191, val_r2=-4.0773, val_cum_r2=-25.7756, val_cum_pearson=-0.0027:  45%|████▌     | 451/996 [00:12<00:23, 23.08it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e+00, tolerance: 4.648e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 455, train_r2=0.0191, val_r2=-2.1438, val_cum_r2=-25.7750, val_cum_pearson=-0.0027:  45%|████▌     | 451/996 [00:12<00:23, 23.08it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e+00, tolerance: 4.650e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 456, train_r2=0.0192, val_r2=-0.0450, val_cum_r2=-25.7726, val_cum_pearson=-0.0027:  46%|████▌     | 454/996 [00:12<00:23, 23.22it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e+00, tolerance: 4.650e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 457, train_r2=0.0191, val_r2=-0.5984, val_cum_r2=-25.7718, val_cum_pearson=-0.0027:  46%|████▌     | 454/996 [00:12<00:23, 23.22it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.281e+00, tolerance: 4.650e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 458, train_r2=0.0191, val_r2=-0.0218, val_cum_r2=-25.7547, val_cum_pearson=-0.0027:  46%|████▌     | 454/996 [00:12<00:23, 23.22it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.281e+00, tolerance: 4.650e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 459, train_r2=0.0191, val_r2=-0.4419, val_cum_r2=-25.7525, val_cum_pearson=-0.0027:  46%|████▌     | 457/996 [00:12<00:25, 21.12it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.282e+00, tolerance: 4.654e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 460, train_r2=0.0192, val_r2=-0.0726, val_cum_r2=-25.7189, val_cum_pearson=-0.0027:  46%|████▌     | 457/996 [00:12<00:25, 21.12it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.282e+00, tolerance: 4.654e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 461, train_r2=0.0191, val_r2=-0.3879, val_cum_r2=-25.7134, val_cum_pearson=-0.0027:  46%|████▌     | 457/996 [00:12<00:25, 21.12it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.285e+00, tolerance: 4.660e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 462, train_r2=0.0192, val_r2=0.6086, val_cum_r2=-25.7116, val_cum_pearson=-0.0027:  46%|████▌     | 460/996 [00:12<00:26, 20.50it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.286e+00, tolerance: 4.661e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 463, train_r2=0.0191, val_r2=-0.5607, val_cum_r2=-25.6895, val_cum_pearson=-0.0027:  46%|████▌     | 460/996 [00:12<00:26, 20.50it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.286e+00, tolerance: 4.661e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 464, train_r2=0.0192, val_r2=-0.2558, val_cum_r2=-25.6701, val_cum_pearson=-0.0027:  46%|████▌     | 460/996 [00:12<00:26, 20.50it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.288e+00, tolerance: 4.665e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 465, train_r2=0.0191, val_r2=0.3793, val_cum_r2=-25.6633, val_cum_pearson=-0.0027:  46%|████▋     | 463/996 [00:12<00:25, 20.66it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.290e+00, tolerance: 4.669e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 466, train_r2=0.0190, val_r2=-1.5301, val_cum_r2=-25.6400, val_cum_pearson=-0.0026:  46%|████▋     | 463/996 [00:12<00:25, 20.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.290e+00, tolerance: 4.670e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 467, train_r2=0.0191, val_r2=-0.4425, val_cum_r2=-25.6363, val_cum_pearson=-0.0026:  46%|████▋     | 463/996 [00:12<00:25, 20.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.293e+00, tolerance: 4.674e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 468, train_r2=0.0191, val_r2=-1.5284, val_cum_r2=-25.6337, val_cum_pearson=-0.0027:  47%|████▋     | 466/996 [00:13<00:25, 20.86it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.293e+00, tolerance: 4.675e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 469, train_r2=0.0190, val_r2=-1.0342, val_cum_r2=-25.6201, val_cum_pearson=-0.0027:  47%|████▋     | 466/996 [00:13<00:25, 20.86it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.293e+00, tolerance: 4.675e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 470, train_r2=0.0190, val_r2=-4.8371, val_cum_r2=-25.5426, val_cum_pearson=-0.0027:  47%|████▋     | 466/996 [00:13<00:25, 20.86it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.295e+00, tolerance: 4.678e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 471, train_r2=0.0188, val_r2=-0.7963, val_cum_r2=-25.5003, val_cum_pearson=-0.0027:  47%|████▋     | 469/996 [00:13<00:24, 21.68it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.302e+00, tolerance: 4.692e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 472, train_r2=0.0189, val_r2=0.3042, val_cum_r2=-25.4985, val_cum_pearson=-0.0027:  47%|████▋     | 469/996 [00:13<00:24, 21.68it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.305e+00, tolerance: 4.700e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 473, train_r2=0.0189, val_r2=-0.0946, val_cum_r2=-25.4959, val_cum_pearson=-0.0027:  47%|████▋     | 469/996 [00:13<00:24, 21.68it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.305e+00, tolerance: 4.700e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 474, train_r2=0.0190, val_r2=-0.2600, val_cum_r2=-25.4934, val_cum_pearson=-0.0027:  47%|████▋     | 472/996 [00:13<00:23, 22.33it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.306e+00, tolerance: 4.701e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 475, train_r2=0.0190, val_r2=-15.4045, val_cum_r2=-25.4493, val_cum_pearson=-0.0027:  47%|████▋     | 472/996 [00:13<00:23, 22.33it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.306e+00, tolerance: 4.701e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 476, train_r2=0.0190, val_r2=-13.1685, val_cum_r2=-25.4187, val_cum_pearson=-0.0027:  47%|████▋     | 472/996 [00:13<00:23, 22.33it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e+00, tolerance: 4.709e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 477, train_r2=0.0189, val_r2=-0.1838, val_cum_r2=-25.4097, val_cum_pearson=-0.0027:  48%|████▊     | 475/996 [00:13<00:23, 22.43it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.313e+00, tolerance: 4.715e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 478, train_r2=0.0188, val_r2=-0.5206, val_cum_r2=-25.4012, val_cum_pearson=-0.0027:  48%|████▊     | 475/996 [00:13<00:23, 22.43it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.314e+00, tolerance: 4.717e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 479, train_r2=0.0188, val_r2=-3.7670, val_cum_r2=-25.3990, val_cum_pearson=-0.0027:  48%|████▊     | 475/996 [00:13<00:23, 22.43it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.315e+00, tolerance: 4.718e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 480, train_r2=0.0188, val_r2=-0.0376, val_cum_r2=-25.3952, val_cum_pearson=-0.0027:  48%|████▊     | 478/996 [00:13<00:23, 22.09it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.315e+00, tolerance: 4.719e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 481, train_r2=0.0187, val_r2=-0.5726, val_cum_r2=-25.3871, val_cum_pearson=-0.0027:  48%|████▊     | 478/996 [00:13<00:23, 22.09it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.315e+00, tolerance: 4.719e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 482, train_r2=0.0188, val_r2=-0.0999, val_cum_r2=-25.3787, val_cum_pearson=-0.0027:  48%|████▊     | 478/996 [00:13<00:23, 22.09it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.316e+00, tolerance: 4.721e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 483, train_r2=0.0187, val_r2=-0.4326, val_cum_r2=-25.3723, val_cum_pearson=-0.0027:  48%|████▊     | 481/996 [00:13<00:22, 22.63it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.317e+00, tolerance: 4.722e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 484, train_r2=0.0187, val_r2=-1.9901, val_cum_r2=-25.3587, val_cum_pearson=-0.0027:  48%|████▊     | 481/996 [00:13<00:22, 22.63it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.318e+00, tolerance: 4.724e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 485, train_r2=0.0186, val_r2=-3.3513, val_cum_r2=-25.3504, val_cum_pearson=-0.0028:  48%|████▊     | 481/996 [00:13<00:22, 22.63it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.319e+00, tolerance: 4.726e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 486, train_r2=0.0186, val_r2=-0.5961, val_cum_r2=-25.3430, val_cum_pearson=-0.0028:  49%|████▊     | 484/996 [00:13<00:24, 20.78it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.320e+00, tolerance: 4.728e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 487, train_r2=0.0185, val_r2=0.3839, val_cum_r2=-25.3417, val_cum_pearson=-0.0028:  49%|████▊     | 484/996 [00:13<00:24, 20.78it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.321e+00, tolerance: 4.729e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 488, train_r2=0.0185, val_r2=-0.1059, val_cum_r2=-25.3353, val_cum_pearson=-0.0028:  49%|████▊     | 484/996 [00:13<00:24, 20.78it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.321e+00, tolerance: 4.729e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 489, train_r2=0.0185, val_r2=-3.2349, val_cum_r2=-25.3316, val_cum_pearson=-0.0027:  49%|████▉     | 487/996 [00:13<00:23, 21.70it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.321e+00, tolerance: 4.730e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 490, train_r2=0.0185, val_r2=-3.6369, val_cum_r2=-25.3251, val_cum_pearson=-0.0027:  49%|████▉     | 487/996 [00:14<00:23, 21.70it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.322e+00, tolerance: 4.731e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 491, train_r2=0.0185, val_r2=-1.5486, val_cum_r2=-25.3198, val_cum_pearson=-0.0027:  49%|████▉     | 487/996 [00:14<00:23, 21.70it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.322e+00, tolerance: 4.732e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 492, train_r2=0.0185, val_r2=-0.2023, val_cum_r2=-25.3062, val_cum_pearson=-0.0027:  49%|████▉     | 490/996 [00:14<00:23, 21.56it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.323e+00, tolerance: 4.733e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 493, train_r2=0.0185, val_r2=-0.0224, val_cum_r2=-25.2954, val_cum_pearson=-0.0027:  49%|████▉     | 490/996 [00:14<00:23, 21.56it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.324e+00, tolerance: 4.736e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 494, train_r2=0.0185, val_r2=-0.7902, val_cum_r2=-25.2943, val_cum_pearson=-0.0027:  49%|████▉     | 490/996 [00:14<00:23, 21.56it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.325e+00, tolerance: 4.738e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 495, train_r2=0.0185, val_r2=-2.4577, val_cum_r2=-25.2932, val_cum_pearson=-0.0027:  49%|████▉     | 493/996 [00:14<00:22, 21.89it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.325e+00, tolerance: 4.738e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 496, train_r2=0.0185, val_r2=-20.0728, val_cum_r2=-25.2829, val_cum_pearson=-0.0027:  49%|████▉     | 493/996 [00:14<00:22, 21.89it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.325e+00, tolerance: 4.738e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 497, train_r2=0.0185, val_r2=-0.1741, val_cum_r2=-25.2611, val_cum_pearson=-0.0027:  49%|████▉     | 493/996 [00:14<00:22, 21.89it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.326e+00, tolerance: 4.740e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 498, train_r2=0.0184, val_r2=-0.0257, val_cum_r2=-25.2484, val_cum_pearson=-0.0027:  50%|████▉     | 496/996 [00:14<00:23, 21.44it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.329e+00, tolerance: 4.744e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 499, train_r2=0.0184, val_r2=-0.7149, val_cum_r2=-25.2291, val_cum_pearson=-0.0028:  50%|████▉     | 496/996 [00:14<00:23, 21.44it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.330e+00, tolerance: 4.747e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 500, train_r2=0.0184, val_r2=0.1543, val_cum_r2=-25.2202, val_cum_pearson=-0.0028:  50%|████▉     | 496/996 [00:14<00:23, 21.44it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.332e+00, tolerance: 4.750e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 501, train_r2=0.0183, val_r2=-0.6548, val_cum_r2=-25.1936, val_cum_pearson=-0.0027:  50%|█████     | 499/996 [00:14<00:23, 20.71it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.332e+00, tolerance: 4.752e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 502, train_r2=0.0183, val_r2=0.1319, val_cum_r2=-25.1916, val_cum_pearson=-0.0027:  50%|█████     | 499/996 [00:14<00:23, 20.71it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.335e+00, tolerance: 4.757e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 503, train_r2=0.0184, val_r2=-0.5334, val_cum_r2=-25.1895, val_cum_pearson=-0.0027:  50%|█████     | 499/996 [00:14<00:23, 20.71it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.335e+00, tolerance: 4.757e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 504, train_r2=0.0184, val_r2=-0.4464, val_cum_r2=-25.1855, val_cum_pearson=-0.0027:  50%|█████     | 502/996 [00:14<00:23, 20.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.335e+00, tolerance: 4.758e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 505, train_r2=0.0183, val_r2=0.0375, val_cum_r2=-25.1850, val_cum_pearson=-0.0027:  50%|█████     | 502/996 [00:14<00:23, 20.90it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.336e+00, tolerance: 4.759e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 506, train_r2=0.0183, val_r2=-0.0492, val_cum_r2=-25.1798, val_cum_pearson=-0.0027:  50%|█████     | 502/996 [00:14<00:23, 20.90it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.336e+00, tolerance: 4.759e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 507, train_r2=0.0183, val_r2=-0.2119, val_cum_r2=-25.1767, val_cum_pearson=-0.0027:  51%|█████     | 505/996 [00:14<00:24, 20.36it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.336e+00, tolerance: 4.760e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 508, train_r2=0.0184, val_r2=0.0514, val_cum_r2=-25.1748, val_cum_pearson=-0.0027:  51%|█████     | 505/996 [00:14<00:24, 20.36it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.336e+00, tolerance: 4.760e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 509, train_r2=0.0183, val_r2=-0.0929, val_cum_r2=-25.1696, val_cum_pearson=-0.0027:  51%|█████     | 505/996 [00:14<00:24, 20.36it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.337e+00, tolerance: 4.761e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 510, train_r2=0.0183, val_r2=-0.0591, val_cum_r2=-25.1669, val_cum_pearson=-0.0027:  51%|█████     | 508/996 [00:14<00:24, 20.00it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.337e+00, tolerance: 4.761e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 511, train_r2=0.0183, val_r2=-0.0491, val_cum_r2=-25.1484, val_cum_pearson=-0.0027:  51%|█████     | 508/996 [00:15<00:24, 20.00it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.337e+00, tolerance: 4.762e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 512, train_r2=0.0183, val_r2=-0.2829, val_cum_r2=-25.1451, val_cum_pearson=-0.0027:  51%|█████     | 508/996 [00:15<00:24, 20.00it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.339e+00, tolerance: 4.765e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 513, train_r2=0.0184, val_r2=-0.1714, val_cum_r2=-25.1423, val_cum_pearson=-0.0027:  51%|█████▏    | 511/996 [00:15<00:23, 21.03it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.339e+00, tolerance: 4.766e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 514, train_r2=0.0184, val_r2=-6.4786, val_cum_r2=-25.1342, val_cum_pearson=-0.0027:  51%|█████▏    | 511/996 [00:15<00:23, 21.03it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.339e+00, tolerance: 4.767e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 515, train_r2=0.0184, val_r2=-0.1113, val_cum_r2=-25.1254, val_cum_pearson=-0.0027:  51%|█████▏    | 511/996 [00:15<00:23, 21.03it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.340e+00, tolerance: 4.768e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 516, train_r2=0.0184, val_r2=-3.5447, val_cum_r2=-25.1176, val_cum_pearson=-0.0027:  52%|█████▏    | 514/996 [00:15<00:23, 20.45it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.341e+00, tolerance: 4.770e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 517, train_r2=0.0184, val_r2=-1.9926, val_cum_r2=-25.1130, val_cum_pearson=-0.0027:  52%|█████▏    | 514/996 [00:15<00:23, 20.45it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.342e+00, tolerance: 4.771e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 518, train_r2=0.0185, val_r2=-1.4899, val_cum_r2=-25.1113, val_cum_pearson=-0.0027:  52%|█████▏    | 514/996 [00:15<00:23, 20.45it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.342e+00, tolerance: 4.772e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 519, train_r2=0.0184, val_r2=-1.2926, val_cum_r2=-25.0880, val_cum_pearson=-0.0027:  52%|█████▏    | 517/996 [00:15<00:23, 20.58it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.342e+00, tolerance: 4.772e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 520, train_r2=0.0184, val_r2=-1.7954, val_cum_r2=-25.0609, val_cum_pearson=-0.0027:  52%|█████▏    | 517/996 [00:15<00:23, 20.58it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.344e+00, tolerance: 4.777e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 521, train_r2=0.0185, val_r2=-1.4813, val_cum_r2=-25.0564, val_cum_pearson=-0.0027:  52%|█████▏    | 517/996 [00:15<00:23, 20.58it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.347e+00, tolerance: 4.782e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 522, train_r2=0.0186, val_r2=-0.8597, val_cum_r2=-25.0509, val_cum_pearson=-0.0026:  52%|█████▏    | 520/996 [00:15<00:22, 20.95it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.347e+00, tolerance: 4.783e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 523, train_r2=0.0186, val_r2=-0.0985, val_cum_r2=-25.0482, val_cum_pearson=-0.0026:  52%|█████▏    | 520/996 [00:15<00:22, 20.95it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.347e+00, tolerance: 4.784e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 524, train_r2=0.0186, val_r2=-0.7663, val_cum_r2=-25.0390, val_cum_pearson=-0.0027:  52%|█████▏    | 520/996 [00:15<00:22, 20.95it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.348e+00, tolerance: 4.784e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 525, train_r2=0.0186, val_r2=-0.4195, val_cum_r2=-25.0313, val_cum_pearson=-0.0027:  53%|█████▎    | 523/996 [00:15<00:22, 21.07it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.349e+00, tolerance: 4.786e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 526, train_r2=0.0186, val_r2=-0.3283, val_cum_r2=-25.0293, val_cum_pearson=-0.0027:  53%|█████▎    | 523/996 [00:15<00:22, 21.07it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.349e+00, tolerance: 4.788e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 527, train_r2=0.0186, val_r2=-1.8989, val_cum_r2=-25.0279, val_cum_pearson=-0.0027:  53%|█████▎    | 523/996 [00:15<00:22, 21.07it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.350e+00, tolerance: 4.788e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 528, train_r2=0.0186, val_r2=0.2228, val_cum_r2=-25.0272, val_cum_pearson=-0.0027:  53%|█████▎    | 526/996 [00:15<00:22, 20.48it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.350e+00, tolerance: 4.788e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 529, train_r2=0.0185, val_r2=-0.2523, val_cum_r2=-25.0208, val_cum_pearson=-0.0026:  53%|█████▎    | 526/996 [00:15<00:22, 20.48it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.350e+00, tolerance: 4.788e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 530, train_r2=0.0186, val_r2=-0.5087, val_cum_r2=-25.0157, val_cum_pearson=-0.0026:  53%|█████▎    | 526/996 [00:15<00:22, 20.48it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.350e+00, tolerance: 4.790e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 531, train_r2=0.0186, val_r2=-0.0442, val_cum_r2=-25.0143, val_cum_pearson=-0.0026:  53%|█████▎    | 529/996 [00:15<00:22, 20.73it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.351e+00, tolerance: 4.791e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 532, train_r2=0.0186, val_r2=-1.0111, val_cum_r2=-25.0044, val_cum_pearson=-0.0027:  53%|█████▎    | 529/996 [00:16<00:22, 20.73it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.351e+00, tolerance: 4.791e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 533, train_r2=0.0186, val_r2=0.1008, val_cum_r2=-24.9945, val_cum_pearson=-0.0026:  53%|█████▎    | 529/996 [00:16<00:22, 20.73it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.352e+00, tolerance: 4.793e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 534, train_r2=0.0186, val_r2=-0.8283, val_cum_r2=-24.9692, val_cum_pearson=-0.0026:  53%|█████▎    | 532/996 [00:16<00:22, 20.91it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.353e+00, tolerance: 4.795e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 535, train_r2=0.0186, val_r2=-0.5082, val_cum_r2=-24.9626, val_cum_pearson=-0.0026:  53%|█████▎    | 532/996 [00:16<00:22, 20.91it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.355e+00, tolerance: 4.799e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 536, train_r2=0.0187, val_r2=0.0627, val_cum_r2=-24.9587, val_cum_pearson=-0.0026:  53%|█████▎    | 532/996 [00:16<00:22, 20.91it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.356e+00, tolerance: 4.801e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 537, train_r2=0.0186, val_r2=-0.5078, val_cum_r2=-24.9484, val_cum_pearson=-0.0026:  54%|█████▎    | 535/996 [00:16<00:21, 21.74it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.356e+00, tolerance: 4.801e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 538, train_r2=0.0186, val_r2=-0.1767, val_cum_r2=-24.9443, val_cum_pearson=-0.0026:  54%|█████▎    | 535/996 [00:16<00:21, 21.74it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.357e+00, tolerance: 4.803e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 539, train_r2=0.0186, val_r2=0.0321, val_cum_r2=-24.9201, val_cum_pearson=-0.0026:  54%|█████▎    | 535/996 [00:16<00:21, 21.74it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.357e+00, tolerance: 4.804e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 540, train_r2=0.0186, val_r2=-3.6809, val_cum_r2=-24.8203, val_cum_pearson=-0.0026:  54%|█████▍    | 538/996 [00:16<00:22, 20.38it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.359e+00, tolerance: 4.809e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 541, train_r2=0.0187, val_r2=-2.2962, val_cum_r2=-24.6961, val_cum_pearson=-0.0025:  54%|█████▍    | 538/996 [00:16<00:22, 20.38it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.369e+00, tolerance: 4.828e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 542, train_r2=0.0186, val_r2=-2.5260, val_cum_r2=-24.6852, val_cum_pearson=-0.0026:  54%|█████▍    | 538/996 [00:16<00:22, 20.38it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.381e+00, tolerance: 4.852e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 543, train_r2=0.0184, val_r2=0.0255, val_cum_r2=-24.6740, val_cum_pearson=-0.0026:  54%|█████▍    | 541/996 [00:16<00:21, 20.75it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.383e+00, tolerance: 4.854e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 544, train_r2=0.0182, val_r2=-0.1123, val_cum_r2=-24.6497, val_cum_pearson=-0.0025:  54%|█████▍    | 541/996 [00:16<00:21, 20.75it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.384e+00, tolerance: 4.856e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 545, train_r2=0.0182, val_r2=-1.8876, val_cum_r2=-24.6362, val_cum_pearson=-0.0026:  54%|█████▍    | 541/996 [00:16<00:21, 20.75it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.386e+00, tolerance: 4.861e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 546, train_r2=0.0183, val_r2=-0.7822, val_cum_r2=-24.6244, val_cum_pearson=-0.0026:  55%|█████▍    | 544/996 [00:16<00:21, 21.44it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.388e+00, tolerance: 4.864e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 547, train_r2=0.0182, val_r2=-7.2983, val_cum_r2=-24.6140, val_cum_pearson=-0.0026:  55%|█████▍    | 544/996 [00:16<00:21, 21.44it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.389e+00, tolerance: 4.866e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 548, train_r2=0.0180, val_r2=-0.2016, val_cum_r2=-24.6030, val_cum_pearson=-0.0026:  55%|█████▍    | 544/996 [00:16<00:21, 21.44it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.390e+00, tolerance: 4.868e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 549, train_r2=0.0180, val_r2=-0.3674, val_cum_r2=-24.5943, val_cum_pearson=-0.0026:  55%|█████▍    | 547/996 [00:16<00:21, 20.50it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.392e+00, tolerance: 4.871e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 550, train_r2=0.0179, val_r2=0.0519, val_cum_r2=-24.5900, val_cum_pearson=-0.0026:  55%|█████▍    | 547/996 [00:16<00:21, 20.50it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.393e+00, tolerance: 4.872e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 551, train_r2=0.0179, val_r2=-2.1968, val_cum_r2=-24.5839, val_cum_pearson=-0.0026:  55%|█████▍    | 547/996 [00:16<00:21, 20.50it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.393e+00, tolerance: 4.873e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 552, train_r2=0.0179, val_r2=-3.1459, val_cum_r2=-24.5305, val_cum_pearson=-0.0026:  55%|█████▌    | 550/996 [00:17<00:22, 20.08it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.394e+00, tolerance: 4.874e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 553, train_r2=0.0179, val_r2=-5.9874, val_cum_r2=-24.4986, val_cum_pearson=-0.0026:  55%|█████▌    | 550/996 [00:17<00:22, 20.08it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.399e+00, tolerance: 4.885e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 554, train_r2=0.0179, val_r2=0.2127, val_cum_r2=-24.4922, val_cum_pearson=-0.0026:  55%|█████▌    | 550/996 [00:17<00:22, 20.08it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.402e+00, tolerance: 4.891e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 555, train_r2=0.0178, val_r2=-1.1222, val_cum_r2=-24.4873, val_cum_pearson=-0.0026:  56%|█████▌    | 553/996 [00:17<00:23, 19.21it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.403e+00, tolerance: 4.893e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 556, train_r2=0.0179, val_r2=-1.3958, val_cum_r2=-24.4848, val_cum_pearson=-0.0026:  56%|█████▌    | 553/996 [00:17<00:23, 19.21it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.403e+00, tolerance: 4.894e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 557, train_r2=0.0179, val_r2=-0.8039, val_cum_r2=-24.4810, val_cum_pearson=-0.0026:  56%|█████▌    | 555/996 [00:17<00:23, 18.97it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.403e+00, tolerance: 4.894e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 558, train_r2=0.0179, val_r2=-1.6443, val_cum_r2=-24.4419, val_cum_pearson=-0.0026:  56%|█████▌    | 555/996 [00:17<00:23, 18.97it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.404e+00, tolerance: 4.895e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 559, train_r2=0.0179, val_r2=-1.1398, val_cum_r2=-24.4142, val_cum_pearson=-0.0026:  56%|█████▌    | 555/996 [00:17<00:23, 18.97it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.408e+00, tolerance: 4.903e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 560, train_r2=0.0178, val_r2=-5.2589, val_cum_r2=-24.3943, val_cum_pearson=-0.0026:  56%|█████▌    | 558/996 [00:17<00:22, 19.67it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.411e+00, tolerance: 4.908e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 561, train_r2=0.0177, val_r2=-0.2494, val_cum_r2=-24.3843, val_cum_pearson=-0.0026:  56%|█████▌    | 558/996 [00:17<00:22, 19.67it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.413e+00, tolerance: 4.912e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 562, train_r2=0.0173, val_r2=-1.8833, val_cum_r2=-24.3130, val_cum_pearson=-0.0026:  56%|█████▌    | 560/996 [00:17<00:22, 19.33it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.415e+00, tolerance: 4.914e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 563, train_r2=0.0172, val_r2=-0.8409, val_cum_r2=-24.3008, val_cum_pearson=-0.0026:  56%|█████▌    | 560/996 [00:17<00:22, 19.33it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.421e+00, tolerance: 4.929e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 564, train_r2=0.0175, val_r2=-0.3188, val_cum_r2=-24.2927, val_cum_pearson=-0.0026:  56%|█████▌    | 560/996 [00:17<00:22, 19.33it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.422e+00, tolerance: 4.931e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 565, train_r2=0.0174, val_r2=0.1797, val_cum_r2=-24.2826, val_cum_pearson=-0.0026:  57%|█████▋    | 563/996 [00:17<00:21, 19.96it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.423e+00, tolerance: 4.933e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 566, train_r2=0.0175, val_r2=-3.7125, val_cum_r2=-24.2659, val_cum_pearson=-0.0026:  57%|█████▋    | 563/996 [00:17<00:21, 19.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.424e+00, tolerance: 4.935e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 567, train_r2=0.0175, val_r2=-0.5533, val_cum_r2=-24.2378, val_cum_pearson=-0.0026:  57%|█████▋    | 563/996 [00:17<00:21, 19.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.426e+00, tolerance: 4.938e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 568, train_r2=0.0175, val_r2=0.1724, val_cum_r2=-24.2227, val_cum_pearson=-0.0026:  57%|█████▋    | 566/996 [00:17<00:21, 20.36it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.428e+00, tolerance: 4.944e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 569, train_r2=0.0177, val_r2=-0.0912, val_cum_r2=-24.2183, val_cum_pearson=-0.0026:  57%|█████▋    | 566/996 [00:17<00:21, 20.36it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.429e+00, tolerance: 4.947e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 570, train_r2=0.0178, val_r2=-0.7282, val_cum_r2=-24.1926, val_cum_pearson=-0.0026:  57%|█████▋    | 566/996 [00:17<00:21, 20.36it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.430e+00, tolerance: 4.948e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 571, train_r2=0.0178, val_r2=-0.8113, val_cum_r2=-24.1709, val_cum_pearson=-0.0026:  57%|█████▋    | 569/996 [00:18<00:22, 19.33it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.433e+00, tolerance: 4.953e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 572, train_r2=0.0177, val_r2=-0.9617, val_cum_r2=-24.1684, val_cum_pearson=-0.0026:  57%|█████▋    | 569/996 [00:18<00:22, 19.33it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.435e+00, tolerance: 4.957e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 573, train_r2=0.0177, val_r2=-0.6549, val_cum_r2=-24.1637, val_cum_pearson=-0.0026:  57%|█████▋    | 569/996 [00:18<00:22, 19.33it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.435e+00, tolerance: 4.958e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 574, train_r2=0.0178, val_r2=-0.3415, val_cum_r2=-24.1479, val_cum_pearson=-0.0026:  57%|█████▋    | 572/996 [00:18<00:21, 19.29it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.436e+00, tolerance: 4.959e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 575, train_r2=0.0177, val_r2=-0.0315, val_cum_r2=-24.1295, val_cum_pearson=-0.0026:  57%|█████▋    | 572/996 [00:18<00:21, 19.29it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.437e+00, tolerance: 4.962e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 576, train_r2=0.0176, val_r2=-1.4091, val_cum_r2=-24.1155, val_cum_pearson=-0.0026:  58%|█████▊    | 574/996 [00:18<00:22, 19.05it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.439e+00, tolerance: 4.966e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 577, train_r2=0.0176, val_r2=-3.6361, val_cum_r2=-24.0717, val_cum_pearson=-0.0026:  58%|█████▊    | 574/996 [00:18<00:22, 19.05it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.441e+00, tolerance: 4.969e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 578, train_r2=0.0175, val_r2=-0.3990, val_cum_r2=-24.0574, val_cum_pearson=-0.0026:  58%|█████▊    | 576/996 [00:18<00:23, 18.20it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.446e+00, tolerance: 4.978e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 579, train_r2=0.0174, val_r2=-1.3070, val_cum_r2=-24.0544, val_cum_pearson=-0.0026:  58%|█████▊    | 576/996 [00:18<00:23, 18.20it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.447e+00, tolerance: 4.981e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 580, train_r2=0.0174, val_r2=-1.1449, val_cum_r2=-24.0470, val_cum_pearson=-0.0026:  58%|█████▊    | 578/996 [00:18<00:23, 17.56it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.447e+00, tolerance: 4.981e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 581, train_r2=0.0175, val_r2=-1.5602, val_cum_r2=-24.0424, val_cum_pearson=-0.0026:  58%|█████▊    | 578/996 [00:18<00:23, 17.56it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.448e+00, tolerance: 4.983e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 582, train_r2=0.0174, val_r2=-0.0842, val_cum_r2=-24.0022, val_cum_pearson=-0.0026:  58%|█████▊    | 578/996 [00:18<00:23, 17.56it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.449e+00, tolerance: 4.984e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 583, train_r2=0.0174, val_r2=0.0376, val_cum_r2=-23.9872, val_cum_pearson=-0.0026:  58%|█████▊    | 581/996 [00:18<00:22, 18.73it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.453e+00, tolerance: 4.992e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 584, train_r2=0.0174, val_r2=-0.7002, val_cum_r2=-23.9811, val_cum_pearson=-0.0026:  58%|█████▊    | 581/996 [00:18<00:22, 18.73it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.454e+00, tolerance: 4.995e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 585, train_r2=0.0174, val_r2=-0.3939, val_cum_r2=-23.9781, val_cum_pearson=-0.0026:  59%|█████▊    | 583/996 [00:18<00:22, 18.61it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.455e+00, tolerance: 4.996e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 586, train_r2=0.0175, val_r2=-0.3797, val_cum_r2=-23.9628, val_cum_pearson=-0.0026:  59%|█████▊    | 583/996 [00:18<00:22, 18.61it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.455e+00, tolerance: 4.997e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 587, train_r2=0.0175, val_r2=-0.0820, val_cum_r2=-23.9346, val_cum_pearson=-0.0026:  59%|█████▊    | 583/996 [00:18<00:22, 18.61it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.456e+00, tolerance: 5.000e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 588, train_r2=0.0175, val_r2=0.2558, val_cum_r2=-23.9298, val_cum_pearson=-0.0026:  59%|█████▉    | 586/996 [00:18<00:21, 18.82it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.459e+00, tolerance: 5.006e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 589, train_r2=0.0174, val_r2=0.1229, val_cum_r2=-23.9115, val_cum_pearson=-0.0025:  59%|█████▉    | 586/996 [00:18<00:21, 18.82it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.460e+00, tolerance: 5.007e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 590, train_r2=0.0175, val_r2=-0.1256, val_cum_r2=-23.9076, val_cum_pearson=-0.0025:  59%|█████▉    | 586/996 [00:19<00:21, 18.82it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.461e+00, tolerance: 5.011e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 591, train_r2=0.0176, val_r2=-8.2293, val_cum_r2=-23.8879, val_cum_pearson=-0.0025:  59%|█████▉    | 589/996 [00:19<00:20, 19.59it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.462e+00, tolerance: 5.012e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 592, train_r2=0.0177, val_r2=-9.3279, val_cum_r2=-23.8562, val_cum_pearson=-0.0025:  59%|█████▉    | 589/996 [00:19<00:20, 19.59it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.464e+00, tolerance: 5.016e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 593, train_r2=0.0177, val_r2=-2.9198, val_cum_r2=-23.8395, val_cum_pearson=-0.0025:  59%|█████▉    | 589/996 [00:19<00:20, 19.59it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.467e+00, tolerance: 5.022e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 594, train_r2=0.0176, val_r2=-10.7998, val_cum_r2=-23.8292, val_cum_pearson=-0.0025:  59%|█████▉    | 592/996 [00:19<00:20, 20.12it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.469e+00, tolerance: 5.026e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 595, train_r2=0.0175, val_r2=-1.5582, val_cum_r2=-23.8192, val_cum_pearson=-0.0025:  59%|█████▉    | 592/996 [00:19<00:20, 20.12it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.471e+00, tolerance: 5.028e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 596, train_r2=0.0172, val_r2=-2.9419, val_cum_r2=-23.8039, val_cum_pearson=-0.0025:  59%|█████▉    | 592/996 [00:19<00:20, 20.12it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.472e+00, tolerance: 5.030e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 597, train_r2=0.0170, val_r2=-1.8271, val_cum_r2=-23.7818, val_cum_pearson=-0.0025:  60%|█████▉    | 595/996 [00:19<00:21, 18.62it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.474e+00, tolerance: 5.033e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 598, train_r2=0.0172, val_r2=-4.7091, val_cum_r2=-23.7767, val_cum_pearson=-0.0025:  60%|█████▉    | 595/996 [00:19<00:21, 18.62it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e+00, tolerance: 5.038e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 599, train_r2=0.0173, val_r2=-2.2866, val_cum_r2=-23.7745, val_cum_pearson=-0.0025:  60%|█████▉    | 597/996 [00:19<00:22, 17.94it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e+00, tolerance: 5.039e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 600, train_r2=0.0173, val_r2=-0.9076, val_cum_r2=-23.7721, val_cum_pearson=-0.0025:  60%|█████▉    | 597/996 [00:19<00:22, 17.94it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e+00, tolerance: 5.040e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 601, train_r2=0.0172, val_r2=-2.3507, val_cum_r2=-23.7456, val_cum_pearson=-0.0025:  60%|██████    | 599/996 [00:19<00:22, 18.03it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.477e+00, tolerance: 5.040e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 602, train_r2=0.0172, val_r2=-0.9543, val_cum_r2=-23.7379, val_cum_pearson=-0.0025:  60%|██████    | 599/996 [00:19<00:22, 18.03it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.480e+00, tolerance: 5.046e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 603, train_r2=0.0172, val_r2=-0.7587, val_cum_r2=-23.7325, val_cum_pearson=-0.0025:  60%|██████    | 601/996 [00:19<00:21, 18.09it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.480e+00, tolerance: 5.047e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 604, train_r2=0.0172, val_r2=-4.1839, val_cum_r2=-23.7014, val_cum_pearson=-0.0025:  60%|██████    | 601/996 [00:19<00:21, 18.09it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.481e+00, tolerance: 5.049e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 605, train_r2=0.0170, val_r2=-0.7920, val_cum_r2=-23.6908, val_cum_pearson=-0.0025:  61%|██████    | 603/996 [00:19<00:21, 18.14it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.485e+00, tolerance: 5.055e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 606, train_r2=0.0168, val_r2=-3.0683, val_cum_r2=-23.6808, val_cum_pearson=-0.0025:  61%|██████    | 603/996 [00:19<00:21, 18.14it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.486e+00, tolerance: 5.057e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 607, train_r2=0.0167, val_r2=-0.1263, val_cum_r2=-23.6765, val_cum_pearson=-0.0025:  61%|██████    | 605/996 [00:19<00:21, 18.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.487e+00, tolerance: 5.060e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 608, train_r2=0.0168, val_r2=-3.9080, val_cum_r2=-23.6746, val_cum_pearson=-0.0025:  61%|██████    | 605/996 [00:20<00:21, 18.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.488e+00, tolerance: 5.061e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 609, train_r2=0.0168, val_r2=-2.3729, val_cum_r2=-23.6621, val_cum_pearson=-0.0025:  61%|██████    | 607/996 [00:20<00:21, 18.21it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.488e+00, tolerance: 5.061e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 610, train_r2=0.0168, val_r2=-8.8886, val_cum_r2=-23.6321, val_cum_pearson=-0.0026:  61%|██████    | 607/996 [00:20<00:21, 18.21it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.489e+00, tolerance: 5.064e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 611, train_r2=0.0168, val_r2=-2.6334, val_cum_r2=-23.6312, val_cum_pearson=-0.0026:  61%|██████    | 609/996 [00:20<00:21, 18.23it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.493e+00, tolerance: 5.070e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 612, train_r2=0.0167, val_r2=-1.1283, val_cum_r2=-23.6301, val_cum_pearson=-0.0026:  61%|██████    | 609/996 [00:20<00:21, 18.23it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.493e+00, tolerance: 5.070e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 613, train_r2=0.0167, val_r2=-4.8008, val_cum_r2=-23.6110, val_cum_pearson=-0.0026:  61%|██████▏   | 611/996 [00:20<00:21, 17.88it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.493e+00, tolerance: 5.071e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 614, train_r2=0.0166, val_r2=-1.0230, val_cum_r2=-23.6032, val_cum_pearson=-0.0026:  61%|██████▏   | 611/996 [00:20<00:21, 17.88it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.495e+00, tolerance: 5.075e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 615, train_r2=0.0165, val_r2=0.0221, val_cum_r2=-23.5973, val_cum_pearson=-0.0026:  61%|██████▏   | 611/996 [00:20<00:21, 17.88it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.496e+00, tolerance: 5.076e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 616, train_r2=0.0165, val_r2=-1.0068, val_cum_r2=-23.5842, val_cum_pearson=-0.0026:  62%|██████▏   | 614/996 [00:20<00:20, 18.36it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.497e+00, tolerance: 5.078e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 617, train_r2=0.0166, val_r2=-2.2681, val_cum_r2=-23.5696, val_cum_pearson=-0.0026:  62%|██████▏   | 614/996 [00:20<00:20, 18.36it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.498e+00, tolerance: 5.080e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 618, train_r2=0.0165, val_r2=-0.2574, val_cum_r2=-23.5530, val_cum_pearson=-0.0026:  62%|██████▏   | 616/996 [00:20<00:20, 18.34it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.500e+00, tolerance: 5.084e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 619, train_r2=0.0164, val_r2=-2.5243, val_cum_r2=-23.5317, val_cum_pearson=-0.0026:  62%|██████▏   | 616/996 [00:20<00:20, 18.34it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.502e+00, tolerance: 5.087e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 620, train_r2=0.0164, val_r2=-2.0667, val_cum_r2=-23.4944, val_cum_pearson=-0.0026:  62%|██████▏   | 618/996 [00:20<00:20, 18.31it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.504e+00, tolerance: 5.092e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 621, train_r2=0.0163, val_r2=-1.7178, val_cum_r2=-23.4872, val_cum_pearson=-0.0026:  62%|██████▏   | 618/996 [00:20<00:20, 18.31it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.508e+00, tolerance: 5.100e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 622, train_r2=0.0163, val_r2=-5.8532, val_cum_r2=-23.4788, val_cum_pearson=-0.0026:  62%|██████▏   | 620/996 [00:20<00:22, 16.87it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.509e+00, tolerance: 5.101e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 623, train_r2=0.0163, val_r2=0.3678, val_cum_r2=-23.4780, val_cum_pearson=-0.0026:  62%|██████▏   | 620/996 [00:20<00:22, 16.87it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.510e+00, tolerance: 5.103e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 624, train_r2=0.0164, val_r2=-0.0196, val_cum_r2=-23.4658, val_cum_pearson=-0.0026:  62%|██████▏   | 622/996 [00:20<00:22, 16.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.510e+00, tolerance: 5.103e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 625, train_r2=0.0164, val_r2=-0.1380, val_cum_r2=-23.4478, val_cum_pearson=-0.0026:  62%|██████▏   | 622/996 [00:20<00:22, 16.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.511e+00, tolerance: 5.106e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 626, train_r2=0.0164, val_r2=-2.1096, val_cum_r2=-23.4208, val_cum_pearson=-0.0026:  63%|██████▎   | 624/996 [00:21<00:22, 16.44it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.513e+00, tolerance: 5.110e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 627, train_r2=0.0163, val_r2=-1.2305, val_cum_r2=-23.4104, val_cum_pearson=-0.0026:  63%|██████▎   | 624/996 [00:21<00:22, 16.44it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.517e+00, tolerance: 5.116e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 628, train_r2=0.0162, val_r2=-0.3800, val_cum_r2=-23.3878, val_cum_pearson=-0.0026:  63%|██████▎   | 626/996 [00:21<00:21, 16.94it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.518e+00, tolerance: 5.118e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 629, train_r2=0.0161, val_r2=-0.5417, val_cum_r2=-23.3153, val_cum_pearson=-0.0026:  63%|██████▎   | 626/996 [00:21<00:21, 16.94it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.520e+00, tolerance: 5.123e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 630, train_r2=0.0161, val_r2=-1.1621, val_cum_r2=-23.2954, val_cum_pearson=-0.0026:  63%|██████▎   | 628/996 [00:21<00:22, 16.65it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.528e+00, tolerance: 5.139e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 631, train_r2=0.0162, val_r2=-0.3760, val_cum_r2=-23.2915, val_cum_pearson=-0.0026:  63%|██████▎   | 628/996 [00:21<00:22, 16.65it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.530e+00, tolerance: 5.143e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 632, train_r2=0.0162, val_r2=-6.8786, val_cum_r2=-23.2783, val_cum_pearson=-0.0026:  63%|██████▎   | 628/996 [00:21<00:22, 16.65it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.530e+00, tolerance: 5.144e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 633, train_r2=0.0162, val_r2=-6.5029, val_cum_r2=-23.2651, val_cum_pearson=-0.0026:  63%|██████▎   | 631/996 [00:21<00:20, 17.55it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.532e+00, tolerance: 5.147e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 634, train_r2=0.0163, val_r2=-0.0406, val_cum_r2=-23.2556, val_cum_pearson=-0.0026:  63%|██████▎   | 631/996 [00:21<00:20, 17.55it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.533e+00, tolerance: 5.150e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 635, train_r2=0.0162, val_r2=-0.1153, val_cum_r2=-23.2425, val_cum_pearson=-0.0026:  64%|██████▎   | 633/996 [00:21<00:21, 17.11it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.534e+00, tolerance: 5.152e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 636, train_r2=0.0163, val_r2=-1.1543, val_cum_r2=-23.2201, val_cum_pearson=-0.0026:  64%|██████▎   | 633/996 [00:21<00:21, 17.11it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.535e+00, tolerance: 5.155e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 637, train_r2=0.0163, val_r2=-1.0684, val_cum_r2=-23.1731, val_cum_pearson=-0.0025:  64%|██████▍   | 635/996 [00:21<00:21, 16.78it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.538e+00, tolerance: 5.160e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 638, train_r2=0.0163, val_r2=-1.7281, val_cum_r2=-23.1580, val_cum_pearson=-0.0025:  64%|██████▍   | 635/996 [00:21<00:21, 16.78it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.543e+00, tolerance: 5.170e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 639, train_r2=0.0163, val_r2=-1.3361, val_cum_r2=-23.1515, val_cum_pearson=-0.0025:  64%|██████▍   | 637/996 [00:21<00:23, 15.43it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.544e+00, tolerance: 5.174e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 640, train_r2=0.0165, val_r2=-1.2277, val_cum_r2=-23.1334, val_cum_pearson=-0.0025:  64%|██████▍   | 637/996 [00:21<00:23, 15.43it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.545e+00, tolerance: 5.175e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 641, train_r2=0.0164, val_r2=-0.0146, val_cum_r2=-23.1271, val_cum_pearson=-0.0025:  64%|██████▍   | 639/996 [00:21<00:23, 15.06it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.547e+00, tolerance: 5.179e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 642, train_r2=0.0164, val_r2=-0.3586, val_cum_r2=-23.1258, val_cum_pearson=-0.0025:  64%|██████▍   | 639/996 [00:22<00:23, 15.06it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.548e+00, tolerance: 5.180e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 643, train_r2=0.0164, val_r2=-0.0245, val_cum_r2=-23.1134, val_cum_pearson=-0.0025:  64%|██████▍   | 641/996 [00:22<00:23, 15.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.548e+00, tolerance: 5.181e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 644, train_r2=0.0164, val_r2=-0.2918, val_cum_r2=-23.1077, val_cum_pearson=-0.0025:  64%|██████▍   | 641/996 [00:22<00:23, 15.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.549e+00, tolerance: 5.183e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 645, train_r2=0.0164, val_r2=-0.3166, val_cum_r2=-23.1004, val_cum_pearson=-0.0025:  65%|██████▍   | 643/996 [00:22<00:22, 15.51it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.550e+00, tolerance: 5.185e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 646, train_r2=0.0164, val_r2=-3.1261, val_cum_r2=-23.0943, val_cum_pearson=-0.0025:  65%|██████▍   | 643/996 [00:22<00:22, 15.51it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.551e+00, tolerance: 5.186e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 647, train_r2=0.0164, val_r2=-3.9085, val_cum_r2=-23.0861, val_cum_pearson=-0.0025:  65%|██████▍   | 645/996 [00:22<00:21, 16.21it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.551e+00, tolerance: 5.188e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 648, train_r2=0.0164, val_r2=-3.4038, val_cum_r2=-23.0824, val_cum_pearson=-0.0026:  65%|██████▍   | 645/996 [00:22<00:21, 16.21it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.553e+00, tolerance: 5.190e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 649, train_r2=0.0163, val_r2=-0.0400, val_cum_r2=-23.0792, val_cum_pearson=-0.0025:  65%|██████▍   | 647/996 [00:22<00:20, 16.78it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.553e+00, tolerance: 5.190e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 650, train_r2=0.0162, val_r2=-0.1117, val_cum_r2=-23.0738, val_cum_pearson=-0.0026:  65%|██████▍   | 647/996 [00:22<00:20, 16.78it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.553e+00, tolerance: 5.191e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 651, train_r2=0.0162, val_r2=-3.0725, val_cum_r2=-23.0704, val_cum_pearson=-0.0026:  65%|██████▌   | 649/996 [00:22<00:20, 16.54it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.554e+00, tolerance: 5.192e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 652, train_r2=0.0162, val_r2=-3.9131, val_cum_r2=-23.0694, val_cum_pearson=-0.0026:  65%|██████▌   | 649/996 [00:22<00:20, 16.54it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.555e+00, tolerance: 5.193e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 653, train_r2=0.0161, val_r2=-2.7513, val_cum_r2=-23.0654, val_cum_pearson=-0.0026:  65%|██████▌   | 651/996 [00:22<00:21, 16.37it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.555e+00, tolerance: 5.193e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 654, train_r2=0.0161, val_r2=-3.5803, val_cum_r2=-23.0605, val_cum_pearson=-0.0026:  65%|██████▌   | 651/996 [00:22<00:21, 16.37it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.555e+00, tolerance: 5.194e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 655, train_r2=0.0161, val_r2=0.1253, val_cum_r2=-23.0551, val_cum_pearson=-0.0026:  66%|██████▌   | 653/996 [00:22<00:21, 16.26it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.556e+00, tolerance: 5.195e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 656, train_r2=0.0160, val_r2=0.0708, val_cum_r2=-23.0504, val_cum_pearson=-0.0026:  66%|██████▌   | 653/996 [00:22<00:21, 16.26it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.556e+00, tolerance: 5.197e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 657, train_r2=0.0161, val_r2=-0.0046, val_cum_r2=-23.0463, val_cum_pearson=-0.0026:  66%|██████▌   | 655/996 [00:22<00:22, 15.04it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.557e+00, tolerance: 5.198e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 658, train_r2=0.0162, val_r2=0.0022, val_cum_r2=-23.0427, val_cum_pearson=-0.0026:  66%|██████▌   | 655/996 [00:23<00:22, 15.04it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.557e+00, tolerance: 5.199e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 659, train_r2=0.0162, val_r2=-0.3225, val_cum_r2=-23.0412, val_cum_pearson=-0.0026:  66%|██████▌   | 657/996 [00:23<00:21, 15.74it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.558e+00, tolerance: 5.199e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 660, train_r2=0.0162, val_r2=-0.0144, val_cum_r2=-23.0346, val_cum_pearson=-0.0026:  66%|██████▌   | 657/996 [00:23<00:21, 15.74it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.558e+00, tolerance: 5.200e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 661, train_r2=0.0162, val_r2=-0.6969, val_cum_r2=-22.9989, val_cum_pearson=-0.0025:  66%|██████▌   | 659/996 [00:23<00:21, 15.82it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.559e+00, tolerance: 5.201e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 662, train_r2=0.0162, val_r2=-2.4569, val_cum_r2=-22.9862, val_cum_pearson=-0.0025:  66%|██████▌   | 659/996 [00:23<00:21, 15.82it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.563e+00, tolerance: 5.209e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 663, train_r2=0.0161, val_r2=-0.1714, val_cum_r2=-22.9840, val_cum_pearson=-0.0025:  66%|██████▋   | 661/996 [00:23<00:21, 15.87it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.564e+00, tolerance: 5.212e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 664, train_r2=0.0162, val_r2=-0.5232, val_cum_r2=-22.9790, val_cum_pearson=-0.0025:  66%|██████▋   | 661/996 [00:23<00:21, 15.87it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.564e+00, tolerance: 5.213e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 665, train_r2=0.0162, val_r2=-0.1751, val_cum_r2=-22.9741, val_cum_pearson=-0.0025:  67%|██████▋   | 663/996 [00:23<00:20, 15.89it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.565e+00, tolerance: 5.214e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 666, train_r2=0.0161, val_r2=-0.8709, val_cum_r2=-22.9697, val_cum_pearson=-0.0025:  67%|██████▋   | 663/996 [00:23<00:20, 15.89it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.565e+00, tolerance: 5.215e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 667, train_r2=0.0161, val_r2=-0.2916, val_cum_r2=-22.9642, val_cum_pearson=-0.0025:  67%|██████▋   | 665/996 [00:23<00:20, 16.54it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.566e+00, tolerance: 5.216e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 668, train_r2=0.0161, val_r2=-0.0751, val_cum_r2=-22.9502, val_cum_pearson=-0.0025:  67%|██████▋   | 665/996 [00:23<00:20, 16.54it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.567e+00, tolerance: 5.217e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 669, train_r2=0.0161, val_r2=-0.1928, val_cum_r2=-22.9415, val_cum_pearson=-0.0025:  67%|██████▋   | 667/996 [00:23<00:20, 15.77it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.568e+00, tolerance: 5.220e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 670, train_r2=0.0161, val_r2=-0.2963, val_cum_r2=-22.9386, val_cum_pearson=-0.0025:  67%|██████▋   | 667/996 [00:23<00:20, 15.77it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.569e+00, tolerance: 5.222e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 671, train_r2=0.0161, val_r2=-0.0231, val_cum_r2=-22.9345, val_cum_pearson=-0.0025:  67%|██████▋   | 669/996 [00:23<00:20, 15.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.569e+00, tolerance: 5.223e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 672, train_r2=0.0161, val_r2=-2.1765, val_cum_r2=-22.9250, val_cum_pearson=-0.0025:  67%|██████▋   | 669/996 [00:23<00:20, 15.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.570e+00, tolerance: 5.224e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 673, train_r2=0.0161, val_r2=-3.9287, val_cum_r2=-22.9207, val_cum_pearson=-0.0025:  67%|██████▋   | 671/996 [00:24<00:21, 15.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.571e+00, tolerance: 5.226e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 674, train_r2=0.0161, val_r2=-24.6657, val_cum_r2=-22.9182, val_cum_pearson=-0.0025:  67%|██████▋   | 671/996 [00:24<00:21, 15.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.571e+00, tolerance: 5.227e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 675, train_r2=0.0161, val_r2=-7.4299, val_cum_r2=-22.9126, val_cum_pearson=-0.0025:  68%|██████▊   | 673/996 [00:24<00:21, 14.76it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.572e+00, tolerance: 5.227e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 676, train_r2=0.0161, val_r2=-0.0321, val_cum_r2=-22.9052, val_cum_pearson=-0.0025:  68%|██████▊   | 673/996 [00:24<00:21, 14.76it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.572e+00, tolerance: 5.229e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 677, train_r2=0.0160, val_r2=-0.3716, val_cum_r2=-22.9000, val_cum_pearson=-0.0025:  68%|██████▊   | 675/996 [00:24<00:20, 15.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.573e+00, tolerance: 5.230e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 678, train_r2=0.0160, val_r2=-0.0562, val_cum_r2=-22.8895, val_cum_pearson=-0.0025:  68%|██████▊   | 675/996 [00:24<00:20, 15.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.574e+00, tolerance: 5.232e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 679, train_r2=0.0161, val_r2=-0.3852, val_cum_r2=-22.8778, val_cum_pearson=-0.0025:  68%|██████▊   | 677/996 [00:24<00:20, 15.52it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.575e+00, tolerance: 5.234e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 680, train_r2=0.0161, val_r2=-1.0432, val_cum_r2=-22.8675, val_cum_pearson=-0.0025:  68%|██████▊   | 677/996 [00:24<00:20, 15.52it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.576e+00, tolerance: 5.237e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 681, train_r2=0.0160, val_r2=-0.7435, val_cum_r2=-22.8634, val_cum_pearson=-0.0025:  68%|██████▊   | 679/996 [00:24<00:20, 15.65it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.578e+00, tolerance: 5.239e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 682, train_r2=0.0160, val_r2=-0.1975, val_cum_r2=-22.8532, val_cum_pearson=-0.0025:  68%|██████▊   | 679/996 [00:24<00:20, 15.65it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.578e+00, tolerance: 5.240e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 683, train_r2=0.0160, val_r2=0.0050, val_cum_r2=-22.8440, val_cum_pearson=-0.0025:  68%|██████▊   | 681/996 [00:24<00:20, 15.19it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.579e+00, tolerance: 5.242e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 684, train_r2=0.0160, val_r2=-1.4012, val_cum_r2=-22.8386, val_cum_pearson=-0.0025:  68%|██████▊   | 681/996 [00:24<00:20, 15.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.580e+00, tolerance: 5.244e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 685, train_r2=0.0160, val_r2=-0.0474, val_cum_r2=-22.8301, val_cum_pearson=-0.0025:  69%|██████▊   | 683/996 [00:24<00:21, 14.89it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.581e+00, tolerance: 5.246e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 686, train_r2=0.0160, val_r2=-0.4870, val_cum_r2=-22.8255, val_cum_pearson=-0.0025:  69%|██████▊   | 683/996 [00:24<00:21, 14.89it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.582e+00, tolerance: 5.248e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 687, train_r2=0.0160, val_r2=-0.0062, val_cum_r2=-22.8116, val_cum_pearson=-0.0025:  69%|██████▉   | 685/996 [00:24<00:21, 14.68it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.582e+00, tolerance: 5.249e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 688, train_r2=0.0160, val_r2=-0.6057, val_cum_r2=-22.7987, val_cum_pearson=-0.0025:  69%|██████▉   | 685/996 [00:25<00:21, 14.68it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.584e+00, tolerance: 5.252e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 689, train_r2=0.0160, val_r2=-0.0132, val_cum_r2=-22.7628, val_cum_pearson=-0.0025:  69%|██████▉   | 687/996 [00:25<00:20, 15.04it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.585e+00, tolerance: 5.255e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 690, train_r2=0.0160, val_r2=-0.3860, val_cum_r2=-22.7288, val_cum_pearson=-0.0025:  69%|██████▉   | 687/996 [00:25<00:20, 15.04it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.589e+00, tolerance: 5.263e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 691, train_r2=0.0160, val_r2=-0.2212, val_cum_r2=-22.7025, val_cum_pearson=-0.0025:  69%|██████▉   | 689/996 [00:25<00:20, 14.79it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.593e+00, tolerance: 5.271e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 692, train_r2=0.0160, val_r2=-0.1544, val_cum_r2=-22.6932, val_cum_pearson=-0.0025:  69%|██████▉   | 689/996 [00:25<00:20, 14.79it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.596e+00, tolerance: 5.277e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 693, train_r2=0.0161, val_r2=-0.2027, val_cum_r2=-22.6882, val_cum_pearson=-0.0025:  69%|██████▉   | 691/996 [00:25<00:20, 14.61it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.597e+00, tolerance: 5.279e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 694, train_r2=0.0160, val_r2=-4.2610, val_cum_r2=-22.6674, val_cum_pearson=-0.0025:  69%|██████▉   | 691/996 [00:25<00:20, 14.61it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.598e+00, tolerance: 5.280e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 695, train_r2=0.0160, val_r2=-2.3802, val_cum_r2=-22.6570, val_cum_pearson=-0.0025:  70%|██████▉   | 693/996 [00:25<00:20, 14.46it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.600e+00, tolerance: 5.285e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 696, train_r2=0.0160, val_r2=-0.8504, val_cum_r2=-22.6446, val_cum_pearson=-0.0024:  70%|██████▉   | 693/996 [00:25<00:20, 14.46it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.601e+00, tolerance: 5.287e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 697, train_r2=0.0160, val_r2=-1.0721, val_cum_r2=-22.6402, val_cum_pearson=-0.0024:  70%|██████▉   | 695/996 [00:25<00:19, 15.43it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.602e+00, tolerance: 5.290e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 698, train_r2=0.0162, val_r2=-0.8206, val_cum_r2=-22.6311, val_cum_pearson=-0.0024:  70%|██████▉   | 695/996 [00:25<00:19, 15.43it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.603e+00, tolerance: 5.291e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 699, train_r2=0.0162, val_r2=-0.5323, val_cum_r2=-22.6237, val_cum_pearson=-0.0024:  70%|██████▉   | 697/996 [00:25<00:19, 15.59it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.604e+00, tolerance: 5.293e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 700, train_r2=0.0162, val_r2=-0.5915, val_cum_r2=-22.5956, val_cum_pearson=-0.0024:  70%|██████▉   | 697/996 [00:25<00:19, 15.59it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.605e+00, tolerance: 5.295e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 701, train_r2=0.0162, val_r2=-2.0087, val_cum_r2=-22.5823, val_cum_pearson=-0.0024:  70%|███████   | 699/996 [00:25<00:19, 15.15it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.608e+00, tolerance: 5.302e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 702, train_r2=0.0163, val_r2=-0.2379, val_cum_r2=-22.5784, val_cum_pearson=-0.0024:  70%|███████   | 699/996 [00:25<00:19, 15.15it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.609e+00, tolerance: 5.305e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 703, train_r2=0.0162, val_r2=-0.5385, val_cum_r2=-22.5688, val_cum_pearson=-0.0025:  70%|███████   | 701/996 [00:25<00:19, 15.40it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.610e+00, tolerance: 5.306e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 704, train_r2=0.0162, val_r2=-0.4376, val_cum_r2=-22.5339, val_cum_pearson=-0.0025:  70%|███████   | 701/996 [00:26<00:19, 15.40it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.611e+00, tolerance: 5.308e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 705, train_r2=0.0162, val_r2=-0.1648, val_cum_r2=-22.5190, val_cum_pearson=-0.0025:  71%|███████   | 703/996 [00:26<00:19, 15.17it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.615e+00, tolerance: 5.316e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 706, train_r2=0.0162, val_r2=-0.2245, val_cum_r2=-22.5013, val_cum_pearson=-0.0025:  71%|███████   | 703/996 [00:26<00:19, 15.17it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.617e+00, tolerance: 5.320e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 707, train_r2=0.0161, val_r2=-4.1675, val_cum_r2=-22.4227, val_cum_pearson=-0.0025:  71%|███████   | 705/996 [00:26<00:19, 14.88it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.619e+00, tolerance: 5.324e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 708, train_r2=0.0161, val_r2=-2.2795, val_cum_r2=-22.3727, val_cum_pearson=-0.0025:  71%|███████   | 705/996 [00:26<00:19, 14.88it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.628e+00, tolerance: 5.343e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 709, train_r2=0.0161, val_r2=-2.0971, val_cum_r2=-22.3672, val_cum_pearson=-0.0025:  71%|███████   | 707/996 [00:26<00:18, 15.23it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.634e+00, tolerance: 5.355e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 710, train_r2=0.0160, val_r2=0.1447, val_cum_r2=-22.3532, val_cum_pearson=-0.0025:  71%|███████   | 707/996 [00:26<00:18, 15.23it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.635e+00, tolerance: 5.356e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 711, train_r2=0.0160, val_r2=-0.0546, val_cum_r2=-22.3267, val_cum_pearson=-0.0025:  71%|███████   | 709/996 [00:26<00:20, 13.88it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.636e+00, tolerance: 5.359e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 712, train_r2=0.0161, val_r2=-2.2287, val_cum_r2=-22.3114, val_cum_pearson=-0.0025:  71%|███████   | 709/996 [00:26<00:20, 13.88it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.640e+00, tolerance: 5.365e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 713, train_r2=0.0160, val_r2=-0.3506, val_cum_r2=-22.3086, val_cum_pearson=-0.0025:  71%|███████▏  | 711/996 [00:26<00:20, 13.58it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.642e+00, tolerance: 5.369e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 714, train_r2=0.0159, val_r2=-0.9014, val_cum_r2=-22.3042, val_cum_pearson=-0.0025:  71%|███████▏  | 711/996 [00:26<00:20, 13.58it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.642e+00, tolerance: 5.370e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 715, train_r2=0.0159, val_r2=0.0516, val_cum_r2=-22.2937, val_cum_pearson=-0.0025:  72%|███████▏  | 713/996 [00:26<00:21, 13.34it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.643e+00, tolerance: 5.371e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 716, train_r2=0.0159, val_r2=-0.0814, val_cum_r2=-22.2851, val_cum_pearson=-0.0025:  72%|███████▏  | 713/996 [00:26<00:21, 13.34it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.644e+00, tolerance: 5.373e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 717, train_r2=0.0159, val_r2=0.0319, val_cum_r2=-22.2813, val_cum_pearson=-0.0025:  72%|███████▏  | 715/996 [00:27<00:21, 13.31it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.645e+00, tolerance: 5.376e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 718, train_r2=0.0160, val_r2=-0.0132, val_cum_r2=-22.2777, val_cum_pearson=-0.0025:  72%|███████▏  | 715/996 [00:27<00:21, 13.31it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.645e+00, tolerance: 5.376e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 719, train_r2=0.0160, val_r2=-4.4413, val_cum_r2=-22.2739, val_cum_pearson=-0.0025:  72%|███████▏  | 717/996 [00:27<00:20, 13.85it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.646e+00, tolerance: 5.377e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 720, train_r2=0.0160, val_r2=-0.1143, val_cum_r2=-22.2683, val_cum_pearson=-0.0025:  72%|███████▏  | 717/996 [00:27<00:20, 13.85it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.646e+00, tolerance: 5.378e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 721, train_r2=0.0160, val_r2=-0.1453, val_cum_r2=-22.2590, val_cum_pearson=-0.0025:  72%|███████▏  | 719/996 [00:27<00:19, 13.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.647e+00, tolerance: 5.380e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 722, train_r2=0.0159, val_r2=-0.5932, val_cum_r2=-22.2546, val_cum_pearson=-0.0025:  72%|███████▏  | 719/996 [00:27<00:19, 13.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.648e+00, tolerance: 5.382e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 723, train_r2=0.0159, val_r2=-3.1354, val_cum_r2=-22.2493, val_cum_pearson=-0.0025:  72%|███████▏  | 721/996 [00:27<00:19, 14.04it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e+00, tolerance: 5.383e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 724, train_r2=0.0159, val_r2=-0.8688, val_cum_r2=-22.2455, val_cum_pearson=-0.0025:  72%|███████▏  | 721/996 [00:27<00:19, 14.04it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.649e+00, tolerance: 5.384e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 725, train_r2=0.0159, val_r2=-1.6328, val_cum_r2=-22.2444, val_cum_pearson=-0.0025:  73%|███████▎  | 723/996 [00:27<00:18, 14.57it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.650e+00, tolerance: 5.385e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 726, train_r2=0.0159, val_r2=-0.8326, val_cum_r2=-22.2382, val_cum_pearson=-0.0025:  73%|███████▎  | 723/996 [00:27<00:18, 14.57it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.650e+00, tolerance: 5.385e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 727, train_r2=0.0159, val_r2=0.0738, val_cum_r2=-22.2318, val_cum_pearson=-0.0025:  73%|███████▎  | 725/996 [00:27<00:18, 14.60it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.650e+00, tolerance: 5.387e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 728, train_r2=0.0159, val_r2=-0.1097, val_cum_r2=-22.2215, val_cum_pearson=-0.0025:  73%|███████▎  | 725/996 [00:27<00:18, 14.60it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.651e+00, tolerance: 5.388e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 729, train_r2=0.0160, val_r2=-0.6641, val_cum_r2=-22.2147, val_cum_pearson=-0.0025:  73%|███████▎  | 727/996 [00:27<00:18, 14.81it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.652e+00, tolerance: 5.391e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 730, train_r2=0.0160, val_r2=-0.2784, val_cum_r2=-22.2108, val_cum_pearson=-0.0025:  73%|███████▎  | 727/996 [00:27<00:18, 14.81it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.653e+00, tolerance: 5.392e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 731, train_r2=0.0159, val_r2=-0.2778, val_cum_r2=-22.2088, val_cum_pearson=-0.0025:  73%|███████▎  | 729/996 [00:27<00:17, 15.15it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.654e+00, tolerance: 5.393e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 732, train_r2=0.0159, val_r2=-0.4848, val_cum_r2=-22.2061, val_cum_pearson=-0.0025:  73%|███████▎  | 729/996 [00:28<00:17, 15.15it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.654e+00, tolerance: 5.394e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 733, train_r2=0.0159, val_r2=-2.1594, val_cum_r2=-22.2045, val_cum_pearson=-0.0025:  73%|███████▎  | 731/996 [00:28<00:17, 14.86it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.654e+00, tolerance: 5.395e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 734, train_r2=0.0159, val_r2=-0.4710, val_cum_r2=-22.1954, val_cum_pearson=-0.0025:  73%|███████▎  | 731/996 [00:28<00:17, 14.86it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.655e+00, tolerance: 5.395e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 735, train_r2=0.0159, val_r2=-2.1969, val_cum_r2=-22.1886, val_cum_pearson=-0.0025:  74%|███████▎  | 733/996 [00:28<00:18, 14.16it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.656e+00, tolerance: 5.397e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 736, train_r2=0.0159, val_r2=-0.3853, val_cum_r2=-22.1655, val_cum_pearson=-0.0024:  74%|███████▎  | 733/996 [00:28<00:18, 14.16it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.656e+00, tolerance: 5.399e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 737, train_r2=0.0159, val_r2=-0.6623, val_cum_r2=-22.1589, val_cum_pearson=-0.0024:  74%|███████▍  | 735/996 [00:28<00:17, 14.67it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.659e+00, tolerance: 5.404e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 738, train_r2=0.0160, val_r2=-0.3198, val_cum_r2=-22.1547, val_cum_pearson=-0.0024:  74%|███████▍  | 735/996 [00:28<00:17, 14.67it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.660e+00, tolerance: 5.406e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 739, train_r2=0.0159, val_r2=-3.3185, val_cum_r2=-22.1480, val_cum_pearson=-0.0024:  74%|███████▍  | 737/996 [00:28<00:17, 14.53it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e+00, tolerance: 5.407e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 740, train_r2=0.0159, val_r2=-1.0941, val_cum_r2=-22.1440, val_cum_pearson=-0.0024:  74%|███████▍  | 737/996 [00:28<00:17, 14.53it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.661e+00, tolerance: 5.409e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 741, train_r2=0.0158, val_r2=-2.9165, val_cum_r2=-22.1408, val_cum_pearson=-0.0024:  74%|███████▍  | 739/996 [00:28<00:17, 14.43it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.662e+00, tolerance: 5.410e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 742, train_r2=0.0157, val_r2=-1.0410, val_cum_r2=-22.1386, val_cum_pearson=-0.0024:  74%|███████▍  | 739/996 [00:28<00:17, 14.43it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.663e+00, tolerance: 5.410e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 743, train_r2=0.0156, val_r2=-2.5342, val_cum_r2=-22.1217, val_cum_pearson=-0.0025:  74%|███████▍  | 741/996 [00:28<00:18, 13.80it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.663e+00, tolerance: 5.411e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 744, train_r2=0.0156, val_r2=-0.0228, val_cum_r2=-22.1188, val_cum_pearson=-0.0025:  74%|███████▍  | 741/996 [00:28<00:18, 13.80it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.666e+00, tolerance: 5.415e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 745, train_r2=0.0154, val_r2=-0.6369, val_cum_r2=-22.1016, val_cum_pearson=-0.0024:  75%|███████▍  | 743/996 [00:28<00:18, 13.52it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.666e+00, tolerance: 5.416e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 746, train_r2=0.0154, val_r2=-0.3699, val_cum_r2=-22.0427, val_cum_pearson=-0.0024:  75%|███████▍  | 743/996 [00:29<00:18, 13.52it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.668e+00, tolerance: 5.420e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 747, train_r2=0.0155, val_r2=-0.6419, val_cum_r2=-22.0088, val_cum_pearson=-0.0024:  75%|███████▍  | 745/996 [00:29<00:18, 13.68it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.676e+00, tolerance: 5.435e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 748, train_r2=0.0152, val_r2=-3.5057, val_cum_r2=-21.9997, val_cum_pearson=-0.0024:  75%|███████▍  | 745/996 [00:29<00:18, 13.68it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.680e+00, tolerance: 5.443e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 749, train_r2=0.0152, val_r2=-6.8255, val_cum_r2=-21.9859, val_cum_pearson=-0.0024:  75%|███████▌  | 747/996 [00:29<00:18, 13.40it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.681e+00, tolerance: 5.445e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 750, train_r2=0.0151, val_r2=-1.0943, val_cum_r2=-21.9825, val_cum_pearson=-0.0024:  75%|███████▌  | 747/996 [00:29<00:18, 13.40it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.683e+00, tolerance: 5.448e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 751, train_r2=0.0151, val_r2=-2.0703, val_cum_r2=-21.9697, val_cum_pearson=-0.0024:  75%|███████▌  | 749/996 [00:29<00:18, 13.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.684e+00, tolerance: 5.449e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 752, train_r2=0.0150, val_r2=-0.6230, val_cum_r2=-21.9646, val_cum_pearson=-0.0024:  75%|███████▌  | 749/996 [00:29<00:18, 13.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.686e+00, tolerance: 5.453e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 753, train_r2=0.0149, val_r2=-4.9555, val_cum_r2=-21.9444, val_cum_pearson=-0.0025:  75%|███████▌  | 751/996 [00:29<00:18, 13.49it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.687e+00, tolerance: 5.454e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 754, train_r2=0.0148, val_r2=-6.7899, val_cum_r2=-21.9128, val_cum_pearson=-0.0025:  75%|███████▌  | 751/996 [00:29<00:18, 13.49it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.689e+00, tolerance: 5.459e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 755, train_r2=0.0147, val_r2=-0.4963, val_cum_r2=-21.8583, val_cum_pearson=-0.0025:  76%|███████▌  | 753/996 [00:29<00:17, 13.70it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.694e+00, tolerance: 5.467e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 756, train_r2=0.0146, val_r2=-1.0626, val_cum_r2=-21.7254, val_cum_pearson=-0.0026:  76%|███████▌  | 753/996 [00:29<00:17, 13.70it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.701e+00, tolerance: 5.480e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 757, train_r2=0.0142, val_r2=-2.5059, val_cum_r2=-21.6912, val_cum_pearson=-0.0027:  76%|███████▌  | 755/996 [00:29<00:17, 13.41it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.719e+00, tolerance: 5.514e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 758, train_r2=0.0138, val_r2=-0.6917, val_cum_r2=-21.6574, val_cum_pearson=-0.0027:  76%|███████▌  | 755/996 [00:29<00:17, 13.41it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.725e+00, tolerance: 5.523e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 759, train_r2=0.0134, val_r2=-2.8129, val_cum_r2=-21.5728, val_cum_pearson=-0.0027:  76%|███████▌  | 757/996 [00:30<00:17, 13.63it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.729e+00, tolerance: 5.532e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 760, train_r2=0.0133, val_r2=-1.8351, val_cum_r2=-21.4909, val_cum_pearson=-0.0027:  76%|███████▌  | 757/996 [00:30<00:17, 13.63it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.740e+00, tolerance: 5.553e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 761, train_r2=0.0131, val_r2=-0.3092, val_cum_r2=-21.4795, val_cum_pearson=-0.0027:  76%|███████▌  | 759/996 [00:30<00:17, 13.37it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.752e+00, tolerance: 5.574e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 762, train_r2=0.0128, val_r2=-0.4629, val_cum_r2=-21.4662, val_cum_pearson=-0.0027:  76%|███████▌  | 759/996 [00:30<00:17, 13.37it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.753e+00, tolerance: 5.577e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 763, train_r2=0.0127, val_r2=-0.6385, val_cum_r2=-21.4579, val_cum_pearson=-0.0028:  76%|███████▋  | 761/996 [00:30<00:17, 13.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.755e+00, tolerance: 5.581e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 764, train_r2=0.0127, val_r2=-1.2687, val_cum_r2=-21.4372, val_cum_pearson=-0.0027:  76%|███████▋  | 761/996 [00:30<00:17, 13.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.756e+00, tolerance: 5.583e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 765, train_r2=0.0127, val_r2=0.0631, val_cum_r2=-21.4319, val_cum_pearson=-0.0027:  77%|███████▋  | 763/996 [00:30<00:18, 12.69it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.759e+00, tolerance: 5.588e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 766, train_r2=0.0127, val_r2=-1.2700, val_cum_r2=-21.4237, val_cum_pearson=-0.0027:  77%|███████▋  | 763/996 [00:30<00:18, 12.69it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.759e+00, tolerance: 5.590e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 767, train_r2=0.0127, val_r2=-0.3310, val_cum_r2=-21.4157, val_cum_pearson=-0.0027:  77%|███████▋  | 765/996 [00:30<00:18, 12.72it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.760e+00, tolerance: 5.592e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 768, train_r2=0.0127, val_r2=-0.1088, val_cum_r2=-21.4118, val_cum_pearson=-0.0027:  77%|███████▋  | 765/996 [00:30<00:18, 12.72it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.761e+00, tolerance: 5.594e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 769, train_r2=0.0127, val_r2=-0.1643, val_cum_r2=-21.4088, val_cum_pearson=-0.0027:  77%|███████▋  | 767/996 [00:30<00:17, 13.11it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.762e+00, tolerance: 5.595e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 770, train_r2=0.0127, val_r2=-1.5975, val_cum_r2=-21.3944, val_cum_pearson=-0.0027:  77%|███████▋  | 767/996 [00:30<00:17, 13.11it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.762e+00, tolerance: 5.596e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 771, train_r2=0.0127, val_r2=-0.8421, val_cum_r2=-21.3918, val_cum_pearson=-0.0027:  77%|███████▋  | 769/996 [00:30<00:17, 13.01it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.764e+00, tolerance: 5.600e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 772, train_r2=0.0128, val_r2=-3.1096, val_cum_r2=-21.3894, val_cum_pearson=-0.0027:  77%|███████▋  | 769/996 [00:31<00:17, 13.01it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.764e+00, tolerance: 5.600e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 773, train_r2=0.0127, val_r2=-1.4784, val_cum_r2=-21.3799, val_cum_pearson=-0.0027:  77%|███████▋  | 771/996 [00:31<00:16, 13.77it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.765e+00, tolerance: 5.601e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 774, train_r2=0.0127, val_r2=-0.2589, val_cum_r2=-21.3753, val_cum_pearson=-0.0027:  77%|███████▋  | 771/996 [00:31<00:16, 13.77it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.766e+00, tolerance: 5.603e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 775, train_r2=0.0127, val_r2=-0.9812, val_cum_r2=-21.3720, val_cum_pearson=-0.0027:  78%|███████▊  | 773/996 [00:31<00:17, 13.05it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.767e+00, tolerance: 5.605e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 776, train_r2=0.0127, val_r2=-0.2140, val_cum_r2=-21.3665, val_cum_pearson=-0.0027:  78%|███████▊  | 773/996 [00:31<00:17, 13.05it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.767e+00, tolerance: 5.605e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 777, train_r2=0.0127, val_r2=-7.1997, val_cum_r2=-21.3560, val_cum_pearson=-0.0027:  78%|███████▊  | 775/996 [00:31<00:18, 12.23it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.768e+00, tolerance: 5.607e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 778, train_r2=0.0127, val_r2=-0.9867, val_cum_r2=-21.3296, val_cum_pearson=-0.0027:  78%|███████▊  | 775/996 [00:31<00:18, 12.23it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.769e+00, tolerance: 5.610e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 779, train_r2=0.0127, val_r2=-0.1506, val_cum_r2=-21.3247, val_cum_pearson=-0.0027:  78%|███████▊  | 777/996 [00:31<00:17, 12.77it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.773e+00, tolerance: 5.616e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 780, train_r2=0.0127, val_r2=-2.5648, val_cum_r2=-21.3158, val_cum_pearson=-0.0027:  78%|███████▊  | 777/996 [00:31<00:17, 12.77it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.773e+00, tolerance: 5.618e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 781, train_r2=0.0126, val_r2=-0.0335, val_cum_r2=-21.3148, val_cum_pearson=-0.0027:  78%|███████▊  | 779/996 [00:31<00:16, 12.78it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.774e+00, tolerance: 5.620e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 782, train_r2=0.0127, val_r2=0.1663, val_cum_r2=-21.3122, val_cum_pearson=-0.0027:  78%|███████▊  | 779/996 [00:31<00:16, 12.78it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.775e+00, tolerance: 5.620e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 783, train_r2=0.0127, val_r2=0.0960, val_cum_r2=-21.3001, val_cum_pearson=-0.0027:  78%|███████▊  | 781/996 [00:31<00:16, 12.78it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.775e+00, tolerance: 5.621e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 784, train_r2=0.0127, val_r2=0.0174, val_cum_r2=-21.2907, val_cum_pearson=-0.0027:  78%|███████▊  | 781/996 [00:31<00:16, 12.78it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e+00, tolerance: 5.624e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 785, train_r2=0.0128, val_r2=-0.5641, val_cum_r2=-21.2819, val_cum_pearson=-0.0027:  79%|███████▊  | 783/996 [00:32<00:16, 13.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.777e+00, tolerance: 5.627e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 786, train_r2=0.0128, val_r2=-1.7180, val_cum_r2=-21.2523, val_cum_pearson=-0.0027:  79%|███████▊  | 783/996 [00:32<00:16, 13.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.779e+00, tolerance: 5.629e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 787, train_r2=0.0128, val_r2=-1.7517, val_cum_r2=-21.1898, val_cum_pearson=-0.0027:  79%|███████▉  | 785/996 [00:32<00:16, 12.91it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.783e+00, tolerance: 5.637e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 788, train_r2=0.0127, val_r2=-1.7696, val_cum_r2=-21.1701, val_cum_pearson=-0.0027:  79%|███████▉  | 785/996 [00:32<00:16, 12.91it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.791e+00, tolerance: 5.653e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 789, train_r2=0.0126, val_r2=-0.1480, val_cum_r2=-21.1600, val_cum_pearson=-0.0027:  79%|███████▉  | 787/996 [00:32<00:15, 13.43it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.794e+00, tolerance: 5.659e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 790, train_r2=0.0125, val_r2=-0.5839, val_cum_r2=-21.1483, val_cum_pearson=-0.0027:  79%|███████▉  | 787/996 [00:32<00:15, 13.43it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.795e+00, tolerance: 5.661e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 791, train_r2=0.0125, val_r2=-0.7496, val_cum_r2=-21.1362, val_cum_pearson=-0.0027:  79%|███████▉  | 789/996 [00:32<00:15, 13.23it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.797e+00, tolerance: 5.665e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 792, train_r2=0.0125, val_r2=-20.2829, val_cum_r2=-21.1291, val_cum_pearson=-0.0027:  79%|███████▉  | 789/996 [00:32<00:15, 13.23it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.799e+00, tolerance: 5.668e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 793, train_r2=0.0124, val_r2=-0.2929, val_cum_r2=-21.1220, val_cum_pearson=-0.0027:  79%|███████▉  | 791/996 [00:32<00:15, 13.51it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.800e+00, tolerance: 5.670e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 794, train_r2=0.0124, val_r2=-0.0971, val_cum_r2=-21.1141, val_cum_pearson=-0.0027:  79%|███████▉  | 791/996 [00:32<00:15, 13.51it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.801e+00, tolerance: 5.672e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 795, train_r2=0.0124, val_r2=-0.4439, val_cum_r2=-21.0750, val_cum_pearson=-0.0027:  80%|███████▉  | 793/996 [00:32<00:14, 13.72it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.802e+00, tolerance: 5.674e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 796, train_r2=0.0124, val_r2=-0.7101, val_cum_r2=-21.0636, val_cum_pearson=-0.0027:  80%|███████▉  | 793/996 [00:32<00:14, 13.72it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.807e+00, tolerance: 5.684e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 797, train_r2=0.0123, val_r2=-0.0831, val_cum_r2=-21.0610, val_cum_pearson=-0.0027:  80%|███████▉  | 795/996 [00:32<00:14, 13.43it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.809e+00, tolerance: 5.687e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 798, train_r2=0.0122, val_r2=-0.5027, val_cum_r2=-21.0568, val_cum_pearson=-0.0027:  80%|███████▉  | 795/996 [00:32<00:14, 13.43it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.809e+00, tolerance: 5.688e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 799, train_r2=0.0122, val_r2=-2.1865, val_cum_r2=-21.0541, val_cum_pearson=-0.0027:  80%|████████  | 797/996 [00:33<00:15, 13.23it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.810e+00, tolerance: 5.689e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 800, train_r2=0.0122, val_r2=-14.7542, val_cum_r2=-21.0464, val_cum_pearson=-0.0027:  80%|████████  | 797/996 [00:33<00:15, 13.23it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.810e+00, tolerance: 5.690e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 801, train_r2=0.0122, val_r2=-3.6902, val_cum_r2=-21.0348, val_cum_pearson=-0.0028:  80%|████████  | 799/996 [00:33<00:15, 12.71it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.811e+00, tolerance: 5.692e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 802, train_r2=0.0122, val_r2=-3.1646, val_cum_r2=-21.0218, val_cum_pearson=-0.0028:  80%|████████  | 799/996 [00:33<00:15, 12.71it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.813e+00, tolerance: 5.695e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 803, train_r2=0.0121, val_r2=-0.7647, val_cum_r2=-21.0086, val_cum_pearson=-0.0028:  80%|████████  | 801/996 [00:33<00:15, 12.74it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.815e+00, tolerance: 5.699e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 804, train_r2=0.0119, val_r2=0.0550, val_cum_r2=-20.9968, val_cum_pearson=-0.0028:  80%|████████  | 801/996 [00:33<00:15, 12.74it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.817e+00, tolerance: 5.702e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 805, train_r2=0.0119, val_r2=-4.3824, val_cum_r2=-20.9922, val_cum_pearson=-0.0028:  81%|████████  | 803/996 [00:33<00:14, 13.15it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.818e+00, tolerance: 5.705e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 806, train_r2=0.0120, val_r2=-2.1187, val_cum_r2=-20.9553, val_cum_pearson=-0.0028:  81%|████████  | 803/996 [00:33<00:14, 13.15it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.819e+00, tolerance: 5.707e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 807, train_r2=0.0120, val_r2=-0.0255, val_cum_r2=-20.9389, val_cum_pearson=-0.0028:  81%|████████  | 805/996 [00:33<00:15, 12.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.824e+00, tolerance: 5.717e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 808, train_r2=0.0119, val_r2=-6.7400, val_cum_r2=-20.9206, val_cum_pearson=-0.0028:  81%|████████  | 805/996 [00:33<00:15, 12.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.827e+00, tolerance: 5.721e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 809, train_r2=0.0119, val_r2=-0.1698, val_cum_r2=-20.9138, val_cum_pearson=-0.0028:  81%|████████  | 807/996 [00:33<00:15, 12.33it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.829e+00, tolerance: 5.726e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 810, train_r2=0.0120, val_r2=-0.2215, val_cum_r2=-20.8952, val_cum_pearson=-0.0028:  81%|████████  | 807/996 [00:33<00:15, 12.33it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.830e+00, tolerance: 5.728e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 811, train_r2=0.0119, val_r2=-0.1941, val_cum_r2=-20.8560, val_cum_pearson=-0.0028:  81%|████████  | 809/996 [00:34<00:14, 12.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.833e+00, tolerance: 5.733e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 812, train_r2=0.0119, val_r2=-0.0489, val_cum_r2=-20.7959, val_cum_pearson=-0.0028:  81%|████████  | 809/996 [00:34<00:14, 12.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.838e+00, tolerance: 5.744e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 813, train_r2=0.0118, val_r2=-0.8237, val_cum_r2=-20.7734, val_cum_pearson=-0.0028:  81%|████████▏ | 811/996 [00:34<00:14, 12.45it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.847e+00, tolerance: 5.760e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 814, train_r2=0.0117, val_r2=-1.6049, val_cum_r2=-20.6824, val_cum_pearson=-0.0028:  81%|████████▏ | 811/996 [00:34<00:14, 12.45it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.850e+00, tolerance: 5.767e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 815, train_r2=0.0117, val_r2=-10.6890, val_cum_r2=-20.6340, val_cum_pearson=-0.0027:  82%|████████▏ | 813/996 [00:34<00:15, 12.19it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.862e+00, tolerance: 5.792e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 816, train_r2=0.0116, val_r2=-0.1896, val_cum_r2=-20.6207, val_cum_pearson=-0.0027:  82%|████████▏ | 813/996 [00:34<00:15, 12.19it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.869e+00, tolerance: 5.805e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 817, train_r2=0.0116, val_r2=-0.4115, val_cum_r2=-20.6181, val_cum_pearson=-0.0028:  82%|████████▏ | 815/996 [00:34<00:14, 12.37it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.871e+00, tolerance: 5.809e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 818, train_r2=0.0116, val_r2=-0.5073, val_cum_r2=-20.6146, val_cum_pearson=-0.0028:  82%|████████▏ | 815/996 [00:34<00:14, 12.37it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.871e+00, tolerance: 5.810e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 819, train_r2=0.0115, val_r2=0.0242, val_cum_r2=-20.6065, val_cum_pearson=-0.0027:  82%|████████▏ | 817/996 [00:34<00:14, 12.49it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.872e+00, tolerance: 5.811e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 820, train_r2=0.0115, val_r2=-1.7156, val_cum_r2=-20.5774, val_cum_pearson=-0.0027:  82%|████████▏ | 817/996 [00:34<00:14, 12.49it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.873e+00, tolerance: 5.813e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 821, train_r2=0.0116, val_r2=-1.2102, val_cum_r2=-20.5508, val_cum_pearson=-0.0027:  82%|████████▏ | 819/996 [00:34<00:14, 12.61it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.877e+00, tolerance: 5.821e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 822, train_r2=0.0114, val_r2=0.2102, val_cum_r2=-20.5450, val_cum_pearson=-0.0027:  82%|████████▏ | 819/996 [00:34<00:14, 12.61it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.881e+00, tolerance: 5.829e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 823, train_r2=0.0115, val_r2=-1.4170, val_cum_r2=-20.5438, val_cum_pearson=-0.0027:  82%|████████▏ | 821/996 [00:35<00:14, 12.27it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.881e+00, tolerance: 5.830e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 824, train_r2=0.0116, val_r2=-0.7105, val_cum_r2=-20.5425, val_cum_pearson=-0.0027:  82%|████████▏ | 821/996 [00:35<00:14, 12.27it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.882e+00, tolerance: 5.831e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 825, train_r2=0.0116, val_r2=-0.2589, val_cum_r2=-20.5410, val_cum_pearson=-0.0027:  83%|████████▎ | 823/996 [00:35<00:14, 11.74it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.882e+00, tolerance: 5.831e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 826, train_r2=0.0115, val_r2=-4.6618, val_cum_r2=-20.5369, val_cum_pearson=-0.0027:  83%|████████▎ | 823/996 [00:35<00:14, 11.74it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.882e+00, tolerance: 5.832e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 827, train_r2=0.0115, val_r2=-1.1308, val_cum_r2=-20.5266, val_cum_pearson=-0.0027:  83%|████████▎ | 825/996 [00:35<00:14, 11.41it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.883e+00, tolerance: 5.833e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 828, train_r2=0.0115, val_r2=-1.0874, val_cum_r2=-20.5227, val_cum_pearson=-0.0027:  83%|████████▎ | 825/996 [00:35<00:14, 11.41it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.884e+00, tolerance: 5.836e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 829, train_r2=0.0115, val_r2=-2.1417, val_cum_r2=-20.4589, val_cum_pearson=-0.0027:  83%|████████▎ | 827/996 [00:35<00:14, 11.47it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.885e+00, tolerance: 5.837e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 830, train_r2=0.0115, val_r2=-0.2247, val_cum_r2=-20.4133, val_cum_pearson=-0.0027:  83%|████████▎ | 827/996 [00:35<00:14, 11.47it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.894e+00, tolerance: 5.855e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 831, train_r2=0.0115, val_r2=0.1313, val_cum_r2=-20.3917, val_cum_pearson=-0.0026:  83%|████████▎ | 829/996 [00:35<00:15, 10.87it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.900e+00, tolerance: 5.868e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 832, train_r2=0.0116, val_r2=-1.4747, val_cum_r2=-20.3553, val_cum_pearson=-0.0026:  83%|████████▎ | 829/996 [00:35<00:15, 10.87it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.902e+00, tolerance: 5.874e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 833, train_r2=0.0120, val_r2=-0.8828, val_cum_r2=-20.3407, val_cum_pearson=-0.0026:  83%|████████▎ | 831/996 [00:35<00:16, 10.09it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.907e+00, tolerance: 5.884e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 834, train_r2=0.0119, val_r2=-0.1964, val_cum_r2=-20.3302, val_cum_pearson=-0.0026:  83%|████████▎ | 831/996 [00:36<00:16, 10.09it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.910e+00, tolerance: 5.889e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 835, train_r2=0.0118, val_r2=-1.0276, val_cum_r2=-20.2810, val_cum_pearson=-0.0026:  84%|████████▎ | 833/996 [00:36<00:15, 10.26it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.911e+00, tolerance: 5.892e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 836, train_r2=0.0119, val_r2=-0.4197, val_cum_r2=-20.2177, val_cum_pearson=-0.0026:  84%|████████▎ | 833/996 [00:36<00:15, 10.26it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.918e+00, tolerance: 5.906e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 837, train_r2=0.0117, val_r2=-1.6067, val_cum_r2=-20.2033, val_cum_pearson=-0.0026:  84%|████████▍ | 835/996 [00:36<00:15, 10.38it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.928e+00, tolerance: 5.924e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 838, train_r2=0.0116, val_r2=-3.5581, val_cum_r2=-20.1932, val_cum_pearson=-0.0026:  84%|████████▍ | 835/996 [00:36<00:15, 10.38it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.930e+00, tolerance: 5.929e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 839, train_r2=0.0116, val_r2=-0.4266, val_cum_r2=-20.1843, val_cum_pearson=-0.0026:  84%|████████▍ | 837/996 [00:36<00:15, 10.45it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.932e+00, tolerance: 5.932e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 840, train_r2=0.0115, val_r2=-0.5331, val_cum_r2=-20.1798, val_cum_pearson=-0.0026:  84%|████████▍ | 837/996 [00:36<00:15, 10.45it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e+00, tolerance: 5.934e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 841, train_r2=0.0116, val_r2=-0.9570, val_cum_r2=-20.1757, val_cum_pearson=-0.0026:  84%|████████▍ | 839/996 [00:36<00:14, 10.78it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e+00, tolerance: 5.935e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 842, train_r2=0.0116, val_r2=-0.9591, val_cum_r2=-20.1506, val_cum_pearson=-0.0026:  84%|████████▍ | 839/996 [00:36<00:14, 10.78it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+00, tolerance: 5.937e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 843, train_r2=0.0116, val_r2=-1.3953, val_cum_r2=-20.1270, val_cum_pearson=-0.0026:  84%|████████▍ | 841/996 [00:36<00:14, 10.75it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.937e+00, tolerance: 5.944e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 844, train_r2=0.0117, val_r2=-1.4070, val_cum_r2=-20.0342, val_cum_pearson=-0.0026:  84%|████████▍ | 841/996 [00:36<00:14, 10.75it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.941e+00, tolerance: 5.951e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 845, train_r2=0.0116, val_r2=-0.4677, val_cum_r2=-20.0100, val_cum_pearson=-0.0027:  85%|████████▍ | 843/996 [00:37<00:13, 11.00it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.955e+00, tolerance: 5.979e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 846, train_r2=0.0115, val_r2=-0.8291, val_cum_r2=-20.0080, val_cum_pearson=-0.0027:  85%|████████▍ | 843/996 [00:37<00:13, 11.00it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.959e+00, tolerance: 5.986e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 847, train_r2=0.0113, val_r2=-2.5473, val_cum_r2=-20.0058, val_cum_pearson=-0.0027:  85%|████████▍ | 845/996 [00:37<00:14, 10.62it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.959e+00, tolerance: 5.986e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 848, train_r2=0.0113, val_r2=-0.2521, val_cum_r2=-19.9865, val_cum_pearson=-0.0027:  85%|████████▍ | 845/996 [00:37<00:14, 10.62it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.960e+00, tolerance: 5.987e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 849, train_r2=0.0113, val_r2=-0.1858, val_cum_r2=-19.9737, val_cum_pearson=-0.0027:  85%|████████▌ | 847/996 [00:37<00:14, 10.56it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.962e+00, tolerance: 5.993e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 850, train_r2=0.0113, val_r2=-3.1653, val_cum_r2=-19.9414, val_cum_pearson=-0.0027:  85%|████████▌ | 847/996 [00:37<00:14, 10.56it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.964e+00, tolerance: 5.997e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 851, train_r2=0.0113, val_r2=-1.2787, val_cum_r2=-19.8911, val_cum_pearson=-0.0026:  85%|████████▌ | 849/996 [00:37<00:13, 10.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.969e+00, tolerance: 6.006e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 852, train_r2=0.0113, val_r2=-0.0220, val_cum_r2=-19.8897, val_cum_pearson=-0.0026:  85%|████████▌ | 849/996 [00:37<00:13, 10.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.976e+00, tolerance: 6.021e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 853, train_r2=0.0114, val_r2=-0.0819, val_cum_r2=-19.8752, val_cum_pearson=-0.0026:  85%|████████▌ | 851/996 [00:37<00:13, 10.91it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.977e+00, tolerance: 6.022e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 854, train_r2=0.0114, val_r2=-0.2338, val_cum_r2=-19.8714, val_cum_pearson=-0.0026:  85%|████████▌ | 851/996 [00:37<00:13, 10.91it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.978e+00, tolerance: 6.026e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 855, train_r2=0.0115, val_r2=-0.6939, val_cum_r2=-19.8622, val_cum_pearson=-0.0026:  86%|████████▌ | 853/996 [00:38<00:13, 10.55it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.979e+00, tolerance: 6.027e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 856, train_r2=0.0116, val_r2=-0.9375, val_cum_r2=-19.8546, val_cum_pearson=-0.0026:  86%|████████▌ | 853/996 [00:38<00:13, 10.55it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.980e+00, tolerance: 6.030e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 857, train_r2=0.0116, val_r2=-0.5481, val_cum_r2=-19.8534, val_cum_pearson=-0.0026:  86%|████████▌ | 855/996 [00:38<00:13, 10.59it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.981e+00, tolerance: 6.032e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 858, train_r2=0.0117, val_r2=-1.4052, val_cum_r2=-19.8452, val_cum_pearson=-0.0026:  86%|████████▌ | 855/996 [00:38<00:13, 10.59it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.981e+00, tolerance: 6.033e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 859, train_r2=0.0117, val_r2=-2.5947, val_cum_r2=-19.8339, val_cum_pearson=-0.0026:  86%|████████▌ | 857/996 [00:38<00:13, 10.60it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.982e+00, tolerance: 6.035e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 860, train_r2=0.0117, val_r2=-0.0033, val_cum_r2=-19.8195, val_cum_pearson=-0.0026:  86%|████████▌ | 857/996 [00:38<00:13, 10.60it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.984e+00, tolerance: 6.039e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 861, train_r2=0.0116, val_r2=-0.3333, val_cum_r2=-19.7971, val_cum_pearson=-0.0026:  86%|████████▌ | 859/996 [00:38<00:13, 10.12it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.986e+00, tolerance: 6.043e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 862, train_r2=0.0116, val_r2=-3.7908, val_cum_r2=-19.7781, val_cum_pearson=-0.0026:  86%|████████▌ | 859/996 [00:38<00:13, 10.12it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.990e+00, tolerance: 6.050e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 863, train_r2=0.0116, val_r2=-2.1630, val_cum_r2=-19.7727, val_cum_pearson=-0.0026:  86%|████████▋ | 861/996 [00:38<00:12, 10.53it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.993e+00, tolerance: 6.056e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 864, train_r2=0.0114, val_r2=-0.2060, val_cum_r2=-19.7646, val_cum_pearson=-0.0026:  86%|████████▋ | 861/996 [00:38<00:12, 10.53it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.994e+00, tolerance: 6.057e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 865, train_r2=0.0114, val_r2=-1.2193, val_cum_r2=-19.7541, val_cum_pearson=-0.0026:  87%|████████▋ | 863/996 [00:39<00:13, 10.07it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.995e+00, tolerance: 6.060e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 866, train_r2=0.0115, val_r2=-0.8069, val_cum_r2=-19.7503, val_cum_pearson=-0.0026:  87%|████████▋ | 863/996 [00:39<00:13, 10.07it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.997e+00, tolerance: 6.063e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 867, train_r2=0.0115, val_r2=-0.3482, val_cum_r2=-19.7489, val_cum_pearson=-0.0026:  87%|████████▋ | 865/996 [00:39<00:12, 10.50it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.997e+00, tolerance: 6.064e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 868, train_r2=0.0115, val_r2=-0.4230, val_cum_r2=-19.7397, val_cum_pearson=-0.0026:  87%|████████▋ | 865/996 [00:39<00:12, 10.50it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.997e+00, tolerance: 6.065e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 869, train_r2=0.0115, val_r2=0.0541, val_cum_r2=-19.7287, val_cum_pearson=-0.0026:  87%|████████▋ | 867/996 [00:39<00:12, 10.54it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.999e+00, tolerance: 6.067e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 870, train_r2=0.0115, val_r2=-0.6194, val_cum_r2=-19.6567, val_cum_pearson=-0.0026:  87%|████████▋ | 867/996 [00:39<00:12, 10.54it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+00, tolerance: 6.071e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 871, train_r2=0.0115, val_r2=0.0414, val_cum_r2=-19.6424, val_cum_pearson=-0.0026:  87%|████████▋ | 869/996 [00:39<00:12, 10.32it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.011e+00, tolerance: 6.093e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 872, train_r2=0.0116, val_r2=-0.7801, val_cum_r2=-19.6314, val_cum_pearson=-0.0026:  87%|████████▋ | 869/996 [00:39<00:12, 10.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.013e+00, tolerance: 6.097e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 873, train_r2=0.0117, val_r2=-1.0457, val_cum_r2=-19.6233, val_cum_pearson=-0.0026:  87%|████████▋ | 871/996 [00:39<00:11, 10.68it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+00, tolerance: 6.101e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 874, train_r2=0.0117, val_r2=-0.1663, val_cum_r2=-19.6166, val_cum_pearson=-0.0026:  87%|████████▋ | 871/996 [00:39<00:11, 10.68it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.016e+00, tolerance: 6.103e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 875, train_r2=0.0117, val_r2=-0.1617, val_cum_r2=-19.6088, val_cum_pearson=-0.0026:  88%|████████▊ | 873/996 [00:39<00:11, 10.42it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.017e+00, tolerance: 6.105e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 876, train_r2=0.0117, val_r2=-5.8475, val_cum_r2=-19.5730, val_cum_pearson=-0.0026:  88%|████████▊ | 873/996 [00:40<00:11, 10.42it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.018e+00, tolerance: 6.108e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 877, train_r2=0.0116, val_r2=-2.1832, val_cum_r2=-19.5060, val_cum_pearson=-0.0026:  88%|████████▊ | 875/996 [00:40<00:12, 10.01it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.024e+00, tolerance: 6.119e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 878, train_r2=0.0117, val_r2=-2.4117, val_cum_r2=-19.4334, val_cum_pearson=-0.0026:  88%|████████▊ | 875/996 [00:40<00:12, 10.01it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.035e+00, tolerance: 6.140e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 879, train_r2=0.0115, val_r2=-0.1614, val_cum_r2=-19.4251, val_cum_pearson=-0.0026:  88%|████████▊ | 877/996 [00:40<00:11, 10.18it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.046e+00, tolerance: 6.163e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 880, train_r2=0.0115, val_r2=0.0073, val_cum_r2=-19.4179, val_cum_pearson=-0.0026:  88%|████████▊ | 877/996 [00:40<00:11, 10.18it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.048e+00, tolerance: 6.165e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 881, train_r2=0.0114, val_r2=-0.1026, val_cum_r2=-19.4150, val_cum_pearson=-0.0026:  88%|████████▊ | 879/996 [00:40<00:11, 10.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.049e+00, tolerance: 6.168e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 882, train_r2=0.0114, val_r2=-1.6655, val_cum_r2=-19.3997, val_cum_pearson=-0.0026:  88%|████████▊ | 879/996 [00:40<00:11, 10.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.049e+00, tolerance: 6.169e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 883, train_r2=0.0115, val_r2=-0.1074, val_cum_r2=-19.3962, val_cum_pearson=-0.0026:  88%|████████▊ | 881/996 [00:40<00:12,  9.50it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.051e+00, tolerance: 6.173e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 884, train_r2=0.0115, val_r2=-0.0815, val_cum_r2=-19.3917, val_cum_pearson=-0.0026:  89%|████████▊ | 882/996 [00:40<00:12,  9.43it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.052e+00, tolerance: 6.175e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 885, train_r2=0.0115, val_r2=-2.0086, val_cum_r2=-19.3587, val_cum_pearson=-0.0026:  89%|████████▊ | 883/996 [00:41<00:12,  9.37it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.053e+00, tolerance: 6.176e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 886, train_r2=0.0115, val_r2=-1.3622, val_cum_r2=-19.3175, val_cum_pearson=-0.0026:  89%|████████▊ | 883/996 [00:41<00:12,  9.37it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.058e+00, tolerance: 6.187e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 887, train_r2=0.0115, val_r2=-1.5799, val_cum_r2=-19.2879, val_cum_pearson=-0.0026:  89%|████████▉ | 885/996 [00:41<00:11,  9.81it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.064e+00, tolerance: 6.200e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 888, train_r2=0.0115, val_r2=-10.0550, val_cum_r2=-19.2659, val_cum_pearson=-0.0026:  89%|████████▉ | 885/996 [00:41<00:11,  9.81it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.069e+00, tolerance: 6.209e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 889, train_r2=0.0114, val_r2=-0.6321, val_cum_r2=-19.2399, val_cum_pearson=-0.0026:  89%|████████▉ | 887/996 [00:41<00:10, 10.08it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.073e+00, tolerance: 6.216e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 890, train_r2=0.0113, val_r2=-0.9090, val_cum_r2=-19.2147, val_cum_pearson=-0.0026:  89%|████████▉ | 887/996 [00:41<00:10, 10.08it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.077e+00, tolerance: 6.225e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 891, train_r2=0.0114, val_r2=-0.5243, val_cum_r2=-19.2129, val_cum_pearson=-0.0026:  89%|████████▉ | 889/996 [00:41<00:10,  9.98it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.081e+00, tolerance: 6.233e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 892, train_r2=0.0115, val_r2=-0.1429, val_cum_r2=-19.2076, val_cum_pearson=-0.0026:  89%|████████▉ | 889/996 [00:41<00:10,  9.98it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.081e+00, tolerance: 6.233e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 893, train_r2=0.0114, val_r2=-3.8789, val_cum_r2=-19.1923, val_cum_pearson=-0.0026:  89%|████████▉ | 891/996 [00:41<00:10, 10.18it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.082e+00, tolerance: 6.235e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 894, train_r2=0.0114, val_r2=-1.5648, val_cum_r2=-19.1741, val_cum_pearson=-0.0026:  89%|████████▉ | 891/996 [00:41<00:10, 10.18it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.085e+00, tolerance: 6.240e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 895, train_r2=0.0113, val_r2=-0.2742, val_cum_r2=-19.1684, val_cum_pearson=-0.0026:  90%|████████▉ | 893/996 [00:41<00:09, 10.33it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.088e+00, tolerance: 6.246e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 896, train_r2=0.0113, val_r2=-0.9046, val_cum_r2=-19.1643, val_cum_pearson=-0.0026:  90%|████████▉ | 893/996 [00:42<00:09, 10.33it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.089e+00, tolerance: 6.248e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 897, train_r2=0.0112, val_r2=-3.2937, val_cum_r2=-19.1566, val_cum_pearson=-0.0026:  90%|████████▉ | 895/996 [00:42<00:09, 10.17it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.090e+00, tolerance: 6.249e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 898, train_r2=0.0112, val_r2=-1.1420, val_cum_r2=-19.1527, val_cum_pearson=-0.0026:  90%|████████▉ | 895/996 [00:42<00:09, 10.17it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.091e+00, tolerance: 6.252e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 899, train_r2=0.0112, val_r2=0.3333, val_cum_r2=-19.1498, val_cum_pearson=-0.0026:  90%|█████████ | 897/996 [00:42<00:10,  9.83it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.092e+00, tolerance: 6.253e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 900, train_r2=0.0111, val_r2=-2.5397, val_cum_r2=-19.1475, val_cum_pearson=-0.0026:  90%|█████████ | 897/996 [00:42<00:10,  9.83it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.092e+00, tolerance: 6.254e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 901, train_r2=0.0112, val_r2=-5.4324, val_cum_r2=-19.1359, val_cum_pearson=-0.0026:  90%|█████████ | 899/996 [00:42<00:09,  9.83it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.092e+00, tolerance: 6.255e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 902, train_r2=0.0112, val_r2=-0.7700, val_cum_r2=-19.1301, val_cum_pearson=-0.0026:  90%|█████████ | 900/996 [00:42<00:09,  9.70it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.094e+00, tolerance: 6.258e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 903, train_r2=0.0112, val_r2=-2.7494, val_cum_r2=-19.1247, val_cum_pearson=-0.0026:  90%|█████████ | 901/996 [00:42<00:09,  9.57it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.095e+00, tolerance: 6.260e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 904, train_r2=0.0112, val_r2=-3.3719, val_cum_r2=-19.1175, val_cum_pearson=-0.0026:  91%|█████████ | 902/996 [00:42<00:09,  9.47it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.096e+00, tolerance: 6.262e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 905, train_r2=0.0111, val_r2=-2.3888, val_cum_r2=-19.1144, val_cum_pearson=-0.0026:  91%|█████████ | 902/996 [00:43<00:09,  9.47it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.098e+00, tolerance: 6.264e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 906, train_r2=0.0111, val_r2=-2.7194, val_cum_r2=-19.1101, val_cum_pearson=-0.0026:  91%|█████████ | 904/996 [00:43<00:09,  9.62it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.098e+00, tolerance: 6.266e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 907, train_r2=0.0110, val_r2=0.1662, val_cum_r2=-19.1080, val_cum_pearson=-0.0026:  91%|█████████ | 905/996 [00:43<00:09,  9.51it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.099e+00, tolerance: 6.267e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 908, train_r2=0.0110, val_r2=-0.1407, val_cum_r2=-19.1042, val_cum_pearson=-0.0026:  91%|█████████ | 905/996 [00:43<00:09,  9.51it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.099e+00, tolerance: 6.268e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 909, train_r2=0.0110, val_r2=-0.0682, val_cum_r2=-19.1000, val_cum_pearson=-0.0026:  91%|█████████ | 907/996 [00:43<00:09,  9.35it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.100e+00, tolerance: 6.269e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 910, train_r2=0.0110, val_r2=-6.0814, val_cum_r2=-19.0830, val_cum_pearson=-0.0026:  91%|█████████ | 908/996 [00:43<00:09,  9.30it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.101e+00, tolerance: 6.270e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 911, train_r2=0.0110, val_r2=-4.5865, val_cum_r2=-19.0810, val_cum_pearson=-0.0026:  91%|█████████▏| 909/996 [00:43<00:09,  8.96it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.103e+00, tolerance: 6.276e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 912, train_r2=0.0111, val_r2=-1.9312, val_cum_r2=-19.0731, val_cum_pearson=-0.0026:  91%|█████████▏| 910/996 [00:43<00:09,  9.00it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.104e+00, tolerance: 6.276e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 913, train_r2=0.0111, val_r2=-2.1499, val_cum_r2=-19.0645, val_cum_pearson=-0.0026:  91%|█████████▏| 911/996 [00:43<00:09,  9.04it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.105e+00, tolerance: 6.279e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 914, train_r2=0.0110, val_r2=-1.8419, val_cum_r2=-19.0620, val_cum_pearson=-0.0026:  92%|█████████▏| 912/996 [00:44<00:09,  9.06it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.106e+00, tolerance: 6.282e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 915, train_r2=0.0110, val_r2=-0.9165, val_cum_r2=-19.0572, val_cum_pearson=-0.0026:  92%|█████████▏| 912/996 [00:44<00:09,  9.06it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.107e+00, tolerance: 6.283e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 916, train_r2=0.0110, val_r2=-0.4475, val_cum_r2=-19.0540, val_cum_pearson=-0.0026:  92%|█████████▏| 914/996 [00:44<00:08,  9.70it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.108e+00, tolerance: 6.284e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 917, train_r2=0.0109, val_r2=-3.0051, val_cum_r2=-19.0240, val_cum_pearson=-0.0026:  92%|█████████▏| 914/996 [00:44<00:08,  9.70it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.109e+00, tolerance: 6.285e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 918, train_r2=0.0109, val_r2=-6.4107, val_cum_r2=-18.9987, val_cum_pearson=-0.0026:  92%|█████████▏| 916/996 [00:44<00:07, 10.04it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.114e+00, tolerance: 6.295e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 919, train_r2=0.0108, val_r2=-0.1053, val_cum_r2=-18.9967, val_cum_pearson=-0.0026:  92%|█████████▏| 917/996 [00:44<00:08,  9.83it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.118e+00, tolerance: 6.304e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 920, train_r2=0.0107, val_r2=-4.8830, val_cum_r2=-18.9496, val_cum_pearson=-0.0026:  92%|█████████▏| 917/996 [00:44<00:08,  9.83it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.118e+00, tolerance: 6.304e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 921, train_r2=0.0107, val_r2=-2.3775, val_cum_r2=-18.9139, val_cum_pearson=-0.0027:  92%|█████████▏| 919/996 [00:44<00:07, 10.14it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.127e+00, tolerance: 6.320e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 922, train_r2=0.0105, val_r2=-1.0966, val_cum_r2=-18.9129, val_cum_pearson=-0.0027:  92%|█████████▏| 919/996 [00:44<00:07, 10.14it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.133e+00, tolerance: 6.332e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 923, train_r2=0.0103, val_r2=-1.9216, val_cum_r2=-18.8501, val_cum_pearson=-0.0027:  92%|█████████▏| 921/996 [00:44<00:07, 10.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.134e+00, tolerance: 6.332e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 924, train_r2=0.0103, val_r2=-1.0990, val_cum_r2=-18.8075, val_cum_pearson=-0.0027:  92%|█████████▏| 921/996 [00:45<00:07, 10.32it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.144e+00, tolerance: 6.353e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 925, train_r2=0.0102, val_r2=-1.1670, val_cum_r2=-18.7989, val_cum_pearson=-0.0027:  93%|█████████▎| 923/996 [00:45<00:07,  9.40it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.152e+00, tolerance: 6.368e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 926, train_r2=0.0101, val_r2=0.0688, val_cum_r2=-18.7899, val_cum_pearson=-0.0027:  93%|█████████▎| 924/996 [00:45<00:07,  9.10it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.153e+00, tolerance: 6.371e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 927, train_r2=0.0102, val_r2=-61.7530, val_cum_r2=-18.6989, val_cum_pearson=-0.0026:  93%|█████████▎| 925/996 [00:45<00:07,  9.08it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.154e+00, tolerance: 6.374e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 928, train_r2=0.0102, val_r2=-1.6177, val_cum_r2=-18.6838, val_cum_pearson=-0.0026:  93%|█████████▎| 925/996 [00:45<00:07,  9.08it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+00, tolerance: 6.404e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 929, train_r2=0.0106, val_r2=-3.3231, val_cum_r2=-18.6445, val_cum_pearson=-0.0026:  93%|█████████▎| 927/996 [00:45<00:07,  9.38it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.171e+00, tolerance: 6.410e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 930, train_r2=0.0106, val_r2=-0.9136, val_cum_r2=-18.6314, val_cum_pearson=-0.0026:  93%|█████████▎| 927/996 [00:45<00:07,  9.38it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.177e+00, tolerance: 6.423e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 931, train_r2=0.0108, val_r2=-0.7436, val_cum_r2=-18.5932, val_cum_pearson=-0.0026:  93%|█████████▎| 929/996 [00:45<00:06,  9.80it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.179e+00, tolerance: 6.428e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 932, train_r2=0.0109, val_r2=-2.1616, val_cum_r2=-18.4541, val_cum_pearson=-0.0026:  93%|█████████▎| 930/996 [00:45<00:06,  9.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.186e+00, tolerance: 6.441e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 933, train_r2=0.0107, val_r2=-2.1606, val_cum_r2=-18.4067, val_cum_pearson=-0.0027:  93%|█████████▎| 930/996 [00:45<00:06,  9.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.212e+00, tolerance: 6.489e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 934, train_r2=0.0102, val_r2=-2.2309, val_cum_r2=-18.3972, val_cum_pearson=-0.0027:  94%|█████████▎| 932/996 [00:46<00:06,  9.46it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.222e+00, tolerance: 6.506e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 935, train_r2=0.0096, val_r2=-2.1430, val_cum_r2=-18.3876, val_cum_pearson=-0.0027:  94%|█████████▎| 932/996 [00:46<00:06,  9.46it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.223e+00, tolerance: 6.510e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 936, train_r2=0.0097, val_r2=-4.6377, val_cum_r2=-18.3478, val_cum_pearson=-0.0026:  94%|█████████▍| 934/996 [00:46<00:06,  9.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.225e+00, tolerance: 6.513e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 937, train_r2=0.0098, val_r2=-1.2547, val_cum_r2=-18.3229, val_cum_pearson=-0.0026:  94%|█████████▍| 934/996 [00:46<00:06,  9.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.231e+00, tolerance: 6.527e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 938, train_r2=0.0101, val_r2=-0.7775, val_cum_r2=-18.3204, val_cum_pearson=-0.0026:  94%|█████████▍| 936/996 [00:46<00:05, 10.10it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.235e+00, tolerance: 6.536e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 939, train_r2=0.0101, val_r2=-0.3064, val_cum_r2=-18.3198, val_cum_pearson=-0.0026:  94%|█████████▍| 936/996 [00:46<00:05, 10.10it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.235e+00, tolerance: 6.537e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 940, train_r2=0.0101, val_r2=-4.6160, val_cum_r2=-18.3183, val_cum_pearson=-0.0026:  94%|█████████▍| 938/996 [00:46<00:05,  9.77it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.236e+00, tolerance: 6.537e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 941, train_r2=0.0100, val_r2=-3.0147, val_cum_r2=-18.3153, val_cum_pearson=-0.0026:  94%|█████████▍| 938/996 [00:46<00:05,  9.77it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.236e+00, tolerance: 6.537e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 942, train_r2=0.0100, val_r2=-0.2172, val_cum_r2=-18.3145, val_cum_pearson=-0.0026:  94%|█████████▍| 940/996 [00:46<00:05,  9.79it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.237e+00, tolerance: 6.538e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 943, train_r2=0.0100, val_r2=-12.9397, val_cum_r2=-18.3054, val_cum_pearson=-0.0026:  94%|█████████▍| 941/996 [00:47<00:05,  9.66it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.237e+00, tolerance: 6.539e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 944, train_r2=0.0100, val_r2=-0.7659, val_cum_r2=-18.3026, val_cum_pearson=-0.0026:  94%|█████████▍| 941/996 [00:47<00:05,  9.66it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.238e+00, tolerance: 6.542e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 945, train_r2=0.0101, val_r2=-0.3488, val_cum_r2=-18.3005, val_cum_pearson=-0.0026:  95%|█████████▍| 943/996 [00:47<00:05,  9.72it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.238e+00, tolerance: 6.543e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 946, train_r2=0.0101, val_r2=-0.5200, val_cum_r2=-18.2950, val_cum_pearson=-0.0026:  95%|█████████▍| 943/996 [00:47<00:05,  9.72it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.239e+00, tolerance: 6.544e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 947, train_r2=0.0101, val_r2=-2.3428, val_cum_r2=-18.2916, val_cum_pearson=-0.0026:  95%|█████████▍| 945/996 [00:47<00:05,  9.53it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.240e+00, tolerance: 6.546e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 948, train_r2=0.0101, val_r2=-1.4066, val_cum_r2=-18.2861, val_cum_pearson=-0.0026:  95%|█████████▍| 946/996 [00:47<00:05,  9.45it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.240e+00, tolerance: 6.547e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 949, train_r2=0.0101, val_r2=-0.2976, val_cum_r2=-18.2772, val_cum_pearson=-0.0026:  95%|█████████▍| 946/996 [00:47<00:05,  9.45it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.241e+00, tolerance: 6.549e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 950, train_r2=0.0101, val_r2=-0.6684, val_cum_r2=-18.2697, val_cum_pearson=-0.0026:  95%|█████████▌| 948/996 [00:47<00:04,  9.84it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.243e+00, tolerance: 6.552e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 951, train_r2=0.0102, val_r2=-4.3083, val_cum_r2=-18.2587, val_cum_pearson=-0.0026:  95%|█████████▌| 949/996 [00:47<00:04,  9.69it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.244e+00, tolerance: 6.555e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 952, train_r2=0.0102, val_r2=-8.5109, val_cum_r2=-18.2404, val_cum_pearson=-0.0026:  95%|█████████▌| 950/996 [00:47<00:04,  9.54it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.246e+00, tolerance: 6.559e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 953, train_r2=0.0101, val_r2=-0.8552, val_cum_r2=-18.2398, val_cum_pearson=-0.0026:  95%|█████████▌| 951/996 [00:48<00:04,  9.44it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.250e+00, tolerance: 6.565e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 954, train_r2=0.0099, val_r2=0.1873, val_cum_r2=-18.2380, val_cum_pearson=-0.0026:  95%|█████████▌| 951/996 [00:48<00:04,  9.44it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.250e+00, tolerance: 6.565e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 955, train_r2=0.0099, val_r2=0.0558, val_cum_r2=-18.2368, val_cum_pearson=-0.0026:  96%|█████████▌| 953/996 [00:48<00:04,  9.60it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.250e+00, tolerance: 6.566e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 956, train_r2=0.0100, val_r2=-0.4133, val_cum_r2=-18.2320, val_cum_pearson=-0.0026:  96%|█████████▌| 954/996 [00:48<00:04,  9.49it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.251e+00, tolerance: 6.567e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 957, train_r2=0.0100, val_r2=-7.5620, val_cum_r2=-18.2024, val_cum_pearson=-0.0026:  96%|█████████▌| 955/996 [00:48<00:04,  9.41it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.251e+00, tolerance: 6.568e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 958, train_r2=0.0100, val_r2=-11.9718, val_cum_r2=-18.1940, val_cum_pearson=-0.0026:  96%|█████████▌| 956/996 [00:48<00:04,  9.34it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.256e+00, tolerance: 6.579e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 959, train_r2=0.0101, val_r2=-3.0760, val_cum_r2=-18.1927, val_cum_pearson=-0.0026:  96%|█████████▌| 956/996 [00:48<00:04,  9.34it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.258e+00, tolerance: 6.582e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 960, train_r2=0.0101, val_r2=-9.5115, val_cum_r2=-18.1813, val_cum_pearson=-0.0026:  96%|█████████▌| 958/996 [00:48<00:03,  9.55it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.258e+00, tolerance: 6.582e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 961, train_r2=0.0101, val_r2=-10.4050, val_cum_r2=-18.1739, val_cum_pearson=-0.0026:  96%|█████████▌| 958/996 [00:48<00:03,  9.55it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.260e+00, tolerance: 6.586e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 962, train_r2=0.0100, val_r2=-4.0448, val_cum_r2=-18.1706, val_cum_pearson=-0.0026:  96%|█████████▋| 960/996 [00:48<00:03,  9.66it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.262e+00, tolerance: 6.589e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 963, train_r2=0.0100, val_r2=-1.3085, val_cum_r2=-18.1686, val_cum_pearson=-0.0026:  96%|█████████▋| 961/996 [00:49<00:03,  9.54it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.263e+00, tolerance: 6.590e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 964, train_r2=0.0099, val_r2=-0.4118, val_cum_r2=-18.1640, val_cum_pearson=-0.0026:  97%|█████████▋| 962/996 [00:49<00:03,  9.45it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.263e+00, tolerance: 6.591e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 965, train_r2=0.0098, val_r2=-2.5583, val_cum_r2=-18.1563, val_cum_pearson=-0.0026:  97%|█████████▋| 963/996 [00:49<00:03,  9.37it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.264e+00, tolerance: 6.593e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 966, train_r2=0.0099, val_r2=-0.0732, val_cum_r2=-18.1514, val_cum_pearson=-0.0026:  97%|█████████▋| 964/996 [00:49<00:03,  9.30it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.265e+00, tolerance: 6.596e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 967, train_r2=0.0099, val_r2=-2.5665, val_cum_r2=-18.1432, val_cum_pearson=-0.0026:  97%|█████████▋| 965/996 [00:49<00:03,  9.26it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.266e+00, tolerance: 6.597e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 968, train_r2=0.0099, val_r2=-1.0088, val_cum_r2=-18.1313, val_cum_pearson=-0.0026:  97%|█████████▋| 966/996 [00:49<00:03,  8.87it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.267e+00, tolerance: 6.600e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 969, train_r2=0.0099, val_r2=-1.9273, val_cum_r2=-18.1107, val_cum_pearson=-0.0026:  97%|█████████▋| 967/996 [00:49<00:03,  8.94it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.270e+00, tolerance: 6.605e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 970, train_r2=0.0099, val_r2=-1.5634, val_cum_r2=-18.0813, val_cum_pearson=-0.0026:  97%|█████████▋| 968/996 [00:49<00:03,  8.65it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.274e+00, tolerance: 6.612e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 971, train_r2=0.0098, val_r2=-1.2567, val_cum_r2=-18.0701, val_cum_pearson=-0.0026:  97%|█████████▋| 969/996 [00:50<00:03,  8.79it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.279e+00, tolerance: 6.623e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 972, train_r2=0.0097, val_r2=-0.1808, val_cum_r2=-18.0668, val_cum_pearson=-0.0026:  97%|█████████▋| 970/996 [00:50<00:02,  8.89it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.282e+00, tolerance: 6.627e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 973, train_r2=0.0097, val_r2=-0.0208, val_cum_r2=-18.0632, val_cum_pearson=-0.0026:  97%|█████████▋| 971/996 [00:50<00:02,  8.95it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.282e+00, tolerance: 6.628e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 974, train_r2=0.0096, val_r2=-0.3932, val_cum_r2=-18.0568, val_cum_pearson=-0.0026:  98%|█████████▊| 972/996 [00:50<00:02,  9.01it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.283e+00, tolerance: 6.630e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 975, train_r2=0.0096, val_r2=-1.1616, val_cum_r2=-18.0532, val_cum_pearson=-0.0026:  98%|█████████▊| 972/996 [00:50<00:02,  9.01it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.284e+00, tolerance: 6.632e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 976, train_r2=0.0096, val_r2=-0.0412, val_cum_r2=-18.0501, val_cum_pearson=-0.0026:  98%|█████████▊| 974/996 [00:50<00:02,  9.70it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.285e+00, tolerance: 6.633e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 977, train_r2=0.0095, val_r2=0.0857, val_cum_r2=-18.0450, val_cum_pearson=-0.0026:  98%|█████████▊| 974/996 [00:50<00:02,  9.70it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.286e+00, tolerance: 6.634e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 978, train_r2=0.0096, val_r2=-1.6858, val_cum_r2=-18.0339, val_cum_pearson=-0.0026:  98%|█████████▊| 976/996 [00:50<00:02,  9.75it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.286e+00, tolerance: 6.636e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 979, train_r2=0.0096, val_r2=-0.0016, val_cum_r2=-18.0296, val_cum_pearson=-0.0026:  98%|█████████▊| 977/996 [00:50<00:01,  9.61it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.288e+00, tolerance: 6.640e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 980, train_r2=0.0095, val_r2=-2.9705, val_cum_r2=-18.0219, val_cum_pearson=-0.0026:  98%|█████████▊| 978/996 [00:50<00:01,  9.47it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.289e+00, tolerance: 6.642e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 981, train_r2=0.0095, val_r2=-0.0172, val_cum_r2=-18.0204, val_cum_pearson=-0.0026:  98%|█████████▊| 979/996 [00:51<00:01,  9.43it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.291e+00, tolerance: 6.645e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 982, train_r2=0.0096, val_r2=-0.3607, val_cum_r2=-18.0187, val_cum_pearson=-0.0026:  98%|█████████▊| 980/996 [00:51<00:01,  9.35it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.291e+00, tolerance: 6.645e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 983, train_r2=0.0096, val_r2=0.0050, val_cum_r2=-18.0149, val_cum_pearson=-0.0026:  98%|█████████▊| 980/996 [00:51<00:01,  9.35it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.291e+00, tolerance: 6.646e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 984, train_r2=0.0096, val_r2=-0.3706, val_cum_r2=-18.0140, val_cum_pearson=-0.0026:  99%|█████████▊| 982/996 [00:51<00:01,  9.55it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.292e+00, tolerance: 6.647e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 985, train_r2=0.0096, val_r2=-2.4547, val_cum_r2=-18.0133, val_cum_pearson=-0.0026:  99%|█████████▊| 983/996 [00:51<00:01,  9.45it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.292e+00, tolerance: 6.648e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 986, train_r2=0.0096, val_r2=-0.4538, val_cum_r2=-18.0001, val_cum_pearson=-0.0026:  99%|█████████▉| 984/996 [00:51<00:01,  9.37it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.292e+00, tolerance: 6.648e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 987, train_r2=0.0096, val_r2=-3.2278, val_cum_r2=-17.9915, val_cum_pearson=-0.0026:  99%|█████████▉| 984/996 [00:51<00:01,  9.37it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.294e+00, tolerance: 6.653e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 988, train_r2=0.0096, val_r2=-0.6078, val_cum_r2=-17.9861, val_cum_pearson=-0.0026:  99%|█████████▉| 986/996 [00:51<00:01,  9.56it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.296e+00, tolerance: 6.656e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 989, train_r2=0.0097, val_r2=0.0904, val_cum_r2=-17.9816, val_cum_pearson=-0.0026:  99%|█████████▉| 987/996 [00:51<00:00,  9.15it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.297e+00, tolerance: 6.658e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 990, train_r2=0.0097, val_r2=-1.4759, val_cum_r2=-17.9754, val_cum_pearson=-0.0026:  99%|█████████▉| 988/996 [00:52<00:00,  9.17it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.297e+00, tolerance: 6.660e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 991, train_r2=0.0098, val_r2=-1.9396, val_cum_r2=-17.9721, val_cum_pearson=-0.0026:  99%|█████████▉| 989/996 [00:52<00:00,  9.16it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.298e+00, tolerance: 6.662e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 992, train_r2=0.0098, val_r2=-1.5237, val_cum_r2=-17.9684, val_cum_pearson=-0.0026:  99%|█████████▉| 989/996 [00:52<00:00,  9.16it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.299e+00, tolerance: 6.663e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 993, train_r2=0.0097, val_r2=0.1008, val_cum_r2=-17.9661, val_cum_pearson=-0.0026:  99%|█████████▉| 991/996 [00:52<00:00,  9.73it/s] C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.300e+00, tolerance: 6.664e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 994, train_r2=0.0097, val_r2=0.0223, val_cum_r2=-17.9606, val_cum_pearson=-0.0026: 100%|█████████▉| 992/996 [00:52<00:00,  9.56it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.300e+00, tolerance: 6.665e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 995, train_r2=0.0097, val_r2=-0.0298, val_cum_r2=-17.9560, val_cum_pearson=-0.0026: 100%|█████████▉| 993/996 [00:52<00:00,  9.49it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.301e+00, tolerance: 6.667e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 996, train_r2=0.0098, val_r2=-0.1610, val_cum_r2=-17.9535, val_cum_pearson=-0.0026: 100%|█████████▉| 994/996 [00:52<00:00,  9.04it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.302e+00, tolerance: 6.669e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 997, train_r2=0.0098, val_r2=-0.6292, val_cum_r2=-17.9478, val_cum_pearson=-0.0026: 100%|█████████▉| 995/996 [00:52<00:00,  9.06it/s]C:\\Users\\specf\\AppData\\Local\\Temp\\ipykernel_31804\\1223702891.py:18: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self.reg.fit(X, y)\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.302e+00, tolerance: 6.670e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "Validation on day 998, train_r2=0.0098, val_r2=-0.6115, val_cum_r2=-17.9461, val_cum_pearson=-0.0026: 100%|██████████| 996/996 [00:52<00:00, 18.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from pipeline.backtest import cross_validation\n",
    "from visualization.metric import plot_performance\n",
    "idx = pd.IndexSlice\n",
    "table = [21, 24, 25, 29, 33]\n",
    "model = KernelModel(0.1, 'linear', None)\n",
    "performance_ev, comparison = cross_validation(model, list(set(features) - {'return'}),  df = df_with_return.loc[idx[:, table], :])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from qids_lib import QIDS\n",
    "qids = QIDS(path_prefix='../../')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Day 1700, test cum pearson -0.0244: 100%|█████████▉| 699/700 [00:48<00:00, 14.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Feeding is finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<visualization.metric.Performance at 0x186966dec10>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pipeline.backtest import evaluation_for_submission\n",
    "\n",
    "evaluation_for_submission(model, dataset, qids, lookback_window = 50)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07617050653234414\n",
      "PearsonRResult(statistic=-0.031619997583683924, pvalue=0.025684793960168387)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0YAAAGsCAYAAAD5ZLfVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOz9eXSk6VkejF+176v2rdXLdPds9ng8Nl7wOIZgJ0CIwfDhhPwgnJAQB0Li8AEJh8Q/Qgg+CZsdwI6BgEMCxIH44/sBJsaQgCfePZ4Zz0z39KbWLpVq3/eq3x+3Lt2vqktqSa2S1K3nOkenW6qqt973eZ/3ee7luq/b1u12uzAwMDAwMDAwMDAwMDjFsB/3CRgYGBgYGBgYGBgYGBw3jGNkYGBgYGBgYGBgYHDqYRwjAwMDAwMDAwMDA4NTD+MYGRgYGBgYGBgYGBicehjHyMDAwMDAwMDAwMDg1MM4RgYGBgYGBgYGBgYGpx7GMTIwMDAwMDAwMDAwOPVwHvcJHDY6nQ5WV1cRCoVgs9mO+3QMDAwMDAwMDAwMDI4J3W4XxWIRk5OTsNt3zwk9cI7R6uoqZmZmjvs0DAwMDAwMDAwMDAxOCJaWljA9Pb3rex44xygUCgGQiw+Hw8d8NgYGBgYGBgYGBgYGx4VCoYCZmZktH2E3PHCOEelz4XDYOEYGBgYGBgYGBgYGBnsqsTHiCwYGBgYGBgYGBgYGpx7GMTIwMDAwMDAwMDAwOPUwjpGBgYGBgYGBgYGBwamHcYwMDAwMDAwMDAwMDE49jGNkYGBgYGBgYGBgYHDqYRwjAwMDAwMDAwMDA4NTD+MYGRgYGBgYGBgYGBicehjHyMDAwMDAwMDAwMDg1MM4RgYGBgYGBgYGBgYGpx7GMTIwMDAwMDAwMDAwOPUwjpGBgYGBgYGBgYGBwamHcYwMDAwMDAwMDAwMDE49jGNkYGBgYGBgYGBgYHDqYRwjAwMDAwMDAwMDA4NTD+MYGRgYGBgYGBgYGBicehjHyMDAwMDAwMDAwMDg1MM4RgYGBgYGBgYGBgYGpx7GMTIwMDAwMDAwMDAwOPUwjpGBgYGBgYGBgYGBwamHcYwMDAwMDAwMDAwMDE49jGNkYGBgYGBgYGBgYHDqYRwjAwMDAwMDAwMDA4NTD+MYGRgYGBgYGBgYGBicejiP+wQMDO4Ft24BKyuAwwFcugSMjBz3GRkYGBgYGBgYGNyPMI6RwX2Ja9eA3/s94AtfAPJ5wGYDJieBr/s64G/+TWB8/LjP0MDAwMDAwMDA4H6CcYwM7jtcuwb80i8BL74I+P3A2bNAswkkEsDHPgZkMsD3fq9xjgwMDAwMDAwMDPYOU2NkcN/hT/8UuHFDaHPnzgHBIBCLAQ8/DDidwJe+BDz//HGfpYGBgYGBgYGBwf0E4xgZ3Fe4dQv46lcBtxsIhe58fWQEKJeBZ58FksmjPz8DAwMDAwMDA4P7E8YxMrivUK0ClYo4Rh7Pna8HAkCnI+9rNI7+/AwMDAwMDAwMDO5PGMfI4L6Czyd1RY0GUK/f+Xq5DNjt8j63++jPz8DAwMDAwMDA4P6EcYwM7itcuAC8+tXiGBWLd76eTErW6KmnjHS3gYGBgYGBgYHB3mFU6QzuO7zjHaJM9+KLkiEaGVFVOpsNeP3rgde85rjP0sDAwMDAwMDA4H7CwDNGH/rQh3Du3Dl4vV489dRTeOaZZ3Z878c//nG8/e1vx8jICMLhMN70pjfhk5/85KBP0eA+w+XLwA/9EPD2t4sK3fw8sLoKjI0B7363keo2MDAwMDAwMDDYPwaaMfrYxz6G9773vfjQhz6Er/3ar8VHPvIRfOM3fiOuXLmCM2fO3PH+T3/603j729+On/mZn0E0GsVv/uZv4lu+5VvwhS98AU8++eQgT9XgPsPly8C//JeiUreyAjgcwKVLhj5nYGBgYGBgYGBwMNi63W53UAd/wxvegNe+9rX48Ic/vPW3Rx55BN/6rd+K97///Xs6xmOPPYZ3v/vdeN/73ren9xcKBUQiEeTzeYTD4QOdt4GBgYGBgYGBgYHB/Y/9+AYDo9I1Gg08++yzeMc73rHt7+94xzvw2c9+dk/H6HQ6KBaLiMfjO76nXq+jUChs+zEwMDAwMDAwMDAwMNgPBuYYpVIptNttjI2Nbfv72NgY1tfX93SMn//5n0e5XMZ3fud37vie97///YhEIls/MzMz93TeBgYGBgYGBgYGBganDwMXX7DZbNt+73a7d/ytH373d38XP/mTP4mPfexjGB0d3fF9P/7jP458Pr/1s7S0dM/nbGBgYGBgYGBgYGBwujAw8YXh4WE4HI47skMbGxt3ZJF68bGPfQzf933fh9/7vd/DN3zDN+z6Xo/HA4/Hc8/na3D/ol4HOh1p7GqmgoGBgYGBgYGBwUEwsIyR2+3GU089hU996lPb/v6pT30Kb37zm3f83O/+7u/ie7/3e/E7v/M7+OZv/uZBnZ7BA4BaTWS65+eB27dVtrtWO+4zMzAwMDAwMDAwuN8wULnuH/7hH8Z3f/d343Wvex3e9KY34Vd/9VexuLiI97znPQCEBreysoLf+q3fAiBO0fd8z/fggx/8IN74xjduZZt8Ph8ikcggT9XgPkOtJjLdtRoQCAAulzR5zWaBahWYmgK83uM+y+OFyaQZGBgYGBgYGOwdA3WM3v3udyOdTuOnfuqnsLa2hscffxyf+MQnMDs7CwBYW1vD4uLi1vs/8pGPoNVq4Qd/8Afxgz/4g1t//7t/9+/iox/96CBP1eA+QyYjTlEspn9zu+Unm5XXJyeP7/yOE7WaXH+xCLTb0uMpFALiceMsGhgYGBgYGBjshIH2MToOmD5GDz7qdaHNeTziCPWi0ZD3nD17+jIlO2XSymVxikwmzcDAwMDAwOA04UT0MTIwGBQ6HcmEuFz9X3e55PVO52jP6yTAmklzuwGbTf6NxTSTZGBgYGBgYGBgcCeMY2Rw38FuF3pYs9n/9WZTXrefstldrwt9LhDo/3ogIK/X60d7XgYGBgYGBgYG9wNOmelo8CDA45GamXK5/+vlsrx+2mh0JpNmYGBgYGBgYHBwGMfI4L4EhQSyWakp6nbl32xW/h6PH/cZHj1MJs3AwMDAwMDA4OAwJpLBfQkKCcRiQg3L5+XfWOz0CgyYTJqBgYGBgYGBwcExULluA4NBwusVSW7Tr0cRj0sfp2y2vyrdacykGRgYGBgYGBjsBcYxMrjvcdqdISuYSWMfo0pF6HOxmOljZGBgYGBgYGCwG4xjZGDwgMFk0gwMDAwMDAwM9g/jGBkYPKAwzpCBgYGBgYGBwd5hxBcMDAwMDAwMDAwMDE49jGNkYGBgYGBgYGBgYHDqYRwjAwMDAwMDAwMDA4NTD+MYGRgYGBgYGBgYGBicehjHyMDAwMDAwMDAwMDg1MM4RgYGBgYGBgYGBgYGpx7GMTIwMDAwMDAwMDAwOPUwjpGBgYGBgYGBgYGBwamHcYwMDAwMDAwMDAwMDE49jGNkYGBgYGBgYGBgYHDq4TzuEzAYHOp1oNMB7HbA4znuszEwMDAwMDAwMDA4uTCO0QOIWg3IZIBiEWi3AYcDCIWAeBzweo/77AwMDAwMDAwMDAxOHoxj9IChVgNWVuTfQABwuYBmE8hmgWoVmJoyzpGBgYGBgYGBgYFBL0yN0QOGTEacolgMcLsBm03+jcU0k2RgYGBgYGBgYGBgsB3GMXqAUK8LfS4Q6P96ICCv1+tHe14GBgYGBgYGBgYGJx3GMXqA0OlITZHL1f91l0te73SO9rwMDAwMDAwMDAwMTjqMY/QAwW4XoYVms//rzaa8bjd33cDAwMDAwMDAwGAbjIn8AMHjEfW5crn/6+WyvG6kuw0MDAwMDAwMDAy2wzhGDxgoyZ3NAo0G0O3Kv9ms/D0eP+4zNDAwMDAwMDAwMDh5MHLdDxi8XpHkZh+jSkXoc7GY6WNkYGBgYGBgYGBgsBOMY/QAwusFJidFfa7TkZoiQ587OMw4GhgYGBgYGBg8+DCO0QMMY8TfG9j3qVgUNT+HQ2q0TObNwMDAwMDAwODBg6kxMjDog1oNWFmR2ixAmuQC8vvKirxuYGBgYGBgYGDw4MBkjAzugKGOSaYon5f/p9M6HsGgjI/PJ3RFAwMDAwMDAwODBwPGMTLYgqGOCep1IJWSceh0AL8fcDqBVkucJbtdfh8aOr2Oo4GBgYGBQT+Y4KrB/QzjGBkAUOpYrQYEAoDLJQ1hs1mgWhWlu5PqHB32ItzpiIPY6QDRqP7d5QIiESCX09cNDAwMDAwMTHDV4MGAcYwMAMhiVquJrDfhdstPNiuvnzTq2KAW4WZTjh0M9n/d7QZKJXmfz3fw7zEwMDAwMHgQcL8EV002y+BuMI6RAep1cS4Cgf6vBwLyer1+chaSQS7CLpd8ttEQGl0vGg153eW6t2swMDAwMDB4EHDSg6smm2WwVxhVOgN0OrJQ7GTou1zy+mFQx+p1cVzq9Xs7jnURdrsBm03+jcV0ATwo7HZZLB0OqSlqNoFuV/7N5+Xv8bi8z8DAwMDA4DRjP8HV44BVZdbjEUq8x2NUZg36w2SMDGC3i7HfbKostRXNprx+L47AYUZrBp3h8niA4WERWwCENletyvVHIvK34eGTkz0zMDAwMDA4LuwluFqpHF9d7knPZhmcLBjHyAAejzgp2Wx/x6hclgXloI6AlfbmdMp3tNsHp73ttAiTO2yz3XuGKx6XcyNVz+GQY7Zacq7x+MGPbWBg8GDC1C8YnEYcRXD1oLgfSwUMjhfGMTIAoI5ANru9ZqdcvndH4LB7AvUuwrWaKMWVStudpqmpg4sjeL3yeWa5Gg35zljMcJINDAy2w9QvGJxmHGZwdRAqsyc5m2Vw8mAcIwMAdzoClcrhOAKD6AlkXYQ7HWB9Xb6Hx06n5biplLz3oOfu9YrDZqLABgYGO+F+UeMyMBgk7jW4OqjgwknOZhmcTBjHyGALg3AEBtUTiIvwwoIsbEND4mwVCpKJGh+X1w+DO/ygOUPG0TMwODyY+gUDg3sLrg4yuDDoUgGDBw/GMTK4A4e5QAyqJ5DXKwIIKyti5BeLKo4QjcrrdrvhDlth6D4GBocLU79gYKA4aHB10MGFQZYKGDx4MI6RwUDR2xOo0dAF0+2+t55Abrc4R16vyGn3LsKGO6wwdB8Dg8OHqV8wMLgT+wkCHEVwYVClAgYPJoxjZDBQsCfQ+jpw65Y6Rfw3EhHa20H4veQO08nqheEOKwzdx1AIDQ4fpn7BwODecFTBBVMzbLBXGMfIYKDweIRGt1MDNdLsDtpvyHCH747TTvcxFEKDQcGsQQYG94ajDi6YZ9HgbjCOkcGRwOUSA8Lp1IxRq3XvHacNd/juOM10H0MhNBg0zBpkYHBwmOCCwUmDcYwM7hm7pabrdTESzp+XBS6T0ah9PC6p7Wbz4NkKwx2+O04z3cdQCA0GDbMGGRjcG0xwweAkwThGBgfGXihKzFbs5PQ4nepYHRSGO7w7TmtE7rRTCA2ODmYNMjA4OExwweAkwThGBgfCXilKdrtQ5pJJMRhIp2OD12JRFr/DyFYMyhB5EIyd0xiRO80UQoPjwf26PhicLDwIe85+YYILBicFxjEy2Ia9Lkp7pSh5POIE5XLAzIy+lw1el5bEWTqJC+CDVLR/GiNy/SiE1vltsz24FEIDA4P7Dw/SnnNQnERbwOB0wThGx4yTEh3Zz4K8H4oSIBmiaFQyRH6/ZowqFfk76XSHcf2HNZ4PYtH+aYvIWSmEnY4456WSXnu7DczOPthjYGBwVDgt68qg8CDuOQYG9yOMY3RMOEmRof0uyPulKDmdwPS0OEalkhyTPYwikXuvMeI1HOZ4PshF+6fJaInHxSG6dk3mRDgsfy8UZM5Vq3KfjcFhcBg4jc7BSdrL7mc8yHuOgcH9BOMYHQNOWmRovwvyflXOHA75GR+/03BoNO6dznTY42mK9h8ceL3643DIHLHbgeFhyVZWq4MxOPoZyKfRaD4tOK3OwUnby+5XmD3HwODkwDhGx4CTFBk6yIK8X5Uz63t7F/XDUEQ77PE0RfsPDigXf+4c0O3e6ZjY7YdrcPQzkDmPms3TZTSfFpxm5+Ak7WX3M8yeY2BwcmDKjo8Y+63PGTT6Lcj1umzo9br8vd2+c0GmUZfNStan25V/s9k7Vc728979YhDjac2I9cOD0PfHeo8fZFjnt8cD+HzbHaCd5vdBQAM5m5XviETk79euAdevy7yPROS1bFaNaYP7G1bnwO0WUQ+3W36no/wg4qTtZfczTsOeY2Bwv8BkjI4YRxUZ2ittx7og9ytQpzHZuyDvR+VskIpogxjPB7nvz2mj/PTSPnufi8M0OPpFzymHDsg8DIdNRP1BwmmmQJksx+HhQd5zDAzuNxjH6Iix3/qc/WK/hi8X5PV1+Wy9vl05bn0dGBmRaHcv9qNyNihFtEGN54PY9+c0Un6s8xvY7vQHg/K38fF7n4v9DOR6Xb7P79fvpoFcr8u8TKeBoSFj8NyvOM3OwaD3stOGB3HPMTC4H2GWrCMGDbVyuf/r5fLB+/r0o/LshbYTj4tK18qKbGRWOe2REVmUd6OD9KMo7fZeu10MhcOgWHg8simn0/2Pd9DxZJYrFpPj5vPybyx2/zoQp5Xy4/dLJnRpSR0iu11+z+XUcbkX9DOQOx35cTrlhyp46+vy3WtrwOKiodTdzzjNFKhB7mWnEQ/inrMXnBZat8H9A5MxGjD6ZUgGFRk6SCFsrSYGWj4vztDSkpxnNCrnEY0eXoH6YdO4rMdLJuU6RkZEcczhuPfxZJarUJCxcTpV7vl+w2mm/LBfVjQqWZtSSeY0Gw7z9XtBv+i53S4/rZb83mwCGxuSffX7VQwin5f/P8jGz4OK006BMlmOw8Vp6jV32mjdBvcPjGM0INztoT/smpuDGL7MMDFqPjUl51KpaFNWr1eMtnuhg9Tr8vm1NTnWYdC4rLSwcFiOmUqJg5TLARMT4iD1jud+Nhw6jYWCnLfPJ0b1/bhwnzTKz1Ft/Hwu4vH+NUaNxuE4hP0MZI9HslP5vPzebstzRVGGfF6e+bExU290P+M0OweDrB89zXhQnSFiN1o392+//8EfB4OTCeMYDQB7reU4zMjQXg3falW/b21NIth+v9Cq2m0x5GjM5XJSf3FQOgidw3RaxqNaBWZnxcEgjeugRej9smMzM8DoqLwWCm0/3n6jU7kccOWKfIZ0vXpdjJ2TWo+z21w6KfUARx0l7H0uesflMB3CfgZyIAAkEjK+LpfM/WZTvpOZWeDBztg96DjtzsFpynIYHA767d+k16+uil0yMWEySAbHA+MYDQD7obQd1gZyN8O3VJKMSrst1J7VVeDWLa0PoujC+fPyN79fi8Urlf3TQWo1Of7Ghvx/Y0Oi5bduSSZndlYXu/0ahbtlxzweKWav1/V4+xUdqNXEKUomxTG01lzx/Hy+kxPd34uzcRIoP8ch/nCUDuFOBvLly3LNt2/LdTockjViRhZ4sIv0TwOMc3D6rtfgYOi3f9dqUntZr8u62G7L3x9kYSCDkwvjGB0yjquWYzfDt1YD5uZkYXG7xeBfXpb3jo/LOXW7sjA1GsCFC+IY1eti5LHeaD9YXdV6Jb9ffrxeOZfVVfn/7Ky8d79G4X5pYfutvVpbk7+Nj+t3uFxizObzYtielOj+fpyN46b8HEczyKN2CHcykOt1pdJ5vXd+34NcpH+acNzrgYHBSUe//TuXkzUyEhFbpFiUtZJrt6EZGxwlzDZ8yNiL0X5YDSV7sVMj1YUFoa7NzoohmE5LXc7UlGRC6nVxAsbH5f2plByj3ZZj7jdaU6+L42W3qzKewyHnEA4rjY8qNPs1CvejBLXfJoT1utQUeTyyMPfC7xfjnpTE48Z+lOaOU/XoOJtBDrLB8E7oVWpkJrPT6W88GwUvAwOD0wDr/l2vi1OUyag6aKulwjWAaRRscPQYuGP0oQ99COfOnYPX68VTTz2FZ555Zsf3rq2t4bu+67tw+fJl2O12vPe97x306R06jlO+tZ/hWyzK9509K0ZzJiOGYSgkhhsg2ZVGQ+k9Pp/UGV2+DJw7t3+DuVqV76WCm9utDgUgxy6V9Pf9GoX7kYndr6Pa6cj4eDyqJmaF0yljZbMdf3T/IM4GMxpnz8q9PXtWfh80TeE4AwYnRQb3OBw0AwMDg5MEj0fW+9u3hVWytCQskmxWqfvBoNoDg9wbDAz6YaBUuo997GN473vfiw996EP42q/9WnzkIx/BN37jN+LKlSs4c+bMHe+v1+sYGRnBT/zET+AXf/EXB3lqA8M26o6jDXzhC1JgMzoKvOENKJcdA63l6KXysJFkKCSOSLstRj2lp2koRqNiSHc64ljMzEjx42EhElFD3m6/d6OwlxbW6cjxqlW5Lh7P6qhSHtnK/+91VO12rbmqVFRBjGCGLRw+/uj+QZTm2DMC2HvvqcPAcYs/nIQakNNepG9gYHB/YRDrZa2mPw6H7kPJpLBZJie3t08wNGODo8ZAHaNf+IVfwPd93/fh7//9vw8A+MAHPoBPfvKT+PCHP4z3v//9d7z/7Nmz+OAHPwgA+I3f+I1BntpAEY8D1T/4JLI/9e8QSNyCC0004UJ57AK87/vniP+9vzbwc+AiZjVI+f9uVwx8t1sLHdttcZBqNfHhZmYObqj5fOKIFQoitMDzGR2V71hZEaPdbj+4Uej1yrEpIsHsUyi03ZmxRqccDl3kg0G59mp1e42JNRvFxZq1WXa71GGNjByu03hQ7MfZYG3X8rIY5YBc5/T00WSMToL4A8/jOHESHDQDAwOD3TBI9VCyVi5fFhpdqaR7s9erP8SD3gusH8z+cLwYmGPUaDTw7LPP4l/8i3+x7e/veMc78NnPfvbQvqder6Nu4QoVCoVDO/ZB4f3ExzH1g38HGURRRAgV+OFAG7HEK4j/4LfCO/7bwLvedSTnYjVI6YRks7LwMUV95ow4E7mcvOeRR+7MlOz3O6engWvXxBHy+zWjY7OJY/HQQyLycJCHnot2KiXGfrUq1zU6Kk5ZuSzO19SUvp/RKdL7UilJ5M3M3Jmt4hixJxIzbQ6HjNWjj56M6P5enY1uV8Q3FhbkGoaG5PVCAbh+XcbvwoXBX9Nxiz8AJ2fDMZudgYHBScQg1UOt9G+3W+qa63UJcm5siI1Qqch32+2noxeYFabp7cnAwByjVCqFdruNsbGxbX8fGxvD+vr6oX3P+9//fvzrf/2vD+1494x2G/in/xRe1DCJddSRQQd22NGBB5uewXvfC7zznTLrjwC9BunQkBjJdJa8XjGSAXFoDmMRmpyUh3xpSSW7+aDPzsrrB3WKuGhXqyo0UKnI9Xg88juVbIA7o1OMTLXb4kj1W3AoYjA8LMdutYR+ODZ2shaovTgbmYz00vF6tzu8w8PiuG5syJgdlurPTs5HL5Usl1NBjomJwY6r2XD2h5PiQBoYGBwtBqke2o/+7fHID+sv19dlbwgEThfN+DjaWRj0x8Dlum0227bfu93uHX+7F/z4j/84fviHf3jr90KhgJmZmUM7/r7xzDPCV9qEB43tr3e74i088wzwtrcdySn1GqSxmCxOhYIYPqXS4dOqSBnK5cSxCATkb6GQPPDp9J0p837oNdC4aPv9cgwuIJTSZlPaQEBeB+Q7rdEpHs9m297viGCqf3ZWnIZ2WxfuREI+d/bsyTAa71a3YrPJOHQ6Qh/sBftVpdPyOimO95LJ2835oLNWr8v7WWuWyQxuAzQbzt5hHEgDg9OLQbcb2Yn+Xa/LXhAMCitjZuZoa2BPAo6jnYVBfwzMMRoeHobD4bgjO7SxsXFHFule4PF44DlJT8/a2uG+75Dg9UqmiJKYjz4q/w6yEJ/iBUNDmnEJheS1uz3otZoMUaEgC6bPJwsE1e6oUmOV1Pb75Zi8FioD9kanrN9RLssY8O/cGJxObTgXicjv5bKc09ycvCcSORlG4251K9Wq1pf1kx9n89qVFfmsy3UwY3ivzof1fZHI0TgpZsPZG4wDaWBwunEQQZ/9oJf+XattZ3KUShqcPUlm3aBxXP0vDfpjYI6R2+3GU089hU996lP4tm/7tq2/f+pTn8I73/nOQX3t8WOvVflHWL2/WxTYqv5ymKjXpY6nWt1usJfLqoC304OeywFXrsg5ezyygLJBJhcP9jlotWSxZj+EZFIbaXa7Ynz3Rqe4GFtrrSoVGY9uVz7P8yb1rF6X97tccg2tlpzbSTIa+y2Ydrucc6ejY2VFuSxZsFBIzj8YPJgxvFfn46idFLPh7B3GgTQwON04CvVQ0r/X19Umcbtlf2LglDXCx72nHhUG7ZAa7A8DFUD84R/+Yfz6r/86fuM3fgNXr17FP/tn/wyLi4t4z3veA0BocN/zPd+z7TPPP/88nn/+eZRKJSSTSTz//PO4cuXKIE/zcPH008JJ24kuaLNJnvjpp4/kdBgFZv0NG65msxodpoTzYTZQq1Qku0J1N/YVyudlQaQSXu+DXquJU5RMikhDMChDls8L5apcFofL45HXKhU5740NcXY8Hs0ocYG3NjktFID5eXWgxsc1grWyIt/RbsuxmF0D5PubTclGhcMyXt1u/0aqJwlsLGq3y1j1IpGQ652dlXHYrUHsTtir81EoHH2T12pV5sxOG4rpkSE4zga8BgYG2zGIPXkv2E+PwIOC9G9A23d0OhIwnZmRPfkk76mDwHH2vzS4EwOtMXr3u9+NdDqNn/qpn8La2hoef/xxfOITn8Ds7CwAaei6uLi47TNPPvnk1v+fffZZ/M7v/A5mZ2cxPz8/yFM9PDgcwAc/CHzHd4iV2e3qa3SWPvCBIxNe2C0KvL4uBn8gcPj1BLmcPMzRqEZBrLVAqZS81vugr63JOcdicgwatXa7nKPdLk7N6Kh8vlaTkq5WS86fjWSDQVlgqSq3vi7ns7ysmZ9oVN5vjYqXy1p3w2walXK8XtmsIhGVFwVOftaBmcHFRbk+SqinUjI+s7P9M4d7va69RrtaraOLinFjTadlTlFoJBrdPrfNhiMwEUsDg+PHSajxOwr1UJtNjn3xorA7eutaT/qeetg4Ke0sDAQDNwd+4Ad+APPz86jX63j22Wfx1re+deu1j370o/iLv/iLbe/vdrt3/Nw3ThHxrncBv//7wNQU6nCjCi/qcEsm6fd//8ikuneLAtdq8trqqvzu9YoPl0hoJulevrfRkIxPvyyF3y/Ojdu9/UGv1yWrYLPJ5lAoyHuCQU21F4tarG+3i6Hb7arhTeW18XFdxF0uOdbqqjhlwaBkUaiCw2vlYhwKSWYonZYNod1W58jtlvMnlQ842VkHbrRspJfLiUT3+rqM/ezszlLde72uvUa7nM6jiYpZs6ShkMwF9ulaX98+tw8jAvogwEQsDQyOF3thdxwFmNGJxbQBfL0uvx8WvY2BmGCwf33zSd5TBwU6v9ms2BsUJspmT5dk+UnAwFXpTitq3/QuZF7/ThT/95fRTiThGBtB6Oteh/iIA0dFm90tCpzLKbc3nRangpkZyiifPy/v3a90L793eFgcLfYyYqF/uSz/781SdDqyGNRqsiBYFwKXSxbmpSU5B6uymccjTlgsppuJ9XM0fsfGJGsSDut7rEp2jIqHQtJnaWFBv6PVkvMdGhIni1xo4OQajdZi+nBYzn12Vmu3pqdl0d0pebnX69prtCsclkzcoKNivVlSbvD1un7/0NDp65GxG/rdQ+tzX6mYiKWBwSBxkmr8Bt2I+ihqme433E1h9rTUW50EGMdoAFCD1IHAW9+g6k4FoNo4uqLC3aQxSyVxQtJp+TcaFWelUpHXrlxRit1+0/r8XodD6WylkjghNpt8dnh4ew2P9XOtVv/jtlryHi7atZpkgWw2ea1QUK4yz69UkvdNTMgY+HzbF1vS5up1OQ4X48lJGZdCQZyuUEjGanlZxsJmEyeNEtjj4yfPaOy30YZC8pNIyH11u8VBuFdHZa/0i93eZ7PJ/bkX+kS/LKnXq/OQfTLcbnGOzIajsBZFN5vqTNbr8hrrAgxOHk5q36mTel4nDSdVJGZQ33UU1LH7ce71qgefNsnykwLjGA0AJyXys9Pi0+nITzothunIiCwiyaQ4Ru22OBzVqtCsSEfbq1qZ9XtZ19FoaN8a1jVZy6/4OdLUvF7ZCLxezTQlk+JQxeNynpmMXMfYmIo85PPyPaTSlUrqcAHiyOTzqjbndMr1dDp6z7gQTU3JwlQsitGeTMrfz5yRz7OBbSik2bWTgnpd7q/TuX0ztSryra7K2DUaavwelE9us8l7czk51k7Rrn5RsVZL5dzX1u6NV79TlpTOUTQq5zgzMzhFxvsV3JQTie2KkOHw/nqPGRwdTkJNyqDP6340cPeL01jjN6happP6TNwN9+t5P4gwjtEho2/kp90GvvAFYGMDgdgYik98DepDjiNZ5PstPq2W/F6vC7WKqm7NptYaORxiOI+MiAFJtbK9Onf9JDn9fjHCed39JDmHh8XpaDTkHJjdouF+9qy8n6IKsZg4L+22bBxOpzg+7bZG2apV4PZt+V5uPKT3UZ67UBAD0LoYW6M3nQ7wyCNy/aWSOlzsJVypnAxDm07J+rrQBv1+GUdyuXnfKXnOf2s1GQPWAe01fd9vMXe7Vdii3xy30jSoXuhwHE7vnLtRNHjNPt/ej3lQ3I8GHXuPTUzcee5Gsvtk4aT2nTqs8zpNhuJppJYNgjo2yGdikOv5SX2WTyuMY3TIuCPy84lPAO97H7AmKgcuAJWxy+j84j8F/va3Dvx8dlp8xsbUeUgm5SFk3cz6ujz8zIqwBofYS1qfdLmNDVWZ63TEWGbztkJBDFSroRWJaH2PwyHfb7PJuY2OyiLhdovjROfT65XjLyzo4tJoyPunpuTcmVGiGITXq72JYjEZD+tibN2U6eAx+8Vr4QLZaBy/gg7PN5XSbF+zKQ4RM2lLS3J9IyO60VKsIpuVezM+vveFf6fFnEqCd3M+PB6lch5WdvUkqPvsxaA7iU6TNajTb+xOm1LUScdJYSYM4rxOm6F4VOvWSVt3DruWaRDPRK8tYLNJEHVi4vDm4El9lk8rjGN0yNgW+fmzTwD/4O9ve70JFxyJFdi/692A53ePRKGu3+IzPi5Zj7U1cRZ8Pll82XuoXpfMUiCgjg0XrLul9a1SyZmMHJuiCsmk9kjweuU9gYBS24A763s8Hm0O6/WKc7K2ps5nraZKPrOzsnDNzckxul3ta1SpiPFfLsvxQiHJCE1Pb//+3k253ZaxyOVkYRwd3c79PW6ag/V86TjGYpIxWloSOqTPJ78PDclnmBngNQQCcs/3szHd62I+KF79UcjN7oS7GXRDQzL2J9FpOo10nvsVJ7Um5bDO6zQaioNct0569u0w5uggngmu5+xjyJrLpSWxQR599N6ZIif1WT7NMI7RIWMr8pNuw/1jP3bH62UEEEMWHjSA7/9+4J3vPLKeRtaHyuORzMz16/LwVyqyAFBCkxmEalV+Jif187ul9a2GoculNUO3bskxWSMEyMN+65Zsfo89dmcdCut7arXtKXaKJJB2wLoWOjd0fMbHtVGeVQSi3ZZzuXy5f9SHm7LPJ//PZKTugrU4Y2NyfsGg9mI6TpoDz9fvV0fT5RKH79YtuR8jI0oDTKX03In9Gr2HsZgPyhA/TnWfu/UNSyRknh7UaRokTiOd534FGxefNCf2MJ7p02ooDmrdOi3Zt0HsJ5mM1i3X67LHBgISKF1fF5Gq17723sbPBKROHoxjNADE40D1zz6PbLaDAFxwoYkmXCgjAC/qiCMrb0yngb/4C+Cv/tV9f8dhRJUnx9qoffrLyH+5jnWMwjV9ERMTji2pbGZZbDbJ3tCQ3i2tbzUM63VZ2AsFWYhtNnnIaXSFw/L3VOrOCODdUuykHXS7YuxbFe7KZTXgHA55PRZTR6ndlr9RoKF3XItFqbVZX5ff3W4591JJziGTEUeDC6bdLr8fB6xGBPs+ODefao9HhCKYpWs05D2zs+Lc3Uuj050Wc94vm+3ufSgGaYgPWm62H+5m0DWbMneokAjs3Wk6CuPlJNAQDXbHSW9cfBjP9Gk2FAexbp2E7NtRrMOHvZ9wPWemyMoqcbnEfkgm5Tk8d+7knLfBvcM4RgOA1wtMXf0zZJBFESFU4IcDbcSQRRxZeFHXN+/TMbrXlPjWAvX/+wN4f+SHcH45iZt4G1J4HSbCTXT+zncg/JbXY3hYvmNlRQy5YlEWgU7nTpEC67GthiFVrdbXxYGJRLRPkNutUXKnUzb6oaE7F82dFlHSDjIZjeQ0m5oVqlaFOubxyDkPD8v/WRPUK9tNcFOuVnUx3NjQmqlGQxwiGomvvKIiA/Pzg6NF7XScTkfOlTLndrv8S6MiEJD3jI4qLbKftPh+jd7exZy1aKXSdsOGmb9+OApD/KRQ0UjB4HzsxW5O01FSh46ThmiwO6yRfzYuTqfvVOIEjs+JPYxn2hiKh3ffjjv7dpQUvsPeT7i30r7ohdOptdL3Mn6mh9zJg3GMBgSvs4VJrKOODDqww46O0OfuAfeSEs/nZRMtlwHH//pTON77zxFCCwG4MY4kzmAZvkIdgQ//NHzxH0HrjU9vdbvO58UBKJXEebFGTqzoZxiGw7IY5vOyGDYaKt3tdmuj1mZzfxFA0g7sdnHYslkdo1BIXq9W5fViUZ0bdpYOh/sf126Xa8jlhG7WaMjCFA6Lc5fJyBiur8t7fD4Zj0hEPnvYtKjdNhZAzmN9Xf5OcYlqVTNYdJZ8Pvlctyvv9/vld2vt1n6MXuti3ulodo2NfNNpOXYqJe/tl5nrdGQePyiG+G4GXaej2cdeg+5uTtNRUodMk8Gjx16DJ/dL4+J7da5N5vLwcBzZN87nRkPW/6Ok8B1mYMduF+YDVVx70WrJ/Ox27338TA+5kwXjGA0Kb3sb8NM/fXdn6G1v2/MhD5ISZxPUmzc3FyhfG9Gf/nkE0EUWMWQRQxc2zGIRDXjQgAelD/8X2F/zZoTDDrhcsrhNTIhctdcri0yv1DYf4nZ7u2Ho80m2gpt3pyMLSjQqzobdLn9zufYfAfR6NYWdyahzFQrJ/9tt+Xs0KovO3JwarkD/DA97KZVK8jku8k6nLJJ+v4x/sSifnZqS/3e7B6NF7WYU7eYI53LaByoWU9W9alWc0EZDxrdWk+vIZuXvzKRVq3JvJiZEnGFycv+bFBfzhQU5r6EhbbQbDEoEm1k9zst+jp7LpY1dj8sQP4zM3m4Gnd0u3xEO33n83ZwmYO/Gy2FlJ4+DhngasZ9o+v3UuPgwnOvTkLm8H+llu6F3PqdSSt0+qiz4YQZ2PB5Zr5eWtrMwCIo57cQ+2e95W3vItVpy3lTxPYwecmY93zuMYzQovO1tMtPT6Z3fMzS0Z8fIujH2m+D9oso0rBcX5fepKaD1hedQSNVQxxDGsY48wqjDgwiKqKCNYaTRyazDvvEccudfh1JJjj0xoVkW68IWjwvHtlBQJblUShZDynJPTMgiksuJkzQ2pgtlPi/X0Y9Gt1dMTMhxXnpJHJhCQcanUhEHgb17MhlxpB57TGhxOzkrw8Oy2KXT8q/NJu9hhMjvl++IxTQjY10Ye2lRvF9+vzamjcfvbhTt5ghfuya/X768vY+Tw6EZMrtd+1Y5nSoocemSUgIprnEQkF64siLXVyyqzDtrHpixq9dlfuwk700jj87BUS3ch0312Mmgq1S0gW4vdnOagLsbL4Oiq5jNc3DYb/b/fmtcfK/O9YOcubyf6WU7oXc+dzoanFxfv7Oed5BZ8MMM7ExMiH3Da2Cz+UpF+yKGQodzDazn7nblfrXbsl+3WnItva1N9oqTrkh4EmEco0HB4QB+9VeBb//2nd/z9/7enhXpaOiXStonxm5XdTHSqKxR5UxGDHhGHmw2wJVLIYIC8ggjhwjiyKKIIOpwoQEXMogggiJcaxkUhlW4IBzevogFArIQXr+uogQUKSgU5O9nz8oDyL4oDodebqOhDszMzL1HAFnobz1+qSTjMzOjWZ14XMaPdLt+0StrLyVKfhcKsjCGw+JQeL3qIPl8GvUHdJxoIGcy2xckOond7s5GUaMhFMF+CxcXfP6ffZxu3JAfqlVduiTKdLmcHGtkRBwZQK47GJRr2diQzx9k0XW75ZhsDNy7CVmzHdns7hnPcnlnmuYgMAi1pt0MuuFhuQ+JhPy+F6cJ2N14OS2KUwfFSY2S7jf7f5IaF+8HJnO5HcfxvB5F9q13PrPuNRqVPbK3FyL3hWr1YPd2L3PiMOaK1yuS3FeuyNpNO8fvl2uIRA5n/Op1mRe3b2OrhMHjkf+vrkqQ1umUPZvsmnvpNWj2h91hHKNB4l3vAn70R4Gf/dn+r//czwFvfOOeehnRUAbkYWTkgoW38fj2qDIzTD6fvIdKZRgeAgD4UUEJQfhQRQFhrGEUqxjfFIrowr9yFnWIYe33awYiGFRH4KWX5PczZ7ZHUuhEbWyos/KqV8nfkklNooVCcvyD0LisyGTk3C5cUClvZnu6XW12OjSktDrrQt0vemXtpRQOy0LSbMr7bDa5XjahbbdVnY4ZK7cbWF6W/7fbShnMZuUYDz8sjiNhpeHl83LchQW51+XydtUpbgj8P/s41evi/Fy4IN/L+h1GnEghtIK0wZ3EL+4Gq1T5blQNjt1JkuAdlFpTr0HXaMg9zOV0HEjFJDVzakruwV6NFx57ff34FadOIk5ylPQgBfGnue7msK/pOB2t41CIG3T2rd98pghQqaTKsNb5zLYRfDb3+nwex3MdjYokt5UZw5rdw/reTkf2+1ptez2Rzyc/8/PAV74if+N1Dw/fvcnsSVAkvB9hHKNBot0Gfvd3d3/Pe9+7p15G1p4V1n8jETGk19aEVsWFh9QL0pm2OLJPvhYYHYNzYwN5eHET57GIadgADCGLOPIoBqdRHL2AalH7GgUCcg63bqnc9cqKODyUZ7aeTywmRt/k5PZmqOfPK3XL+veDgotyLCYLVj6vRiUXjGJRzndmZrv0NhfqfjUcvb2Uul1ZyAsFGU8asVNT8t3sbZDLyb0IBmWcPB55jY5jJiPjNjt757XUamo0z85qj6Re1Sk6WYAKPhSLMoVoQDOTmMvJj98v19tobDesnE45xn7FL4i9Gmwu18mS4D0KtSaPR+6btQA5GJTx4HiNj2uWzOu9u/HS24V9fV3e4/PduUE+qP1e7oaTHiU9aEH8Sa67uR+yOsftLB+nQtwgs2+987lWk6DoxobMzaGh7cqwtZrU+3q9Mv57fT6P87lmPfOg5jnFU/rRYMl+WVwU28Xj0fl75gzw5JP9P3fcioT3M4xjNEg88wzqyxvowNtfla7blcq+Z57ZtdaIE3xyUuVZqf7VamkmoDdiw0g+KVORCOSPP/qjaP3oj6OIIFKIw4kOhpBDCEU04ELnH383lqcd2NiQRahalUUom5UHs9GQ82CNzcaG1A7x4fL75XOUx+5tLHuYD6F1UY5GVTaaktytlowd09+AjBtFClwuOUa/wnfrZkJOMWljiYSmvVdWlH9MyuDysmTDrOp3Lpe85vVqU1rrWORy6ohSfpz3LZ/XLJfHs/1cSyU5JvsvFYvyvW63zIm1NfnuRuNOY6vVOrj4BbEXg623KW8vjlqC96jUmnaK2I2N3UkfvJvx0msYMNJaLsu19PL4H+R+L7vhpEdJD1oQfxLrbo7b2dgrToKzfBL6Mw3CALbO52pVaPS5nLzWaIiJ4/HInmm3y35ks+1flOEkPNeDciAcDtm7KahkRTotATDWIDEAUirJWAPAm9505/w9CfPtfoVxjAaEWg3IXMmiiFm04YADbYRQvLOPESArxS7gBI9EZDJbe/VQuKCXykQubDotG0GtZnGovu6vIvnjv4Dsr/wPuAopuNGEF1VgeATu97wHja/5WjhW5Pu6XTHyYzEtBmSNE7NC1apkUigR7XTKgmizbaf2MVNEUQArHeygERjrosxCZMpE53Ly/+FhGaN2Wz6TyYhT43LJOdZqQmsbG+t/Dh6PjGO3K++p1+W409Oy2C8syMLFGp6zZ2UTbjTkvOjAVqtyrPFxzQLx+6ja53breNDRowPH6E+rJedB+XDKiZKq5/erQ0ZZbtINW63t11ap3Lv4xV4NtpNEBToKtaaDRux2GoNew6Db1UAD69asPP7T0O+lF/dDlPReaHEnqe6mX8F9oyFrIp0Nm+34zxM4XKP6oGM/yDXnOOcD5/P6ujhBbIDudMrf5+fl3NJp2YPdbtkjvd47z3un5/N+eK7vBU7n9hYfXq8GcBcW5N9YTN7DuUMHaXFRxrO3yazpB3ZwGMdoANjaMHxTCKAOF5powoUsYqjCjymsbHeOJiZ2PV4/49+6oFBrnxPcGsVjZ2YqXpVK8mN/01sw9oY3ofvyS6gn8nBOhoUX53CgW1dpao9H/k+Du9HQTJHPp0pnjHy73VrTQrnouTkpICwUVLmMNTNut9ZaHCTS2Gtk2GyyKNMRo2MUjcrCvbICvPyyvHdmRsbQ65Ux+cpXhEvcm5buXZRZ11OtymfPn1dnhQpjfr+8nz2b7HYZj3BYnLalJTkWa5BIZaOUORd3yvGWSuIgRaNyfVwU19bkHpfLushZs3flskbyqlUZn9FRrQPrdOS8KZe926ay2+a7F4PNmllyOrU+q9U6eirQUdRsHGbErp9h4PFoNpi1YtZ7+CDXneyEwxrzezE09/LZw+j1c9ygs+Hzyf/ZjsFuVypVPH78maTDMqrvNTs2iDXnpGTs4nHJXrAhPIOB7bbUvJIJ4fPpfF9f3z5ngkGxISikZMV+n+uTEDjYD8JhCbTeuiXjUKmojUHp7qmpO+dwMCj7fyol+29vgO0kBSPvJxjHaADYik59w1PAxAiwtgY3mnAjhyyiyCCGSayLlTo9DTz99K7H6zfBrZM5m9UJbo3ihcPyIKVS8vC4XBJxoFpcIuHAsvsJ1IpAyw+4NsucKBnZbMr7YjHNEDkc8jqjEOwOzUWw2ZQFj07RM8/I+VCxzO2W91y7Ju+ZmFBKUCYjn71wYX/qZPG4jMG1a7oY1moSoaLT5fHItb/4oiyas7PynXRWPB5xVubmxDmyondRpgR1oyHf3e3KAs86j9VVuU7KWddqWttjs2k91le+In8HVJ3s4sXtogx0hItFGZNz57bT86x9nGZmdO6xUe2tW/L6I4/Id25syHW6XLKQUrRjbW3nTXU/m+9uiyx7NczNyTlwTEZHB0tl2WmTHHTNxmFG7HYyDJhVJJ2u3Vaxh+OuO9kJgzRa7nXM78XQ3M9nTyItbj+gs+F03tncuVyWNXBxUdZSGrvHVeN1GM7yYVHxDnPNOQn0QIKB1HhcxrFUkmeMaqWtluwxDBg6nXK+1pKAfF7rhXufz70+12zPcdyO4kFw/rwEQYtFVb0D5JqCwZ2bvDocMub95u9Jrks8yTCO0SFjW3TK4QB+6qeAf/APANgAdBFAGUWEUEdWao4+8IE9SXbvdYL3owzMzIjxyf45NKZbLXGaSiX5DB9EGvBchOJxeTi5mOXzqtpWLGoGhRLU4bBshuvrkhGJx2XjYV0Ss1ydjrx/fl5reEol+f01r9mfWp3Ntv13t1syKx7P9p49gYBs1sGgDHswqJ8ZGhLHgUp0RL9F2fp9dAxJU6OEdbUqjkmxKONTr6tTxOyb2633slQSh+H8+Tuvu9WS67FmemhYTkzoPRgakuPkcpKCb7eBxx+XrJDXK05XtSrXCajzvNOmepibL51Vj0fmoDVjdBgN7Pp9326G6k7Gqd8vDkfvnCL2atjvFLHj5wuFnembvdjJMKDjnEzK99BBP4kG9lFEt+8lSnovc52Z8WpVI993++xJosXtF3Q2qlU5f2sgq1LRmtQbN5TeHAzeWz+Wg+IwAhSHRcU7TIf4JNTcEKzTnZzcXk9KJU722gsEdJ169avvFJJaWurfF2gvz7XPt13oZtCO4mE/t9GoSIM//7wGDm02ZZD0O3fWF/v9/efvIAMw9+O6tVcYx+iQcUd06pu+Cfi1XwP+1b8C1tfgQhMV+NGZmkH9538WnW/8Vtj3wIvtN8HbbXkgKAiwG2WAGZN6XSkD8bgYZoWCHLfRUGPYbpdju93yYJbLYry6XPLZsTE9r9VV+X1sTAxtqsO12+JMOZ2yQA0Py3dxMS+Xt2d5zp3TepiXXpLF7MKFuz+8mYx85+XLdz6spACOj4ujRnodey9Vq3LONILL5TvrcHoX5U5HNvlWS5w49ktiTdXwsGwQzM4wm1apqJDDxATw9V8vx+b5nj8PvPCCUP1e97o7nV+/X8a6n2HJuZFOa/Ruelqum72LeC0ej9Is71YAexib727S0sRhb+R7NXJ7BTYo3NEvg9arCGezydyJx3duTNtLH6TTSgcmEpHj3m2O72YYeL0y/0ZH1Qg9aRvVUUa39xpE6l0rDjrXazXpc7K6KvehXFaJfSoQ7ja3T9q92guYkc7ltgeXGg2Nene7qsxJdU22NLiXmsb94l4pRYdd33IYDvFJq7mx25WOXanI9xcKyjphD8aREVmnGg1ZD2Zmtrf6iEbl937nfbfnGtjb83uvBv2gAjzM/M/MaH1etyvryssvy7+Tk9trlttt+d7dnqfDDsCcFPrmIGEco0NG3+iUpftnCQGU4MdiMwBs+NC+vfeJxQmez4sBXC7LYdfXNWKyH8oA62O8XnFQlpd1ozt7Vgxrj0eOTSEBl0vO0+OR3z0eOcbEhKq+zc/rudBZaDR0bNjQkqINVFpzOuVf1irtpfFo7wbR+8AHAvKeQkGilyubohLBoDaZXVmRc+dik0zK79Z70Wvg8rspox4K6XubTaURjI2Jc5TNyrmFw3KcSkUizA8/rPLbdrtQ6dbWJPLl92t0x++Xe76TYTk0tP26qZDXb+O0Osf90u/cVFkTdtDN9yDS0oXC/hrY7YT9GrkUsthtfKkI2WzqvEulNAMWjd75HDOgsboK3Lypx5+e1j5TKyt7cwzuZhjcradFPxxV1O8oo9t3i5ICdwYY3G5Vc+yHnea6tYYyGlUlTKvE/v1eGN4PHo/WtVlrMjsdufZKRdf1blczArmc3JejVsK6F0qRNdjZ73k5qLrXSalfPAzQ+SyX5f8rK3KvSbVcWVF6PXv1sDUFW0ZEIhqAolCRFbtl+H0+2bet+7AVLClgy4qDGvSDDPD0WyN57oWCjOPyslwrAwysTdoLJe4w1p6TRN8cJIxjdMi4Izr10z8NfPhDqMGDHEYxjzOowo/IRh4j/+RfYviXu3B881/f88Sy9kXp7QGQy6l8dz/qDov4+snATk+r8lw8rkZKOi0LCbNEdHLYhJTGBqlx9br2T2Jjt2pVlIoo5MBO2IWCRkWYVWm1NFvVbN698eheNohsVh7malWzIKGQLK75vHw/I+0TE3IOvcZq76JcKMjPY4/JQsXF3e0WQ4kqgtWqbBbhsFLHuBkzmxQKqcKYleLFPkYejxheOxmW6+syvpGIzolSSf62vCwRKKs6FO9TP4lyjlmlovfkIJvvfqWl221xCEnpvJco1EGiqXcz3Ofm9LrqdTm/VksN6rU1Gf9+zzHvKamQvU7IXh0D1qyl09q36qC0iKOM+h1HdHunKOlOG3s6LesqAyl7NX4zGaXP+Xx39nPL5WTdfBBlcYeH5ZrTaW06TucjHJbXgO1rjNstaxPpVUeFe6EUUc1zeXn73GCvOGtrjKPCSVQcY61vMinzntTSblf67Tz2mDZfB2SOUDCAtLtEQuwLPm+992anDH82K2vw+Ljc09772W7LHjoyIvbEQQ36QQV4dlsjvV5hw7D1CB3OiQkJpJ47d3TOyEmibw4SxjEaALaiU//tfyLw4V9DGx4sYxo5RNCBHUNII4YcKvAj8a8/jPG/9nbEYo5dJ9ZeO923WmJ8ut1a90Pll1JJa4OA7UYCjaJmU87hK19RWe5AQDYANi212TRDxEg7DSwW2UYisnDdvKkOWaslx2D7JmZVMhk5ViYjn5+Y2J6K382g2MsGkU6rbLnXK/fmlVc0Q8Ro0oUL6iD2uxdclAsFMXrCYaUWWgtIw2E1pq9dU9qJ06nNcNfWlHJCJ4GOCjnaNBzuZljynk1M6BiEQnKuc3OqHMUNncb81FR/Q5SbKpXjDrL57lVamuqBy8uywU1MyBy5lyjUQRSMdhtfp1Pmq9+vDu/GhpxjPC5jnU7LNZ05c+fc4fGZUeXfeD/24hj0OjKAvHd4eH9CJTzWUUb9drsfDKRUq4NxHHrHc6eNPR6XmryrV+X53Yvxy/tK+txWE+1NMKPCwMBJk8XlHCQTYL9Zw0gEeOghGTc+xxTpCQTkvrKfGkG69k7P5iBxUEoRxXWSSe1XZ80Kss7vKLOBJ1VxjJR0ChrR+WQtJQOs3P+pbMveRxQ0qlRUTbXfetQvw5/Nyjpcr98ZeEul5J6R9sw54PfLd+2VEj6oAM9ua2Stpt/76KM6/1jXdVQ4afTNQcI4RgOA1wtMjbeR+ekfQREerGEcJQQwhgSKCCGMIlxowYcqckk37J98Dme+7XV9J9Z+6Uh0XNbX1YiihDbTzMyGZDJi5NNZ6Hblp1aTPj8+H3Dpkny2UNAFh9LPPl9/A2t1VQwMnhP7WxSLsniFQnI8ZlImJ+Wa2ICUFLW9NB692waRzerC0myKEXP5MvDVr8qGzuzE+LgY5ZTJ3O0hd7nkOENDsjlae0qRDpBMCnWvUJBr4yLfasnxV1flvfG4ZiH42sWL2+uc7mZY9tLiuOhTpefmTaHssZ4lkdCFtR+4qYbD2pF7P5vvXqSlmYlsNMTJSCTEyGJvqXuJQu03mno3R4qZLt7fRkPmCZ8/UkA5X3rnTqWiTQ3rdbmmblfGg+IXzOT1g9WRIUWy3dbs8U6FuTvhqKN+/e4H6xorFa1FiUQORgfcK3bb2LtdGf+FBelaEArd3fi19pcrly1NtDfBDEqpJNd1UowF7implM4F0smGh/eXNWSgjfsIIOO2vi7/9/mUEWDN0hynk7jf+5DJaMa3UlElNb9f+9cdh7rXSVMcW12VddznU2fb5xPGAunsIyPyjKytKZVubk72SwYhYjEVYwL6i3X0W8NiMXkG6/XtPd3qdTn+yIjMxV6ZcI9HnuO71b0Nkr64256Vy2nNIh1O4iizNCeNvjlIGMdoQPB+6RlMZl9GAUHU4MEE1uBEGzX40IYdWQyjAj8acCP1chV4Sh5cq4b/XuhIVoqU260p1tu3NZrZ6chDxd5B2ay8vrysDUIBea/TKcdkZocPqpUaEo+r4cfFif9n/QVpYpTvbDa3izJ4vbpRdruqvkLlokRCG7NyIdiL7LK1P06los5kMqmOQb0uY+33y++A1lRVq3envzSbalz39pSiCl6rJYtvtyuve726AJPWZ7fLdzBTxCiZwyFGSzCom91Oi6aVFtdsqqPGhnrdrlIkKaE6NqZqUnfbVHfafOks9TMy7yYtnc3KPWEUsVTSGqn19e3RvoNEofYbTd1tUyJlg3OYhcGdjtaaMVNA45pzm0qBa2tyjZRF39iQzwQCkmEqFOR7z5/vTy/KZOS+AnJPrdmMXpWvu0XDjyPqZ70fnY482/PzMjZ+vzz74+MyZnuttzoIdtvYWVvJ+80s8G7Gr3XeWJsx03CmUzQ6enJkcbmnUBqZQjKkIzGLvtd7QIqaz6eBuEBA5mM4LGPD3nV0GoeHT46TeDfweeE+1ttcfXxcKZRHjZMk+Z7PSwAOkPkfi8kzQ3XU0VEVnGm3RfSn2RQ7YXVV1v9ew590/d71aKc1jM8gg3nM9GYyWgfcKy1Phk02Kw7cbvPyXuiLd1uXd1MwLZXk/8Fg/xrqo8rSnET65qBgHKNBYW0NAOBCCy60EEQZDbjRhBNpxNCFE15UJWu0sY5cTia3NZq2Gx2JNTp+//YHzueTyRkISOaBtS/Wh8bpFNW3tTVZQHn8bFaMltFRjUxbHQNrsW21qpFGRmBqNfl/NivO2a1bYsg1m/L5QEANBKdT+yIBsrF4vZpZarclg8CMyt1kl639cXguVMNjwSJrmBi9bzY1G5bPy4/PtzP9xXoelBydnNSia4JZsWhUu8B7veqcMHvicMjfSyUZ64kJuY5iUe4Pa1msTgujYAQbylJVi4s+jUAa8KSAFArquFnPiw5l76bau/myRwSgG025vP0zd5OW5nnSgQ0GVZqdzjdpa3a7Ohz7wX6iqf02JSsNNZuVc0ml5H10ZFstjZZTrMNu375B0DkdGgI+9zmVJbfb5biNhjxvk5PaJNmKel2+l0Zsb98PFuEGAvL5u9UMHVfULx6X8bx2Ta4bEAOZTny7Lc9QtTq4COhO85LGB5/JUEipYbsZv9Z5E4ttb8ZMp2hysr/8vhVHKXvLPQXQgBkg84rON9e5vd4DK8W41ZL7yhYFx93IeS/YbfytzwsdeOv73W4Zt+OKkp8UyfdUSub89LQGDj0e2TtSKZkbFAsYGtIa4nxeHJJ+zjIDl700253WMO4vDLzlcmpzuFzqQFjXWJdL3kN6dz/FVOIg9MX91HL227MYvGST+l4cZZbmpNI3BwHjGA0KExMAADs6cKCNJlzwoIE27CggIg1eATThgOd//DaiTw0j8ejXbWn470ZHSiZl0y2VZNMl7YORTdb6RCL9I1mlkvaTYZ0MIA8eFzGX607KA6Og7MfD6Ax7HFUq8v96XWl6Q0PyHYmEPFBnzsj5OhzyfX6/vLaxId/NmqahIXUC7lYPAej1TE7K+FDxrtmU66DzQ/EDZt3Y9HZkRKXE6RxZ6S+92buZGXG4lpbkPk1PazaPPZTGx7XvE2W0uRAz1f+a16hBxuhPIqG0v1BIxoSLX6Ohx2VT2Hhczp2KfjxfbpI2m5wXs1d+v9a7uFyaZWQj3F5Y1RDZZyIW27k2pd8Caq1nAIQrPTmpGygd5FYL+PKX1RBhX6yhIZWD3YsBsN9oam/WMZWSMQNkUwoGhX559ao0y3U4JBLKLFK1qjV3lYpusHyGb9+WQAEdQa9X3ptMyr8zM/0jf52OqnhZN0arytf6utam3a1m6LiiflyHSOHkOcTjqlbVm40+7A12p42dzRFbLV139mr89hozY2PyLzNFuzlFhy2AsduzQUcvnZbrSae317xRNZSNovdzD/pdB2lUzaYc+6Q0r7WOUW99bL/x7/e8WMeE13bcUfLjNEatWda1NaXEFwoyxqQgxuO6/7ONBoN3/cbP6dRePtbXd1vDGCR1u2Ue+3xyXrdvS8PhkZE7v6dSkb/TdtltLBngWVuTdZz1sP0Cbvut5ey3Z7Xb8twMDfV/bo46S3PS6JuDgnGMBoWnnwaCQXhKJYRQRBYxdFGBAx2EUEQBQfhQRQU++FFB9Rc/jOh/eyucTsfW4r0THWlpSSkbjFzz4fZ65cHdKTJKeWAaVtbGrux/w4nOgv1SSaPUdrt8JhqVc6ATtbGhBtrGhjgNVtEFFifz3AIBWVQodNBui7HMxZIPHzNTdG7KZZXozGTUCGBT1mRSewkxM8KFlRkuKveRykPhA79fFXV6JTB3apwbCgkVYGlJnAsWHrMhKx3MdFqj49Wq9vLgJtxoiDF++7YUog4NqTFPel+tps5nKKSUheFh6X/ESJ3TqQ5gICAG2uqqjFM8vr2/CAtdq9Xdo2WAHM9m0x5WwM61KVxA19eVXkmeea0m4wtsrz2y2cR5SKUkWxiJqKP+3HNCv6CQBSWW6Vzv5tDtxZmybko3b8p4k9rJZq+PPy7N965dk8+wuR6li8tluXczM0q9IaXz1i2ZCyMj2gyYm1ooJNc/PHyn8c15au0VY4XbrfVqMzN3vy+HFfXbq4NKozmdFsOEdGBmYXgO7C0WjW6nEx82+m3spL0yywvs3fjdyQGfmNjdCdir0bSXcd7NwQLEgScjoVhUyhGDNlSJ47rr82nW+W7Y6Tq4VnAMaKAeF3rHiPecxtx+gjxWPEhR8oOCQQXSpEdGlKmysiI/DocECTweeQ8VNlstdax6s+V8rbeuZi/3hNQ8IhqVe8w90do7iSI2fNZ2AucQ1eGSyd1r8w5Sy9lvz0qn5f391oKjnn8nib45SBjHaFD4+Me3yKEBlJFBDOsYBQBMYBVZxJFGHC604UUWkeR1RNa/hPr4G7cmfz/nhs4Lswj01CMR5dSy5oTZC2uhc7stlDOXSx5AFkBSKYjUOK9XPv+FL8j3MhrOup94XAxIRh6dTqVlzc/LojE2plFxqsKVy/LesTG5PmvfmkBAjUQuDqmUXNtXv6rpejo4w8PyXa2WOkUbG2rIUiEpkVDJ0FxOxzYalfGxKtw0GvJ3azTHmr2zLk5M3QcC8tmJCe2DEg5rndbyshrFgNah+P1yPqGQUiPn5+WcPB4xwksluX5KpdOhcbvluykJPjIixy2XlQI0NqbjsLystEQeh32qbLa7R4j3W5vi9cr1Ly5q/QZr1ah6yJo3HpM0q7Ex3TyoYjQ3J2PxutcprS2ZlHGdmNi9aHyvmwajjem0Bhm63e3KjuPjco+CQaGqUjq/2ZT312riwNGodThkDPJ5dQYockLnlRkJ9r+ygs9ko7E9wk/wvPbTf+deon77yXJYjWaXS/tycT1gthfYno0eZAR0p42dBkq/+bOb8UH6GMVYqlX5+90cgbsZTaurci67jTMNyrU1mU+9DtbiogRsGEBifRyDNKyFY1Q6EFDDtVzeuebtbtfBusfVVVmPJyaOtwFkP+dteVkL8qkUercgz4MeJT8o7HbtR8Q9hvvb1JQEhazzz2pEk73h8Wyvz7MyYDbJN9uw33vi98txuMZYxZL2IrlunUNkMJC1w+u2zu17reW0/s3vlz3n9m39O22E/Qh/cK0ipfGgOCn0zUHCOEaDQLsN/MAPoAYPMoihiBCacKEMPxIYRQw5hFHEMFIIowgfavCggUYqsfVw7kb7YLZnYkIeDOvEJJUnGpV/X3xRHAOq0zUaSltptbTOhw8Moz+A1lLUahodmZxUY7vb1YXEbpef1dXtnahjMVkAVldVGpsLZq2mjkCrpf2RPB45/0ZDlN0WF2XR8/v1YcxmVdGK1JyhIaX01Wqa4aKYBKPVgYD8rdHQyBIVw6amVKzAqvbGzt1Uy7NK+VLG3Jrdm5gQg2VtTRvQcWxf+1o9f0CM63xeVevCYb0XNKLrdfnb2ppkLgCtSbHbNWvCTAWpIgsL4nAUCuIIsY8IhQFqNVVO2y1atpfaFKrn1Gry79Wrcp3BoIx5ICAGR6OhzoWVRkintdEQ463VknFjTRL7R5VKKqBBR/CwpKY5l8Jh+Y7eYl2OK+cxI43NpsyhalWyW/G4OngMCnQ6ulnyPlDWnj2RejcYu137g9BwIKWSTm5vRLX3vvTe24NG/fZLDbEazXR46OiuralKFbA9G01RjkGh38be7cq17dXQYp+WjQ25F4Dcv1BI5iwpuv3Gcy/y8Ddvytj0o6wODcn/CwXt+zI5qXVQbre87zOfkX8ff1zp2devy5rANXB4WM6Z1OMzZ/S8emveeg2hftfBOtNiUZvdAtpnbzfK7m64FyOs13lj9pqCH1YFM6B/kOcoo+T3q8HJ+c8Gv1yfpqZkHl26dGfAgA4OIGNKVgHX90cf7T+++70nzApls8Kg6B1f1gnuNN79AgChkNpovdmfw6rlrNW0LjUcVuEU1qbu1KrBOoeq1e1rldutNN9+dUt7xW5B1Ptx/lphHKNB4JlnUEsVsYIp1OBBAGUEUUIMObThQA0+jGIDYZS2fawcmkAs1D+yyyJWFvWGQjK5excAK+eUzVSbTeXxs9CflLJuV3632eQ9xaJsXpGIPNiktnDTnZqSzyQSMvknJ5UqR0MyEFBjqNuVjZBUIMpxcvMul+UzHo8sALOzYhjxutbW5HoYnW+31Zi6ckUpTs2mXhuzZFxUmD4vFMRBo9hAICDnl0rJ9fl8WleyuCi/sx4qmZS/M7PWbquUbzzeP9rE70wmNUs0MiJjMTEhY53JaFFvJqPOAulwNMhIkWPB6uzs9s3bWgRuhderin/ka3PjqFZlsRwfv3uUnlkmyvL2Fpgmk5ruTybl3FjQTgWsRkPnCecfnd0bN+T9r3/95rOwmVksleT+sFkw6764ITCLNzq6934Uu8GaqSX9iBLdNKiCQZ1LdOiZbaIU7fPPA1/zNdr8l5s35xszZXa7GKoTE3Kc1dXtGzs3dNJKlpd1jnKe8Dj9sBMH/SBRv/1QQ3qNZitlkvLW6+ta75bPy3MVDh9dBL73evdqaOVykvEsFuWekwK6uCj346GH5FpTKVnLeuuMeo2m3ntA8RhrDyCO88KCCLM4HPK9XDOSSfkMFR1v3FB6Ne8/s+TLy6oGSlovFUhLJc2+cn3ZqRaHgjZW4y+RkDnM9YLH5/q+3wzSvdZh7eS8VauaxcxktP2Fx7NzMGHQUfLDrjk7LNztmjsd3Se5PnDNZKCDznDv562qhhSq8flkDt5Nun+/94T2VKWiwQ/uSb3BD+sxAc2IMdPE6ybTpTf704/xYz0mexXeLTPONdfnk+xvuSxjGYnIWC0uyvEZlOqdQ+WyZJooIsP3LC3JOvba196bc7Tfmr37BcYxGgTW1pBBDDV4EENu689uNHERc7iGi1jDOLxYQAc2NOBGNTKJ8Nc+te3h7FVbo7dPxbjdaB80QMfG1PBNp7WAnSnsZFINglu3dCGjkhnrmCgHTcU2RoNsNu1NAEikMxSSc2U2gPzhZlMiHsPDmiFhx/gzZ7T+xXotbPjWaKiKGqBF/GxE2mhoM9iVFTlONiv/L5Wk/oKOIHnFr3qVXFelonz7VEocLWaBGKknzc7a/yAQUIP58mU5n2pV64Xo0DJTx3FnFuXCBRkrOm6tlkYxSTOkQ8oGdqGQ3Ctyprl5c9FPJHSDZ3Nb67lR+Yt9hJitunhxuxyqdaPhYsuor7X2BhADl13Fq1U5Zqm0PTtSrUoGidS3WEw+Y5UITqdlEefxGZWmgmCxKE7Ho4/qHOFmRdGOey3cp5OZSKjEdjKpmcJcTu5PoSDXGQiIActMmccj43bjhjqhvL+1mhq01aqcK6Osr3+9jB+zAsPD+iywMXEiIccfGtLxsCoS9ioWWteDncZjr+O0X2pIv4gpa1tqNa2nYnDA5xNnn+qEx4G9Glpzc3LerOlaXpa54HLJs9Bqify/16uBhPPn9fM0mpiBpiNks8n3sbO9tZcZoBm7lRV5Bqi0xTo0XoPfL+cTDqtITqGgQRrOV7dbziOf13o9GojWyH9vI01mr8g6oPGXz4vj1u3K56098fjcU4RjLxne/WYo+8E6D8mUyGRU8IdMAQb/mN3eyWg9DGeo3/zaqVfZoJou7wV7ddTIWPD5lFnB+UyqWq+Awk5wu7Vp+l6xW+bCSm3dS5ap3zW32/KMW7OkZKFYA1xWR9oarLTKvHNcOp3te27veVOoiA7ZK6/IeQ0N6XfxXJNJub54/M7nZW5O5vqZMzqnGYxaWpLXX/vavY81cdCavfsFxjEaAOpDkygihADKd7zmRR3nMY9FTOEWzqEGmS2hf/ZjiDgd297LjIfHA5w7pw9puaxqVJyE5Lv6fPJQUAihWtUNkgsBJb3jcaE0zc3Jg+Z2y4Y+MaEOBQ3bRkObSjLaSNnuZFKdJj60uZxKtjLCwaxCKqXOFGtPZmeVZ0xqQ6Eg3zE0pDLTXq98Fw0Ot1uOUavJAsBzJd2OUUHylVmfA8iDHYupEXD9uixCdFZooC8uak2Iw6HZL1K8wmE5Hy4SrIVaW5P7FwyqMtzNm/J33ruJCXFEo1FdJD/9aXUWnE7tDp7JyPuvXJGxHBpStTZAa4VWV+V3Rpmnp+W1hQW51zabijdQTpwCD5XKnepS3FxYF0YngNG35WWth7h2TfuWLC2J8cFFkZKtpFGylw955M89J5+/dEnGjM6V1cliHx+CFCy7/WDSpf2MFFLXNjbkdz4bpJ6m0zJX/H5VIePGMD8vxvXZs/JZ1nAMDak8NaBOeCAAPPGEZBkoj3/jhmScuJFQmZA8/dVVHQdSEAsFPfdB1EBYDcx+Y9Y79v0ipsxcUkSF4xeNytjsRAvZCw4zkr/b5wsFmRfsu9VoyFqZTsvvdrs8U6SO2mzyzE1N6XGZlbh2Td5PcRJm0RIJDc5wHfJ65XlaXpb7kEyqc8Xm2PzdZtN7xf5EgNarBYNqcEWj6oCRvkujzOFQ0ZedsoRkC/D3alUdoEJBro9OEo/JNfZuzSkPoxGx1QlNp2WcQyGZa9eva/b6oYd0/1lelt8PG7s5GvvpVXYU2I9TWq/r+kd1t1pN7nmjIfsd9/fdvicUOhyDulaTNXJ5eXtrielpGcOdgh/9rrlUkj07kZDPsyk5oHXGfPZ7a/KsLQrabQ3Kcq12u+U9DDD2zg+OA6D1tNa5wRpBtjjhXhmPK2uGQlKNxnbqMiBr2MaGClftZ3zvpWbvfoBxjAaATjKFNhxwodn3dSeaaMOFIHKYxBo83/R22P/u16Nc3t7gsN/GAMhDTlBYgQWPLpccY3lZJmcioY5LOq0p705Hm5qSD08qms+nRf2MhFLogQXio6PyELBfQC6nhg+FGgoFjY4AKj9N6t7wsEQyGEW22+W7s1mVHh4d1cwTJcDdbm0eyM/4fHKtXGBJ64rH5RhU4ut05HsLBVXHKZeVTseNvNPRiOn6uhbb0xnodGRBpSPEaA4dt8VFWVDZwBKQe8JIKz9Lg5vS2+m0OiQ0TKpVWehHR+XcqapTKAAvvyxjTWflzBmtQWFvJhqnxaKqv1G2NxoFHn5YvvvKFbnv1o3w9m0Zx0uXdH4x6nr9uoz57KzMWWas6KAPD6viHTe6dlspNYBm3dxu7eHE+iLKzbOL+vCw3Me1NVlkme2LRGQ89yOdu5uRYrPJubDvVCQiYxqJyBgsL+smZ82IsGYM0CwmIEbW4qKc18iIXDszbyMjOra1mjivq6saUXS7ZX6trWkRsjXYYLdr5pe1aTv1pNoJe3EqqH65vLz9/cwcWh0hvr9fxJSfa7Uk2HPhwr05MkdNP7JSJ/n9rJ8kZZjS+Xwu5+dFNKT3OhngoRPDa2DwC9BsdSAgc4MUO4qmkH45NSX3ha8zM1woyDwJhTRqT6GQVkvWqPFxnUfptHx+eFgdrt2yhO227jOsgWOtJOlCHCvSJfl87pbhvdfidYKReypJRiLaToK1GqSojo7Ks8k18jDn0m6OBmszua/s1KvM2ux80NiLU+r3a+0KHc9mU9YpCqsUCqrEShtlv9+zzaBut4FnntEF8emntdcD5Fhzc/Ks8P51uzJXrl+X87hw4U6hhE5H9vnecymXta/Z4qLWDdLRsAZKe2vyvF75sds1wOD3S6bZ75fru3JFMzb9nDL2ZCqV5Ln0enVusEyCdlG7reqoPCf2DuOaEolooIo2Zm9m+m7YS81eLLY71fCkwzhGh412G/Z//mNwwIEmXHD3OEd1uLGMSVThwWVswBMNAP/xg4Bj+2JAI3GnjYG9a8jvnZjQKPu1a7JRnT8vD8Lt2xrFoTHF6HY4rNLJpMyRf00DlgZqJiMT+/p1ecje8Aal+zCj5XKpNDEgDzUg5xmNAk8+qVHL6Wk5d1IcSiXNSkUisiB2OhIpJW2FNQrWXhzBoCwqTG8za8UO7C6XRKYZHaHDFIlo3yfSUUIhTZFTxYVULV4DJcVbLRmTtTXZCChgQeUbCik0GlIXUC7L+eRyuuFRtS6R0IzNpUtybfm8fL5UUkVAihPE4/KdGxvAl74kxyUVkY2AZ2bkeAsLgMfZRvZzVzFRyqLii6E4+QjSaQccDm00yvoyLpzdrjoazOJxHtFRzuWU1rOxIX9nXQ0NbWtBOA0vqvSxjoi0ytlZHVcqHZ49q0ZmPi+bCZ1ia+O7u9HGuAGSQthrpKyvqygEo+Z0yJidZLRvelreT2OGog0zM+qMAirwceaMHDuT0ftpLa4HZCxTKc0wklITj4vjQwl8PqsbGxrIcG6u5KGQGrp324T241R0u3LeyaQ2C6bhZqWBra1tzzbSoKCgBaD9TfizE+7msO1kbLJn2vT0vWWh+oH3hEYOa9F4HyoVGQtmZZn1r9e3X1ezKe9fX5c5kkzKeLJhNA33qSn5lzVEDodmgRiZZaaB2W+KHrAfGrNRVpVMrnOMODNz5HIp9e3cObmfuxWQswdaJqO1RYWCzBGPR+Yz52alsl14YbcM72EVrwMyN/g8lkry3JCOzHt19ar8RCIy//N5eR/FXe6VCtTPAeh25ZgbGzKPrdkDvm6zaa3jxYsH//79YC9OKbOk9bpmw9ttsQ24Nrvd2tur07nTydm38/vxjwP/9J/KBCamp4EPfhB417sAKE2Seyt7I7LmbXlZ7sHk5Pb1j60lKEbF9T+T0b59XMdI8WetzkMPyb3pNf75nPOehkI6LoC8L5mUZ4yU9V5xh7ExacXBNhkMuHHtdDjkeR0bk7lL4SjuQaTcsf6LisWA0m+5RuzFael3z7j/MSB3+7bu33SMeqmGJx3GMTpsPPMMPCtzCGEcWcTg3qwxqsGDHCLIIIbruIghpJFFFL5v+9twNxxbmz8XAxrfu20MfGitcpZUsQsE9P+dznY6FmlUTifQabXhfP4rKCzlETkTge/Nr0Ui4dharFmc7/GIYRMOtuGZu4LmKxm8MhdE4M2vwfi4Y2sRGB6WBZPy4DQsmQFJpZQawgeFsteMPDSbSj05f142hqUlrfth9GVkRI5165bWgLAWh4saGy2OjWk2gEY9o6ikUDDzxIgmFdFIFwyHdbNyOuUzq6tKB+p05PqoHEMBCvYXIi0CkN+7XVmMGS2mI8biaKdTPsNmeEtLcj/PnJH3pVLyudu35Rxv3lTpZho+8Tjw8m9+Dt3//Fuw5fIow4UaPHCG4zjzd74djnOvx+3bKr5hXby44IXDck+LRTHumdGhwAXHn4sxnaNmU7MszIrRgWBtGSPOjYY6wywaj8dV4Sudlp/RUXXUWC9Hx2on2livA0ARj9lZ3SS4gZCiNDQk9y+TkftBqW3OHUqd2+1y76mOSIoh68vabaWhJhIq6OF0at0dax0yGTmOy3Wn4qPbrTL4lFYmVYoUVoqr7NUp2i2C3aselsmoeAgNXKdT/iXVlHQkK5WPdCpmxKzOLOmmvY7cXh22XmPTGmDJZmW+PPTQ4WaPwmGZg0tLmhlnLU0qJT+sK6MT3gtm0FIpNZb4Q0Pd7Zb5Eo3K9VN9jmIIdEqYwcrl1AijiifrLKmwSFUqNhFnfRwDck6n1n6xB91OjTQB7X/kcMjzQNpoLqdGG+vpmC2wGn67NafsR8W0wvrZuznQbrdSfObntX0DqcjMrjebcm9HR+V39szjPeQzv1/0GpPWedrpyDNy+7a+TgGbREIdV0CeE2aXd/uue6WU0illpqf3WC6X1pJduKBrEAA89pg6mWNjaqeEwzLHKACyUx2iFduc349/HPiO77gzkrKyIn///d9H/ZvfhXRaqbqAZtHZe4h2TSCwPTjGMoUbN+7M+J49q1lYrmukpbKfHu9l7/7JIClrgq2gKAnFeKxMIILqp7mc1g/TWWfQsVjUemmOZySimc/5efkcGRWshZ2bk/NKp7VtyN3Wyn73jGsX66cLBW2K3mrtTDU8yTCO0WFjbQ0AEEcWVfiRRRROtJDCEMrwow43wigghixu4Tza//UlxL+9AW/IjWBQ1eCAu29KtZqqm5XLsgCtr+tDvrAgn6ccM5u7Tk9LlD/81b/E8gf/B9bz1xFDHj5kkB15GN5/+H9j+LVv3arRobpS8OoXEP6vv4xQdgFt2LCKUYRjbjz57/4OGt/wTVsL8sqKqrCRRmatsWCEsxc8TytlIBqVVDNT9qRoDA2pmg2pR+x94PPJYlYqaRqa4wVoMTKNdi7SxaIsDsWipqLJ6aXzRCoIxxPQ7yVtMJeTczpzZjvH2efT6DKph6QNuN0yPh6PUmYYRbJG1mdnZYGpVGTBo7zp2pqcB6kY7Nng/vxfwvHBX8IQUriCR1CDB0GU4SusIvzhn4En+n+j+Kq3bJ2X1UjhgkejioXYLLRlzVClor16OJak7NhsauQPDclGyl5GgDrupH3F48Czz6rD2mhoLRc7p7MZZbMpzmAqJfO5X1S31wFgJLDd3l6jl0wqHYDZPtI+5+Zkoyctg07++fPqCPG7rA7E7Kx8B2sZPB45fz4jS0ty3jRg6STSobQqkrlcMsakwPr9qlTHTCeprnuJzO2n/wyDNZSCp1FHo8nnk/tEtUmeM7NMIyN3SuTSiWOzajqMfr88c3dz2IA7jU2rtPrYmIwHa+j2E/G/m3FpDdZw3JaX1bln0IRO9pkz8j6OF7MqFIVpNFRdkBkCGkTMVpMmwz52FCVhnVAiIceamJDnYWJCxi6RkAwrAxyjo5pJZhSdrR9CIR0jrnvWlhHWovBKReYJs+ucJ9Wq9otjZpS96iYnt4/nbhlea/G69bt5T9iAnAGb3RxoZjCY5ff5tCaDgbJWS9eWalUzgBTySad1b9rNeOw3d3oFIHpbAABKifT51CkinZwsirk5ucZeKhiw92DCXhwnZtS5TjL7SRVcCvFMT6swDYMcdEDYN9Bul/PO5eTYy8syD6anZSz35Px225Ip6pdeZqTyve9F5a3vxOqqY6tmmtliCvlYBX+4xnD9I5uBQT9rT8W5OTlXisZMT+s9BWRcSGXr3T/puLAu23qdbNHAvayfgxgMKk2WdamhkIrzUOxqaEh+J6MG0DYstBFoLy0vy70aHtb9eK91Xf0CFlQcvXVLKfAeVxu2Z78CVyoNl3cMePWrUS47Dj2DPygYx+iwsZm+8aKOKawggxhu4jxyiCKKPMIowI7OZm8jJ5rNDmrv+tuI/OsfRP4NX49iUR5WGgo7dXdmtO72bZnkiYRG+VjITYdpZkY2TwozTE0B4Rc+Dee/eR86mEUbDsSRRgV+1JN5RH76R+H+yX8PT/Sv4NKlzVqRT38R7Q/9EsqoYRUPoQ4PyvDBm60j8v0/jalfscP3rX8dyaQY7Exls29BtSoPbSAg/zJSxowAKTCskbCCzhEjQTTG+Dku8K+8IsedndWGmF6vjA+zEGNjsjAwunn7tjZKZQF/NqsqdJWKXH8mo+liNv0cGtI6l3Ra3sfmtQsLYjhRoY9RQl6b3S732emU7yNFr1bTrvGjo/J5Rs24WDEKS0cykZCF6ezZHqPM1kbpgx9FHW5MYRVrGEcKwwCAKryowgvfL/5XOP5JBK3JR1GtOtBobC8SDwalF1YqpYs/HW9SF30+MaR7m7MCalQ7HPJoPP64bNYUkGDT15ERrW0D1KniPSBtiPVgjOCNj2vNGvs97JZVqFZVgGRlRevH2BiYjp3Lpc5IOKwNcRkhnJsTA/nhh5UaubEhn33sMbkXHo9Sr2gQ8NqsAiAUUGAWLhK5sxiWqotsEMvjMLLNzFQ0KpvdbpG53frPMLrJTT+bVaolKX50Hmkk85i9DhkDCgxI8Jz4XaR4UHY8m9XoplVhz+qwLS9r4+haTZ4RYLu0OqAZC7YpuFvxb72u/Hhm+HYyLrkeXb0qjae5Jg0NyT28dUvex8xgLCZzg/WDVPhkrRVrf9hGAFDqzNSUSgpzvaPhyT2AvY1Ih7Pb5T3ZrIwHs0vMQK+uquQ9s+nWPcaa5bIWkDP4xL5409Oyt5COyyBYtaq0MK9X6iCpgrq4qLWKpK3tBIqg8LtJx7Hb9T6zN16/on1A+2UtLcncqlblsw6H3BM2BedaTup0OKzPJB1QztF+xuNujonVmOQ8Zbac83RiQn5noT4g70+l5P+kPVqpYNbvXllRQSLWtfSOxW41lRxX0s8qFW2wTactkZCMFenEVkqo0yljvLqqVLSlJZmjzCAy2FOrSbBoZkZbZPSzcbYc5y8+s50+BylJ6MAOOzrwdBuoLW1g7Y++jLz/DVv1OFblTqq5UcGTjgFBASJAngk6KuPjct0MfAI6Vo3Gdkn9XlAOf2lJs1DM0nLvpkIc73fvsbiuMFDBgBigQgsjI9qyolbTWj8KsTz0kN4zMnn8fuCRR1SMYbe6Luta73LJ+3rvmdOpdXJnlp6B6z/9WzSTYlN60EB8zIXiT/wE6t//1+6LOiPjGB02nn5adozlZXhRxxAySGMII0jBizo8aGADI1jELEIoogEXio0wbD/+cxj+tzZsPPZ1W1SHft2dmf2gghGgdB6bTVLBtZpKrjIKy1oaAHA72+j+yC+jBRsiyAPo4ioeFkcHVbQxjPwH/hDVH3sLvD4H7LY2mr/9MRQwDD/KcKADD+powY4WHFjAGbT/v7+O0be+HYuLji26HiOFfr+q09DgO3dOH+j1dVnYKSedTN7ZgKxWbqP0p59HcSGD9tAYHF/zFEJRx9YGQ5la1l5ZnSfS9+x2jU5fvizjStrN2JgswozSplJyHhRqSCa1Lw/7NFgpMPm81hjZ7bLRUbqXGQFGzx0O+TyVrdbWtLHiCy+o8RQOy7EWFrTeiEIXzNYkk3r/GXEKBDaNvM+/gla2CQ86KCKIFlzowIYsomjDhg4cKNZCaP37P8FY4ONof8e3YHHstVtGFqkCrG1hXyVrhoNUBTpAtZo6w5zDgPw9GJQFd2ZGxnt+Xuk/LpfWLJHiZuVFs6nl3JxGvVstVdGzyorv1EuHzwoNDtKQmEmqVNS4tkb+SAmigWlVl2s2lQIxNSUO0eSkZtpIj7TZ5DuffVaOQzXG5WXdkDnmfP4JZlnpBDKjZXU4q1U1slIp+fxOUb9+dAirY8FiZaqHJRLYCthYo4QEsxeNxvZINP/f6zTxu9iDivO925VAhVU5iU4UZalppLC26dIlmUvF4nZn0qpWuFvxL+dMKqV9qUZG5B7T4O9nCEejWg9nt4szxJ5p7DvFOb22Jt89MaEiOO22jG0yqY5oIqGGUrMp/5KCNDEh50enitRb3oupKa3tyee1MJtZIBo1Xq9mz4NBCVT0GmOFgma42VyadQ28D3zue9WnKItMOeRcTiXYKY3N7GNvf6d+oDFKsBdbKiXjbHWgredx+7YaeR6PqoYmEjpONPhXVzW75fXKnKKKXiymjafJLug1Hvei4MbniHU5rBGjQ8wandu35TgMDJFKSWXZREIpgJzLq6ta/8LaVYqiULiHgYSdaipZH8I2HxQHqtdVwpzP4cWL8t5iUQMTDNxwbWX2hOskaWWss2UPvdlZGdddGytvsnAAKUnIIIYiQmjDAQfaCKGIGjzIz2dROiNjwTWWrQ4oYMEWDMxuMfPIABUpyaQSsl0GlVbpUNtsMjeiUQ34svm2dU6QCZLJyOfTabUjqMJHO6BfEJx0Ob9f5yzp+Ox9SDoog1YURyJNf3pa7hMpo2trWkbQuyZa10r2JaK4FOmwrNnjGl4qybzMZAD3y19G6Tf+A9JowQsPIsgjijw8iQby/+SfoTP8M8Df/tbdH/oTAOMYHTYcDikG/PZvBwB0YIcDbYRRhA1AHiFkEQPQQQMu+FBBFX6kEUf6Z/8AQx99Kzodx5aMKHX3eyfn+rr2w+EmzF4M8/OyODzxhEzcclmMBy5SlZevYi0zBTdGcAG3cB63sYJJvIDH4dvMdJ3JvYDw//pPmCuMYt7WgjNfRx1+ONDGGJIoIoAhZFFGABX48HLKhcXfvoql4ONbRielnikfzVqdh863Mbn2FUz92h8jV/Pg1vBfQ/fSEzh7Vmqt2KmZDci8//MPsPLen0UtkUUAZbjQRHP8DLL/4t8g9/a3bxm4pGuk0xKloWJeMKjRXI9HIupsPkj6CqMrrDPiIkojn59PJuV6eG9iMXWiuDiWy7KojI1pdI61M+22nI9VqY2GGPtpMCPT7aqzRaPk5k11Bmi0WAU1OH7JJOCZr8GDIQRRxMt4GKXN+1dGAHV40YQDKQzDgRbGy2uI/uefR33yHyH1trdsRaHX1mTxj0Yly1MqKX2HssCs72GH81xOF3Iahy6XOH80xsNhMUBIuaHEsc8nxhoNKyr90SFkxJeOCqlXNHbu1kuHGz43wvV17SUzPKwGIyCL/5kzcmxmZkiTowHK+RMMKlWJNDFuQn6/0k4YlWVPMW7Y4bDOMdarsLCe8u7hsNaLMIgQDiutc2ZGDI27ZUh66RCs02Lk0upUADLHmYEYG9t+LBqXVEuyGmU0JBmoALZ/l1VRENieYeI9tMr+U+p2ZETG8/ZtlZ+nA8x7bT02FQR7M1pWg5b0qVhM3ru0JPeS57lT4Th7d3EOUsiGrzMqvrAgx7bbxdhbW9M60C99ScaE/dVmZmR+8XWK1bCwnSqJHP9YTF5fW5M5RuEW0pdY60Rar92uNTcMGjESzTVqelrG7coVpcxRVfLsWc1ybmwoVZCO7tSUzOWVFfleisb0rm+Vyu7NJVlzd/myqq/SYJ2b074pXKM57q2WBJioANbpyHlyfrI1AQMSbLdw86asSaQKcm+lxDe/o9fR3klZjYalNVB265bWgAJyDTwOqVc06llnTPVQt1vuMQUFALnPN2/K/3vV7BggpdgGn12uH1zXWCNWKsm9JjX3wgVVZiU1jeuOlQ7NoCfXqlRKRQBol7AeMpWS4zKjUS7L/CmXd2msvMnCqcGDFUyhBo/aAXAhgVHM4wxylZmt/ZTrFRvELyzIGE5NyeHYsoTKrWRghEIaeLQ+j1ShY19HZk9TKXkeYrHtvZo4J9iKIJGQe8/7fOaMtixh8NAaBOczy+uh2Es4rM8PnyXudXTkWA9LuiOVf7l+5nJqXzBrRiedDBiueWzO3unInCSDg2qp8/PymtsNTIy2Ef23Pw8HsnChiVFsIAwxOhtwwYE27D/2I8B3fss2JcGTCOMYDQLvehfw3/878O53w97twIH2lkJdFtFNatMKKgigBi8q8MGGLuq5FlxfugK781WIxzXSRjoDhRaqVeAzn1F6E+lPLLgnNYgPJzc0LrDVjQJqm+fgQhs5xOFGA+PYgANt+FHFKFKI/Nl/QgqvwXN4AiFMowUXYsijDD/iyKILB5xowYYuwsghuVDGSlTrJFiEzFS6zwdU5hZh+8THgfbH0cUXsYLLaOIzmAo3kP8n/wqVJ5/eekjn5wHf5/8csz/xA6ghur1Z7voS3O/9XmQ/8FG0nn77VoSKdTaMwlarYuBQZnpiQhae27dlE4nHNaq0tqZGPBvVDQ0pzzsWk82FXF8KAAQCGtmhkXrxohZF06BiDwQWgW5syPvOnNEIJdUI2235l3KblAovFFQWlZuHNSLP6L7DAQSG/MjCj3WMoQYvqvCgBRfOYgERFJBCHCNIIY4sUhjDWSxh8j/9W5Te8UdIpRxbfZTOn1daGaPJpP0wmpXJyLw7f14jfowg+nyyIb3qVZqh4wbOhf2hh2Qc5+eV818qyXFXVuTvdLJYOzc0pNkk9q6i4QT050MXCjqOCwty/uwH8dJLSmmp1bTGghHdkRHNgrDWiHUTNCocDqWa1Wqa+Vpelp9IRO4PDVq/X+cBv7vTkXMjJTUclvFjvy7WdXU62qsrGhWjjiqIu8mj9tZvWFWFgDsdFpdLo5u92ev5+c25FpD3WI0yOsbxuKq1MQrNeW01jHszTHSiOI/osJGSc/asGIXsp0NxDho0PPZOhfpcH+lc0yCp1+U5SqXkeHSmGaWnyhspV5zHFy4oZcxaF1ipCJ2M2UBmC2/ckNcZ0eY8mpvT7BefcTbw5fNTKMj5Dg+r4iOzJ5RvZ10SswHMvsRius6srqqTRobB7Kx859ycvE4ats22vSYM0MJqjhPnZaMh8510z96mmL1j2gtrtpeOPh0UChJcuybHnpnRrHCzKd97/bpQWmngUkGS38U16MwZGeuVFc3WcTwCAfk/MwOEVRTAep69NVh0epJJ+Zy1hyCfAVKkOY7NpnyO58n54vHoOmal1bJnHnvV8fxYfJ/NqgNvFX2g4p7Xu/3aafDyHjHTQCozawtHRlTunWJI+fxm1sAtY8sMKPsH0llngJLZe9Kpd6x/2mThZJbbqMGz3Q5AE2GUcDv0GnRHHsbjm2UEV66oVDzXwsnJO8+HNHC2AXE4lHlC+h2zkwz8MaNdq+m8pn3A9YEZ9/V1WQde9SqlXBeLGjy0ZqKnpjT7Z61NHhlRhV7SF7kOjo/L+dNWoB1BZd9YbHvWnZlP1oo+/7zSbXnPWQtNCjTtKUDOOZnUuuZKRQPA3VeuYiNjxzhsaMCNCvxbjlEZAcSQhWd5XeTW3/a2Ox/6EwTjGA0KIyNAtwsPGgihiCxiqKKNJUyjhABacMKNFoqbUXw/KhjHOurPfgmOt7wK+bxMcmaMul0xnPJ54ItfFH470+tMy3u92rOCPF4aUuPjMoHDwTaSay34UEEUOYwghRVMYB2SE88hgjq8cKGBEEoIoAQP6khgBF6pikJx85UYsoghhw7scKKLkmsIzaZc+u3bUvPDnh82G9BYXoH7ylfgQxqrGMeLeBhpjCKIIjYKYTR/+gPw/rgNzre+RTJO9ja++u8+gS6mMYlEzwB3AdgQ+HfvQ/utXw+nx4FcTuVl2d2dUTdSPkhZsdmUFsYsAMeKanI0tJn6thpzjOasriq/3+eTz5D3u7KiPZhIU6AxRsOH1D/2QqFyFAslma622dqo3ljBtL2A11/qIj/xKNI5x5YByj4F3a4auPPOSyh4HsGF+ldRhh8ljKOEIOZxDtNYhAdNxJGDHV1U0EILTsQ2riK29kWMPvkmFItqBNBYI/XJZpPryGaFq8ys3MMP6+ZQrer7xsbkx+ORuXvrlvaBIC3J2qSYhdJzcyplTDpkuSyfTyaFksm+EtxMaDRYHQBuBOm0CjZw8wD0X/bjmJ3VnkvMgFhBY5vPHyOUpZL2vbh5U7n5lMBnBNZul9fYZ4vRwtu3ZWP0eDSSOzOjEdVgULNN0ahGAYeGtLjbaqASvUYHabqUtmWtCmv2rNdLWtf4uJ5HLqcZsKeeUmOdUc10Wpy7M2dULISyuKRgjoxsp1KRfskME1X+OOeyWW1eCGzPSjKLwBo/ZqyA/oX67bYcjxk+ihxQnYwKjaxry2Z1jaDk//q6iuU0GrI+03mj5DuDFDSeul0ZN9akkZoJqOHD2is63jS0zp0TR/T2bS3mZk0ii7RpIFENi2saI/08JzrbVL+j4fTEE5rdpoQ+nSIa+bwPIyNKb+S6RxU39myLRuWZ6G2KyTGdmenvGFmzvYmEZsbrda23YFYmnVZaeSwm50jWwfXr20VTqEZGujYDhiMjWtTO55C1KjSemeFiwIVzlE4Qe8ml0/Jdo6NyPuxFUyyKM8+ASTqtLQkCAfkOjmkwKP+3Uqu4hrDdAevi6FB7PNvfT4efNSmLi/LdDDAxu0hxHWvLCdInSU/kOsB6zkhE6zTZqJpGNRkX1gBTo6FOIZkQrOVklmUnB7nTcaD5/l9B8bt/FAFU5O9bNUZdlOFD7Vv+L/hdji3myNCQKjySzjo6qtfi84mTTwoi9wifb9NO2tyfGw1tC8K2ERTqabXkZ2VF9j3WcnHu8hm0ikCwDpCtFvq1RaAzROeRQUav904RG0Cbv9JJ5jUww5dIqJQ+n3/Wc29s6Fzjvsu6TJ9vO5MA0IAihbBI+YzFAG8hAxsaWMUEfKjAjhYCKKMFF7yoI46sHMRCjTypMI7RoGC5+XFkkUMU13ARBYQRQxZ5RJFDFAmMwYMavGjAiTbKz3wVsz/RxtiYYysVzDqIZFKc7Zde0qgROadMydbrsimVy2p0sbYo8ZlXUP3LP0Su5sQIwpjDBaxgEnW4kMUQLuIGXGgigxgyiGMDI+jChmmsoA0H3GgighKCKKMCz2b2ywsXmnBHQnA8dA6uNaUPMX1eLgPdThueK7dwBgkEUcE8ZpFBFF40MIINtOBGCEXglz8AvOVNcLkcGF5/EVcKDSQxjFks9xnkLlxrC3C+8Cwm/sZTsH3pi5j7TBc5Xwy2y5fgdDkwNCSbXLGoCnakFTCaGIloAbW1USKjz6SKseEqoDSmGzfUAGAU5/x5rcNhZoiZM7tdjDlSNPJ5jWZaF7tUSl6LRoGR5FeR/H8/h1Q9ijFcRfVPbqEZnkbh6/4/yI8/Bp9PFtlr14BYpI3h4i0U1ipIFIbhvPgoll/KoAIv0hjFNBbRhh11eBBEBU604UIDU1hBC17U4IF3I7lF37PZdGMlfY5ZFxrSgBhUlJxm1pIyrj6fzMVaTcafzU2p5pPPA3/5l/KZsTGZ56HQdqEE0qWYJel0tGaLstDZ7OYC7ZXXSM1LJHQDZD0YFfS4gUUiYhQlk0qvc7m0PojCCq2W0ilGR9XBIh1uYQH4/Oc1K0UKA41zr1eVumhMj45qnxo+00NDcm2lkpw7+yZRBOTmTVXxO3NGDExGBmmgki+fyWiWkUYDFc6ozpVOy3lduqTy48w4sQiaWSTWTpHKS2n6alUjyqR78B5Eo+qcRSIyJv3qS6wZJmYkSXmixDlBui4Lu7NZGUeqe3Lt4TGshfrM2jLCzYJzPp+A0spotH7mMxrkYd8T3td8Xo0I9lXb2FDaUTIpawUd7hs3lL5J57bblc9zzV5ZkbWEhhYzlZT5ZZG706mqc3QmeZ/oZDmd2vSVEXtArp21PowSs9YqGJTroxHLDBAjzKQwW4vcL1/WPi/cszifAV076NSzGWQv6HyQRs4MFZuyAupYMKsVDMo55nIyrsyo0Hhj0TnnDANI7fZ2cSKHQ+6t1yu03kBgeybUKg6Sz2sz0UhEHXmu/4AGGmiEulxyb6l+xvvk9UrmnDWuzBYzO9vpaBsDKqOyZmVtTZtzs7jf6hDfuqXtAvJ5mX8M8rExdSqlNTicW4CKBxUKug643eJ0Uh3WbpdzIKWUWStm0tnPiDYBjfudMoa9YhbNV/1NZH8yjNEP/SQyGzmUEBTHaGQE7X/8Q3B6X72Vja5WtTkxmRcMwDHrylIFqs3RGaSwCCmQpNk98YSqP1oVWFnDTUeX2V/K1pOWzb2ee0GlIvv10JCuaQya9tKVSXfmXsIM8MqK3IOlJRUHGRuTOTQ6qsyYl15S55tBk6UltXdYH03nenhY7tnkpNxL9oIsFiXYnc9rz0zWY9VqgDMcRwhlxJDDOkaxgimMIrXFSvGiLhdk7S9zQmEco0HBcvO9qMOLKnybP1V4kEcUTTgRRRZONFGFF2UE4Cg34X/ly8D5N2wpuJG68cwzMjEZdVlb0/QnaSKlkixwjDjQqG1eu47VP38ZwAWcxxxGkUANflzFJTThQghFFBFCCCV0YIMDbaxgAnHk4EcFU1jHBFZRgw8hFNGEEy/jEWQwjDFsYONb3oVs3rElScm0/tjYpjztQgpVdOBFE0NIow4P8gijgjYKCOEsFuUDxQLwCz8PjIyi/qUXEUEBTbhQQgAhlO8Y5iZccPyvP4X/R9+Fs6k0kngS6xhDJnwB7u/+vxB7zRvQaMhCsLGhmyBVYkjDoqocIy+Ua7XbtW6IPHOmrK11HqxtyOeBL39ZZb9bLYn0ut2aVrfSMOhokMrAOhfKiS5/YQHeL/8hfOjiDPJowYlFnEG8kMH5//cXkP2uf4x290mRC752E5Fn/xualTxu4zLacCNmL8GPChxoIYVhVOCHD5IjD6GACApowwkPamjBiQRGYMc06reVipNKifFtbXTLmoyHHpLFlQIb+bzWFnBzZC+LWk17MbCxIaBZM0pocw6zVqLT0axRb/fv69dlo5qYEKNselr+fu0atrKXLIrnfef9ZU0SN2BGPINBcTTsdqFA0aBhZJVNai9e1CwHJa4pIsJIPp1lcrPZKNbj2d4HJ5tVWgIDHFRFWlrSeiuKLNDAj8eFwsWaBfL8L1+W983NaUSfEUMWY4+Oyn1lFPH6dTGgWNfFz/CcWJPDDZ6bIgUELl1SBymfl++dm1M5WfalmpiQ4/QruGZgwVpHVyrJcakOSLDuy2ZTwxSQe7a4KOczNaUZIWaPu1112isVGYNoVOW1b97cbsCxHoaOIx0wOpXLyyrnzO7vpAfREGXGmFSpxUU1vhgQ4ZxOJNTQ4hpDUQ2bTZwrQA1Xh2N742pmhhwO+S5mGZhdYY2MNeIbCOj4cc+5eFH7k/Fap6f1d1I4aeix8S+b1qZScv9ZQ8HsE+/ZyIgG9nrFPBgUpHohpfOpGFqva80WDUb2nON5pNNKhaXEPuWlWbPp92tTTwYu2m2Z86xFZRbF79dav2hU1hg+M6TkkmrMMS6XJZvAOjHS0Gg4cw2k8+T1yndTOprr5diYPBc0XLn/89lgZp9BCwYiWLP3yisqLDQ3J5+leAjVUemksw9gNKrNx4tFndOkV5MaTpWyTEZZFV6vrlXcKzc25Drm5mR8Hn1UJd6tQcF+YhalEpB51duw+nN/jqH1FxGtJuAci6P1qtdiI+1A86vY2ufZ94+95ej0khbP9ZzCEQxudLuyd7/0kraL4D0hHZN9yiiEwF6NXB9Zi8gaKt4HBkfZX9HjEafF45E6akrI79Tslk2+i/k2cs+8hMxiAVcLk8iHzyIcc2w5eM8/L+vfY4/JD/ubNRryfbQlKZTDIGQ4rHYO6+vIQqFAB+ndZOMwM0pKYST+COyxMzibfQ5u1FFEGJNYxQgychE2mywgTz/d/yJPEIxjNChs8mLry0lU4UEZQVzGTURQxE2cx+RmFmYJM7ChgwJCGEUKMeTQ3pCJxEm3vCyLSSajikd2WxvJ6xnUWxXY/V54Lg+jVnNspUiZSna5AHTayD7zHOyww4MaqnBjEbPwoAE/KsgijDJ82MAI6vDjDOYRRhFtOGBDG0AQAazBjyq6sG1KdXuxiglEPW20v/E74X7tY8CKRjaZCeBi6u/W4EQJDrSQRRxBFOBEF+NYx3U8jDgycKINOzpw//mfAQCyGEcMOTjRQgIjfR2jMgKI/ZdfgQfrqMONOjxow4lY4Taqv/LLKH+vC4EnXovxcTXYSiXl55IqR6oF5blZPEwFJY9HqT80pimkwEwCjRMqBtbrkn63ykEzc0S+vculDhgLrptN+X+13MbC7z+HHCJ4Ei+gDQcq8KMDO2wAavDC/Uf/D6Jf92rUn7uC1jP/E3ZkturWfKgh1MnCjQbasCGAMmzoogk38ojgPBZQQAQx5NGUvB/qw2fgf+IJtKpKA8zntXCZRhbrs2ZnZSMql5XOxYhcJKJyvomEjKfDoTK85Fkzws16BBo/hYJyv638fRpJzabSFR97TL4LUL4+IMdh81qnU86PQQNmnljszGg0JWqZQYhGVeUK0FqfL39ZrnlyUg1MqiHSiCdnnbQ8UjBSKY3KplLyfaTZxOMyhozss8Ht2bNaT/LEE9q0mRQ7GrqAzKPVVdnMaJSR0kJaj7VXEiDzfn5eqWw8f9bKsBi3VtMIN7N5yaQYiZcuyb2mEptV5ZHGnderUUnSQHy+7QXXNChYGE/KXyajhiCfNZdLqUCzs9pXK5NRiiYFEjhemYw+h+vr2mSWdM5OR75nfV2zaRcvaqNFyl0nEiqXnsupcxcKyb1YW5MxvnxZ64dcLrl+ykVbqSuAGi7MaJAilUyqkufiolKQWK/GeqyJCVVxvHVLzmF5WZ0DUidpvFGhjPTGM2d0nWQwgfRjOg6kTlrlrDlvSWceGlKKMLMOkYga7hScsSp5ra7KOXMeMivFrMStWzIWdNapMkcH3arCR8onaX400ElLIkWTwYtQSMaBwhvMIjAzyRYLhYLWdbCB+Nyc9hAkdZL0uosXVWqZDZpJWWLWlNH3a9fkbzMzqgLJ1hOcc6w563Zl7cnnNeucSKgQUDSqqmE0eNnWgI0/L1xQ6iRroZhhfukldZwmJlSamjQwNjx9+WWt++JayGwVaf1sRk7nhM/1woJmQFgDzcylNZPIzMzCggOBS69BdwywuQEXZG5cuSLnTeYG1y6nU86HgS4GXEiHp9iANWPC2k9S6zweOT5l7RnEIY2y1VLlSGZOmbFMpzUIQ5EfyqS3WnLOV64IHb1XKMiKdhtY+u//B9GPfgCjqZsoYBYFvBkt3zBq3/BmpF/9yFYgBdASAYoAMRtN0Qw6TKyj5TM8M6NMB64RL7+szi8FqChGMTmparmr6w6Uv/EfYfx3fgiAHREUENykPm5Fyj/wgRMvvAAYx2hgqDUdyLzvPyL9/T+GIoJIYhTTWIIdLRQQRh5BNOFCCjE40UQHdgwjgyiyKAXGtrIJjJ5RrrlSAZrXbiD06f+NWC2EIgIAOih+1Q7nk69GZOgsJiaUhhONAs7F26g0NuCBA3V4kcIQUhiBC01U4IUDXTjRgg91lBDEMDY25cVrSCEOP2o4h3nU4YUDbeTtw0g98dfh6J5F/BsuIxB1by1A3GxYuE/OcSvsRBwJhFBGE25kEUUQFUxhBa/gMr6E1+EsFhFFDg60UUQINXg2BQOcWMcENjCGi7iBYWTQhAtlBLZxV2vwIIkRlBHABNbRhAvO/+f3ULr0BLpdx9a4UI2s0xHDOh6XQMZmWRiGh2XcOh1Z2FZXtyu/sW6KtCoajKQQsYEr5UC5CFFOeWhIN2dGYmlsTk5qJNO5toih5hLcqGMWi1jEDGrwowkHXGihDD/chQrWP3sTiT/6IjqbDrgDTXRhhxsNVOFFEy404MY0VlBCCFV4UUAQXXQR3Mz+lTelNZv/4B9hbsGxlZpnhmx5WcbN7dZCbYdDDAL2Z8hkxDguFHSxpCQraYd0Hl58cTtNh1z/hQVVm2O0tt1WGVou+OTbU8GLik7ZrDplzaZSlCiNzEZ3GxvyedKimk2578WifNenP63RQNY1UKWM921hQZWxGPmnChfV+/hc8Foopc0aEitFJxrVaCMziqyL41oAyO8zM3KN7FpOvjoLhrtduWcsQGZGql5XOt7Cgowd1d8AMZTW1rRei+IQvD4+43xWuNEzM3flio7nyIgq7eVyMjfY+2N5WaWfAwF5/nr7BTG7OjWlNE0qxpH/zr5DjPqz9sTlEiOaCkukD1IymFnaZlOOx3oEGjEMTrDPy8qK/JDK4nZrI2tmwzodOUc6rHTi+RqNqEcfacM5dxOtBTcKGTfCT4yjWnNs1UFSYKHb1b4/lLRPJFRxkwIobEvwyivAk0/qvWEk25opu31brpH1EWxzwLqHWk2ywDSqSPVcW1N6KGna4bBG9JnFuXlTJcuZmWHmgFn5qSmZ53QimPWZm5M5ubysCqrZrIopRCJyHjMzMuY0NsNhVb4DNFtlFVvg9XFOMrNNenOzqUX4jYYKUNCZGB1VWWc6WwyMkf6USqnDFAzK51MpuS8zMzr35udV9COTkR8GbZhxYBCOSrN89vksMLvAuUZ5djY/5zq0sKCUVwoQMZvP7EUmo7YClcbIZOh2dW2ORCQ4w6wz76/PJ9dH55nnwuDh+LhcU7stc2tkROstfT45z5UVbdROFT/KlAMq3NDpiKFOYSQ+03TKPR75PtavsqaKtVvXrsl5BwIyH7lvUIyBtLqRETk21QvZo4n9JVlHxSzj/LxSkEkXfugh2fMon03qLNcDqr3Sod2p2W0+D3zxQ5/H/C//CaYQQhevwVfxKMoIYrS6itYf/gESFQfaZy5tZeDSaVn/yEZoteQesIaWawfpsWxFEQjoPaUg1fKyjFMopHscKbyNhjYwL5eBDdcTwN/6Jbzmk/8eM9kXYMdm1GN6Wpyid71rP2b0scE4RgMAF/nEQ9+Mzvck0fqt/4IMIsghjA7sqMCLGrzIIYIqvMhgEm40EUAVLZsXY0NPYLiqyh9UfMnlgM78LdT+zxfQQBQV+OFCE3HkYWu04P3CJxD7+rfD57+4Re1wOgFXuoQa/KjCjSJC6MC2aTR7kMUQxL0SylUUOaxgCsFNNREPGhhHAj7UEEYJEeRR6yTQeA6IwwXbrSiyb383vG9+fCu6SEfO41FnwYHuJl3LgRZsKCGGMArYwBhCKCKDGNKIo4ggOnCgDhemsIYQShhGCm40sIBZPIfX4BFcQxR5xJDdxl1NYWhTJjKFIsIoIQhPfhXFuTnk/Be3pDcZUWq3ZQFm4f7cnES8mVafmJBF84tflLGnuAWjvY2GdpdmpMYaHWUxIxcScrkpCEA6Eg1na/Q0nQbsq3U44IQddaxiAmX40YAdeUTQgQNR5OBFFasvLyFR9yGENryoI40YCoigDD+6WBcHCi1cQAZ22FBEACHkMYYNBFBFAsPIIoTiX/k2dC88jbFoG4HbL6D8XB6rrhGsuh9BvenA616nlDJGza5elTFdWJC5urGxXSq7UlG1nlBIxvj2bVUsAjTzQ9rI44+rw0SFJxq/PCagmfmJCXXCikWllTHiS0OTRadslsg+UayB4mZOx4bZu698ReY1qZZ0aObnVfWHUUYKa7BegapvGxs6blQ1YpaN954y6Mxaku5TLqugAjdmRpAnJuQ7SGekA8WCfWYr6YhbI9pLS0LzYS2AwyGGOKlkdBwZSKD0MWmTLPomDdFmk82YQgA00Ei9W18Xh3hsTK5vclJfv3FDjn3hgjpHpF/OzspnNjbEcEulxMDZ2JBzn57WoNGLL8rfzpyRe0KDhFlAUoRKJTXgqBpIuhALkemkUtyA9Q7nz6vCFFWrAFV2CodVqYnGc72+qdz2ynPo/Op/RinvgQNPIoMwHF/4Aobe+jgSw5e2VAl5v599VkU44nGZi7mc1tZxbrOWr1KR9924Ic8Zo/M0iqksyL5YzEpRmIBORTyuDU2dTs3YMMtLGhUpObWaPLe1mjp0pH3R2KRACQVathp4elSNa2ND5iWVCNkAmL3ceA6k5TJrwuwbDV32eCJrgbW6VB71+eR+sB6HBuLIiMooW9XduJ5zDCsVbVbO4Ajrl/hsUnp/ZUXGmtfCQNoLL2gPPtZUspfRhQvaloCZPNbcWYUp2NR5fl7WYtY3sQ9ePq/PMvcrOpDdrq4NgNwDqswNDyt1nPVZnDd8FrNZrbVk9sXrVWp6NKoqbmRdnD2rgYiZGZlrV69qFoJZ3TNn5L5evCjHWV+X8ZmdVfGNxUUZY2Y8xsa296Zipm18XJ4H7vvcl+kQWxX+mOHn2sdMLYO9DofWdlFVjnM7mdTSAUDOP5cTx5hOY62mvdouX9bgI7PjvY1T83ngK19u48ZvfhYzWMUUVrCGMSxiFjZ0MIEEqvCg+H9exPg/vACH07GVEef6RxoxKb4M8ObzKkLFYGc2K+c6NSXPczotr5M+yz17Zkap45SSJ7ui4HkCcz/5Wzgf+RI87tuyST399H2RKSKMYzQAbFFYXG0E7TU4kUETblzBI0gijtom3cu+aciGUYIbNTjRQWroIurLDri9mo7mYlertlH63A3UEQVghx1tdGGDEw3U4EUYZQQ+98fYmPwhFEsOnDmzuaG7w9jAMMoIAGjDiwYc6CCECqIooIDwZuYljyGkUYIfbjQwjPSmkyL1QEPIwIYuavAijhyCKOBa8WF4P/5b8MXfjdL0U9sEIZxObayHDTvqGAFgRxNONODCOsZRQARDyMKPa/CgDifaWMXYpmqfSHFGUYAHDQTwCm7hLKpw4zVYgAeNrTGvb8pDxjc19IEONjCEJhworFfhuqxpc/ZoSCY16sFozcLC9noMux34K39FqV6ko5AqsbioxfuNhqpUcREkTW9kRCPGiYQWMFprjGIx2bgZnXVXhxDABM7jFlpwIIVR1GHfnDNFtOHECqZR/+KLCCKEFEYQRgEeNOFHBUnEkUMMUeQwiwX4UEYVHoRQQhhF+CHenBsNFBBG4S+/CpsdqD33J6jmMrDBjjCa8HlehdY3vxurk6/eUiSihHk4LPN9fl754oDWtqVSYiBfuKAFyIzitVqaUaQBax030iFY08UoKY1zZm6uXZPvIjVodFQjhKQ2kE5A6g2NefZn4PHpZDSbEgm7fVvmRLst/05NaTScWVFG4FnXwFoPOkjz81rTQUoiMwmcT2wu2Ghsp1gCch4sCme0lYph1qg/6YE0NoHtjT4BNZoAGXOrI5tMiiFeKGitCjfR5WWtOaMkLMU5WHxLZ+P8eeXv0/Ci8cwGlvm8Un6oUnblinzn+fPbZZABec+ZM2J48PkA9DllxpaGBZ3JZhMYGWpj45kbcFeyGD/nR+Pi48jlHFsS4GfOyNi++KK2RWABNml4jFyzniWdlvOnCAjHgcXbbBPAAm6XC3Bffx6l3/k9dGBHGCWc2cwC1xsOzP/Zy6g9HET44uSWU223y/GuXlVjjlF30rto2NOhp1rewoJmcdJppSkxqk1VOFKzafjTkWbAgfV3pJx6PBLc4Jyl0UxqEKABABr87bZmmvJ5WTP5jFDshrRK0lvZw4n1XHQK+AxfvSrnZ7eL0ZtIaJaJNYR+v3z/xoYWwtMR9/u17xxpi6T/WYUrWGNKx5NRf9LFmL1hDRkz6axnHRmR83/hBTHyx8ZUeMHr1XvIXm7cV0j9pXpcPi/nNjOjGb7lZTnPtTXgs5/VIJTfL+cwPy8/Dz+saot0CNbXVViH69DysryPrQFoONNB43pBkYloVBX2WBO3uKgBiAsX5PgUXeAzxKwKFXaTSc3eMmvLIBbZGXRSWZtGI573kg4+7/1rX6vGPFs+PPGEUK65zlPhjbLvzNBTzIhzmWsts+OA1mfxOlotzWZa6+UoAGNtC0C5dPZAmpqSMSFLxVp7eesWsP5fP4nx8g2MYwN2AC604EcVZfiQwCi8aMJWL6Jxexm14dmtQKzfryIzFPmw0iqttF/2m2KWlZk4irMwIwRoTRip2aSNx+Ny/fU6AJsDuUtvBN70xn4m8omHcYwOGVSFc3zu04h85GeAjQQAwI06KpvyCwkMI4487OigghCCqCCyKXtdy9Thq7dRrzu2IhwscjvvXMR6ewEbGIMfFXhQwwqmcQvn8BBuYQrLsFU7KOcW0Qqd26KFdCemAVxDFR5EUUQYBdjRQQwZuNFCEx404UIaEeQ36WnXcQmP42U8jGuowI+bmwp2AZQRQQ5d2FDYbO5qRwuV//6HqP7D16DVcmwtZhMTSm0qO9xowAUnmihv9m1yoIVxJJBHFEGUEd+UDp/DeQRRQhYxTGzWDolQgx9d2HEDlzCBBGaxvJUtkka6HUSRQwrDiKCw1REbocCWkdxqKe2CUSwu1NwwmEp32tvAV19AsLmKC68Jw/aWr0XH5thS03n22e0LKouXWbzISDwLnmm0kIPvdmuhLp0ybipOJ1B1x9HCMJbRxAxW0QLgQQeP4yVU4UcJAYQBuJFCCo+iDjc2MIZH8QrO4Ra6sCOHEGywoYAokhiBF3XEkN/M0kU2pbp9mwIMdaT+9wtYxgUMI4KHcQ2ADb56Bo6P/xo8xa/Fxl/5W1tRUcrnst8OOeHcjJhNWF2VDYmyqORpM7rIvj7nzikdi7LHpMGxCDsc1o7mlFWfm5PNlxmfZFLrnQCt9WDdGxf9dls2JtYTlMuySbEAn8YlI8Ms9mcRPGlPhYLMddaQUYBhdlYzOKQe0AGn9C8jlKGQSsBfvqz0tlxOi71pKNOBKhb1OSONkH3PSA9ZWNiucsQeIzdvqrJRuy3X9MUvihPmdqs4ibXo3doEmXOX85zUMwYBPB51ijwezSayiSADEGwjQKPh6lW5d6QQ9uPcM/JJNbfhYRUacDq1geHwMFD87Avw/tGvo5y3YwnDCOJ5tCKj6H7Te1A/+8RWU1M6OJQVpoQ2myaTrnb7tlwL7zG5+axFGRrS5oqMYvv9gNvZxsYfPIMA7JjCKmxoYQ6z8KOKMEq4iotoX5tD7PVjGB5xbN0rPjNXr+rzsrqqdXyU/6UzDWjRfiwm11Uuy2cYnQ6FAHTaaF69hdVCAZ6hIEJPXoTf79iiqLLonHLho6PynH/hC1oHR2VNOhTMItdq4lgxS07JYQom0Cmw2zUizfoIGqbW3jicQ6Rl0mnm8RMJmUfMomWzKlXMDD6NTiq9WRW6+DwxEzI9LcdfW1NKEdcizv1EQs6L8v9UIGTNlXUNYlDDbtfMVKWimUmKgLBuj1kxikvk8zLPk0l51h96SLNOsZg4hqurcl3ZrBb3U6nx5Zf1u6wBBRrQ6bS8l842swKk6eVyspY1m7JOsDY3Etnsi1jVusV6XZ1JUniXl2VtJwWaga4XXpD1hgpyVH+lc5BO63oZi+m6cumSOngTE2roMzMcCmndH+8bsxvnzmkgiIEtv1/3cf4OyDEWF/X+sJkxM8CkO1MOni0lCGZrJid1HB0OHctGQ+ZOo6E0bQYJ6dCs/fGXMPOnv4oOXHCgCwDwo4oICmjAhRxi8KOIOlxIrLXQdaoSpbV1Am2QsTGVrGdWjIEB7s3sjWYVXaFo0MKCjtPamu5v0ahmyd1ucZA4b+kQ308wjtEho1oFip98BkM/8yMAmvp3+OBCA34UkcMltOBADQEEUIYDblThhR0dTHUWEEjdhOuRy9jY0MnVagH1VBUdODCGNVQgodQY0giijK/BlxFCGauYxCPRDdyInsPaGuBcu43GF58HAITRggMdNOBCG274UUMKftjRBtBBEqMIoIQx3EIcUrRfRghTWMEQMkhjSJTz0EYJQWQRgwsN2NFBvtDC6vOrqPpmEAhgS+zA7ZbFq7l6ExkARQQRRwZ1+JFDHP7NGiE3migiAh9qGEESUeQQQgV5hLGB0U0FtSK8qGIFk1jDBFpwYxrLiKAIOzpowYEy/MhsUvLWMYq2IwhfPYfM3AI8s9Podh0o5NvwLt1AoJZGzj0E+6WLcDmA4MpVDOUz8DdDcH/qeUz8wYcRLiwjiygyyGJoyg/87M8D7/pWBAKqHsbNgo3VqPhFBycYVKOBGyIb5LGR7/PPa2SX6X6fz4HRR4JoXG3hNs5jCBtwo4U8IrChiwBKKCK0mU/zIoIc2nBgBVNwoQ4buhhGBmEU0NzMUNbggRd12NHCc3gN4shjEqsIb46hE22kEUcbIxjBBoaRRQt2ONFC6FP/A76LU2hPP73VPI4NHx99VOV3UymNArNGh6pbpGIEAlq4ToOOdCePR9XlKHjg8yktYmxMN3hSedhYkxk41tdsRbCgdDEab512G76lG5gqLKHoHUNo9DF4fA6srGhvINZRseaDNRNnzqhwRywm95f9Lcifv3lTqVUXLshGSs4+xRZ4ftmMzMmhjSQcV8JoPf44bDYHRkZkM6fhFAqpgcc6KTqLVvECRuSvXVOZYjaGZbNMZjTabTFQPv95rY1wOjU7Qj56sajF58yK8vpmZ2W8JiY0S5rPq1PJrBoNdSqt0VllkGJ5WebN+fP9Ofc0aBYXlQbCfmUMSKTTkl0PfuaTcP/pH8ONJOJwIY0h3MYs3PkufL/7a8i/8x+hfeGxLbEYzieOXTQqDk3hi1eRWKjCEQkhGL2IhQUHVldVFIFqcsx+MutJyXWPB6h+9SZGKvMYRhJeVLCCKfhRQwBVONGEGy3Yuyn4cytwTpxBt6v90ZxOMUhYjJ9Oi1HCHiput4pMsG6PGTyuO8zsNBpA5eWbCH32k4jWPo8mfKjAh0IoiPy3fwdm/saTOHt2e+8SKi8uLurzas3ssHcQDW0ai3yeWXdJYxXQZ4CGJ4NLdGSYAWJmkk10rfUgbEvBOco+MRQAYP+jixc1U1qtbu5HTW2QTolsKm1RwYwqZ6xDevOb5fgUlFhb0/oR0rDoMFK+n8qUVkovmxFHo0rl4vlT+IGqltGonAul5T/9F21sfOqrqCfzcAzH8Zz/Mbz0kmOr3i+bxRZlnI6GlVZJui+fKUrV22xt2NMJ+AptZJou2IdG0GiKg16vq6w1s2eslaVjRapzLLY9c0R6Gz9DSWw6TIAGBpnxZnNiZilDIRVqoLIhs/FsfUARG7ISSJ2zZplIa2N9ps+n+0e1qmsxnTTSEynv3mzKOfO+keY8MSHOGmtHOWbMglINcXVVa7RYl0cKcDqtmSYGI27fbMP93/4zxpBEFX5kEIMbDTThxCjWUYYXCYyhhADcqKJjD8DW1MbJbJ7OJuykDnK9YDCQjgznMufrysp28RjKy7vdqhgajcpeOD2tQXwq7JVLbby69HmEm4v3HZ3OOEaHjXYb+I8fATa9ewBowIUCwqjDjTacCKKEEaSRRxc2tNCGA2UEEEEBXjTQyeW2nCI2NCyVgHIjgioim01VbWjBicu4gYuYwzjWUIMHTTjhHAqjVQccq3Nofu4z6MAGGwKbogcB+FCFDQ54UMcYErChizKCaMKOGPKYxhJiKGICCVQ2H8hJrCOC4lZjtSbsmMMF2CB9mkIoItGqoLVJjZma0kLP6Zf+CI0bn0UFj8GJJkIowoMaKgiiDD9CKMGGDioIYhyriKCEJjxwoQDbZkbDiyrasCO32TupBh9u4jzSiOEhzMGPyqazFscUVrCAabjRRKHdQv3jn4AHHnhsXYQfm0JmbgORyhKAKgA73F47mnDBVVuECy2MYg1V+FBBA2EATrTku1byaH3XT6L4byLAW78OgCz88/OyaEejygengcTiXarU0HghDaFWAzLpNqK1NdjrDRQqQdj8Q/D5HFLTZHPDfXUZflQQQAVV+FCHGw14UIUXWcRgQxcFhBFAGePYgB9lhFBEC5KlK8OHHKIIoYwRpBFDBjlEkMQoGnBjBBuIIYciQqjDAz/KaMCNVUzBi+bW92YQh/NDv4lyKQj3X39yq7CdvHkWPGcy6tAwMkZJbVK2ZmfViKYiEGsLzp3Tbu/kdrPfDKOu3KgcDjEkWGTKPjIulzgmVMIql2UBJ7Vn6S+uofjHX8Gtxgo6mMMI0miEz2L57d+NzNjjCAaBQr6N9NUEKisu1Jpe2Dx+OJyOrSg1azdISRkfl/vMHiQrKyq5TTW45WXtOZNOyyZoe/5ZxP/b78KdT+ASrmIC68iMPIK1738fWl/z9JZxODwsY8GNlKpTNCopi7y6qsIGlHkm5Yr9jGZn5ZhUXaPBRqEL1r6xW3ogoDVOFDhgFLxQkHvHWoL5eWw11GU9D+8jVfZIzaHqU6vRRufWHEK2FObSfky+53G43Y6tjAKgNWfJpMwn/p39wuio2pdvAc9+BrXGV1FDDOuYgA/VLVESD0oIoIzm//o4PE8/jFzOgVu3lE61tLRpYCe+DNd//220CyW0EIQbZVwIe2D/hu9HY/hVW0YUM1suF+BytJG6sQFPuwKb04asdxaBgAMXPGto4zaacOMWzqEBFyawjip8uI0ZVODDENIoZ+pwVcXQYDDA61VFRzbWpQIhm3zS4GGmNZHQCDUjwDYbkH32Bor/6/8gjTimEMNl3EQTThSLYXQ++gtwjr4HwSe/9o7eMnT0SdGhI0DRArYjaDZVbpoiEMWi9mVjgXe9rqpmN29u7pMNuTZrFo79lazPO+s8WGMyNKQBA1J3GaAAtOEyIOcyOanZC0DHkusHFeJIBaSIzsKCXBdrytbXteaINWGAMgdWVtTJYXCFFL2VpTayV1YwXFxA0FmDY/wc3A07Gssu5IsO+KbGADi2qFj1OjCRfA75X/pTpCvP4TwWsIERXPP8DRQf/Ua4Z2e26mpsNq2b4bMByJzm+kdRlngcaC0vAJ99Fv52BXWE0IQbUWcTjYuvRcY9vUUnYybH5QLOn22j8+XnUF/PYCM9i3X/Q6hvOlI2m4wxoHT6RkNqVqJRuW9Xrmh9FR0Mfg9FYpjtYRaRzXJfeEECcaz/oggS68eYDeM87Xa15ovNXjsdcVLYZ4yCN1STvXZNe/0w8+f1ajPheFyeq1gMmBhrI//8LXheSKFi7yD8zjehUnFs9exj3ZvPJ3OI2U9rQ3gyDyhaNDcH3P7DK7iVi2AVb4QDLRQRRBMeuNFAA2440YILLdjQhd3pRzkwAldTnruHH9Y1NhaTcWeWj/TPoSF5VkdGpP9hcPkaKnMttIIBOM+dhd3p2Go+vrAgzy2ftStXZA4xE8hAJK818amvoPj7f4qXyp+EH19BFAVZ1D74wftCgME4RocM37P/B6HMbRQQxvCmfnttU9q6jOBW4XwFPgwjCRdaW4buGSyhAQ9anigCne1NEp1OoOAZx9IzPmTRRRhFDCGDYSSxjjGsYQyrmEDGPo5I6RLW1tuofO4W2hiBB3V0AdThQxMueNFADFkEUYAfFaQwDBvaqMMLoIsc4vCiie6mxLMYzBl40IAHjU1qWxRTWEEQRaQwgg66gN+HYFCpSp0O4HU1kP/sS0hjBg14MYGbmMEykhhBE15U4McczsCOLmawBgc68KCKBM5iGsuowocOgGVMI48IFjGN0U3jP4osyggggVFU4YMNHYwgjSIC8KCFi7iBBtxYwjTs6MDe7SD1kkiOy3g40IYT1ZodTThQxzjGkEIXti1Hq4Aq0ogjhyjCKKACH2of/FXgdW+F0+3Y0v+ntDQ39EgE6LbbmM5fhbOQwajTj5XhJxGPO7boOA4HYL9+BfY/+Qs0ajFUEUYRMQRxDd2zI7ANuZFtdTAEF5zoIIICWnAhiVGMYQ1DSCOEEm7hPJzobinAODfryIIoowEH2gBG0cJ53MYkEqjDhVWMb/Y0KiOFIUwigTYcaMKFHMJow4E8wnCjhiHUsIoJ5BBGBDkEfus/wD78/Vi99KYtqlkioRQzKs+RM046CtPxL74oY/TYY9rLhHU4pEiRbsdMBT9vpeJkMqoCSsOQRdXFomzArEd56CHl3rtfeQ6zn/ptXMN5FBDACs7AgyY8hQS8/+OjqL3tH6IKG5b+cg6lrgteeFDCMJrwwB6OAg47KokG3HUbxh6LoFpzIJNRmobPJ84Qi5Gtkt3WRn2ZDOC8eQXjn/iviCAPD6pYwjQ2MIp20onKv/1lBH4UyD/89FbD1W5XFQ/ZO4ZS0VT/AuSejIxIpur2be0/1W7LxsZmvaRMMKPH6Ku10JsGOGtIZmdVtQ7QflDz8xJ5nJiQ/ycSsqFWKirrSgep25WMXTB1G+0rN9F96Svo1EoYxktYRRR/+XNdDP3I30P68a/DS19tw3f7CiL1DdRDw7iWfxzNpmOrdursWaUdlq4toPXcV+FAA014MIQUigghhxhkqthQQBAhlBAorqJ7+wYq8Ye3sm4UFLj+53Moff7P4UEMLQzDizpejZcwXkjA//FVuL7zfVgeeQJLS210NjYQcpVQTVdRvb0AXzODS7iF0S8mkA5cgP/dX4/Xvd2F4n+4jhyCSG8GM1xoYQaLqMGNJEaRQxxBt38ru0ZnK5NRxzqRUHnyclkV8kjlonIUFbVYuyIy1m1Un3kFHfgQQR4ZDCGLJAKoYAgpuNBB/dd/FbXvfiPqdcc254jRY1KNSEdi75pwWDNGpdL2YncaotGoPh/MHLjdYlRRyKNQ0IbA7IfELBRrL+icsI6INXeM/JfL+tyxxorPBecfMw9UhSwUtLFtKKTjyjWINDsqIVLKmNRn0i3rdVUAZHsDZrvqdRmXytwK2q9cRQ4dtLGCEiqw4Qa8qCCIGeQQRhl2zG1cgO+Rh2Q9nXsF7j/9NbgR3FQebUtwtN6E67lPo2V/CzrO2a0eb42G0oopyczaMjoNQ0OAd+U6XM99BV200YADDbjRhQPFFlC5egPlcS86/mGk07L2jo4CnuvPw/4LH8ZKfh0bGIMPLbR9T6L0xr+G5vSlrVpcBocoOhGJyH3hnsEMPBtTMyPFvmrA9mbHXP+ogvbkk9tZATT+mW0kRYyZ8m5Xx4SMANZCPvKI/GuzidFPB5oZF9bRJJMa7HS5gHj6FRR//Y/RqNTQRREv/cbn0RkvIvkj78dG5B3I5TTwNDqqQUBS97yeNpzXr2IjWcZSERh6x+tw5ZoIKIx11jCLBbyIV6GAMJxoYQZLcKKNxqaQ1jCSeDVeQvZb3oOFgGMri8vWIVzrIxGt76W0PiBr9fDc5zH+gZ9DKVVBC5PIIwxbMIzWt3wbgm96AomE1DqxAXG3K0HGWk0zmaWSKvsGr34R1f/82ziHJKoI4AoewWvxPLwrK8B3fAfw+79/4p0j4xgdMjzpVUxjBddxGXmE4UALaxhDBnF4UUcDNYSRRxt2FBCGBw040UIXQAcOdD1+uJ0dBHxtZLOOLaOyWAScDsBvq6DcdcKJJrKIAJhFEEV04EQdbvi7FczNAemFHDoII4YsPJsNPT2obWZ8bCjDvxmFCMGGLkIoYhor8KO6KWpgwzrGMYZ1tOFAB/ata6zCu/lQprYEGda95+E6M45CUWsWhoeBh9Y/ByfWkUUITjSQQwwutJDCELKbY1KGH1lEsIRJvAo+VBGAHR0sYxINeBFCAS04kNiskRlFElnEMYKNTUeqjhVMYgRJjCAJYBQJjKEDD2wAZrGIEEqYxBo2MIwVTG0aoEMIbeaGcoiiBSeCKGMDoxjBBjqwI4MoyvAjijxq8KEBN4ZTr6D4yvN4xfcUctk2Jmu34cvW4Yn40HbOIpVywPbSV3Hxf/4SRnKvoAEP2migHHkdbN/1txB9/Gukn8JXXkH3T/4IFfiRRQgZxOBFA3bUUJ8voTUv1LYMziGCKMLIYwzryGEI7c14kRt1eFFBFFl0YYNrbAyNRA1FhOBBHR50sYFRjGEdw8ggiygSGMEiZlBCCHa00N5UAAygiiaaGEYaGUQRQRFAFx24MIE1xJHFPM5gBGm4PvIrGPnNr8GNGw4sLGjvC9ZiABqVZGSODspLL4mxxEU2m5XoHKO6FKagAUJlLdaFWftbsJEo+7uwD83wsPyNWYpOZ1OIoNZG62OfQRoXkEMYYRQR2ZSIt8EGD+poPvM5rLbjKG06jgWE0IALDrThLiyjBi86aKKbzgLzCbQeeT268Snkcm3Uri1i1JlCfjyAYuMygkHHloAKC92r1U0RiHwb6S8+iwm0EEQRAVSRQhxeVFGFD9fwCOy/8hU0/v6b4fY6UKthK/Dg9yulh7QSXuvsrG5WjLiurWnmzG5X2g9lj+m00illM0o2N2TmiAZqsaiNVdlnisbqVvbEtanelmuju7aKGPIIj7hRyrpRvL6O0YUvotNMooQgAqijBR+exZNYxQQ82TbO/MQfI/y2FHzPfQatfAZNNFCDEy7344i89Z2oBx7ZapYbiQDNRhu2lz6PdYRQhxct2LCEMyjBDxuAIeRQ2aSONeFCFlGUrnTheqyN0vVV5OtF2ANBBEbGkX/2eVThRwAllBGAH1XY0YENHQAODP/P34H7mzrw/8Vnkaz5YEcbftg36y8dmxqgbQyV5xD7jedQcL0FwbEwbieiCKO0KXITRBcxnMMCcogiaZtGNfz/Z+9PY63t97uw77Pmea0973vf4zOe0TaeAnUcJ4QkRqAQB0irSJHaNECbEKlCNCHhJa0qpICIeRGIEyiEIY1bKhJGD4DxjI+PfXym5zznGe95z3vN89QX/9+1bzt20yr4JK7qJVnWc5972Gut67r+v993vGNx+WqJ7vVe+Ut2d9PwkQV/ZCb9+Wxtc31DbmzbLnmRu2M+L8RitGY+sVOeuNcYqC7H8nIOXGkYq5ipRBjP1kbp5tTHf/ZvWf/7/5r9o4K9vVflkBnTl0mgsusg6x+q19OglYVsLJdJYpSVRWYyuN3dVz06mdxpNnvlOctYzSx8KGdt071xfrVQqOTZOTKZFG7Zsqw4OTODZ5H+zWb6O0ajV1LLLCr56irdI51Oeg+ZXD1L+su8jZnPqlhMv/byZbrms/8t6wnKOpMyYOHw8BWTnkkgnz3j7HMfKF491zI2sOOpB45daBoaOlBAXs6uc8c/8fPmL77F6d5nNH7+x73nbR1dtVBxTNXVTGztmX3xPe3ffl8uX7j1v2TPzyxEJZMxZvLG+Xyt9xO/ZKkchQ1L6whGmttYKXJ2KvfGrp2dgtde4+3pFzT++n9maWpo11jdniuT6Vb5x/6uw+9bmjz8rIuLV0XXGTv++HG6fjMA6erqVeloBqRmASNZkFG2fGfMdLbIdrvpu/gdv+OVZPPBg3SfZFK8LGY9+954FTGez6fv9Nmz9F2+8UZaIDLZe8aoZMt25rfJnqfzOfMPPtb7mR+3ttWwtqNvpeSDs6qP/oO/ovTvd0wPf9tt6t/p6SuPZa9H/fojb/7gX9cZf05O2+gvf90Hu581/l//e177X/0v5I/3bitUphGcdenQPS+1jH3WuykkqzhR3ZkZtV+FIWTP5WbzVRfWW2+9Ws5uny0//nm9v/AX7OiZ6Cha2MiZjZby/7cfVGkvnHzzP3OrIshqJ/LWjqaP9c+nbtYds527rq8LCvm1xX/197WNnThTtnDuyKljr29D//xH/gjf932/oWV1v7kY/Xq/Tk7cDYnEhUOn7hho3S4nr/sw3DItZ46NNeWs1M2s5OzPnxv9wH/msHTq5n/5x728/523UZvjD06VtgNbu06dGGk5cKNhYKJjx7X1du3qSd+wv1VWtFCOGOu1Y1fmqgY6yiErGUUgRDNkWC0jd5xrG+pru7JvJ8IaslfGcM2VlYPObcyu3Pkr/4nJd/6brnfeuh1oJ2d9eQ1LFXv6lgqm6ibqpmrIyVkaaBtrWqj6bj/tO3zeOz7jmSMrBQUbHX2ve2LXwEDTjV1tIzlbFXMz1fDejI3VDLTlbVXN9O04ceabfN2unnNHyKuayAd6O7CbUFNVazltQytJbF82t1BRsHLhwLMffeJZpWTzI//A8fh9Uyd69rRrG7nPfNryF/6RqheOXHnp2Fjdut/T/fP/dwf/Xs6b3/7trv70X/WL3jTQsVSSIiTWaUHGNA6pkTZeN1fxHb7kW33RRFNOkmned6ph4tyx7vnKAxN3nKpaeOHEREPHyLVdFw6tlNxx6dLGUsWFuktHXouuqr6mlaKRhqGmlbJiXC9HLh27VB+PPf/r/62X9d9/G2ecDUoZWpcFS2SobuZNuXs3HXZPnrwq3cs6g7KlOouJ/uWdSZeXr3o+MoP4ixevekfa7Ve+pMyUn5l4q9VIm/rwmfNpx7V9bO3pKlpZKRuoOXcovx4p6FgpmanHdb6Uw1xFKXIVx+ou1m2tr3zeYHDpa//PD+WXE9f6auYG5S8o/MvfbvHap2+XkGw4abdZ/8zPeWv+T8xVXNv3xAPveev259nIa00G+l99oTcqmfRX5sWa3Ye7ao3CraE885DM5yHNy70q9MsM95knab1+tVhm5vGskDVD5jNPULbQZUNqVliYIfIZKn919Sqq9itfSf92sxmI60df1vyRnzKdbsytrHQVdawcWFm6sRtS2q2ujoWyjr5dPTNV1//4I6+b+5Rnpuq2mj69+IJf/AcbV5/pmX3nd90OstXemdVyZOBEzspjr8nZauvrGKiHnK6vZamgZ1el27P6L/6yF4uDKEWea+c/p725kCM8fAmZHWnYuKNgZWfwRO2/+X45++Ye3j6D0gJ25tClro61gpK1n/uBzzuoP/Jc20TTTEVPx5ljC8nw0fi2t1C4jXjPZEsZA5sFB2QR1MfHLJ48V/ziL5pui7amzjQMnVo/eGA9L6penCtaWMnp6rsr78RLOVzZ8xbmSsZ21M0dOrf5C/+p4t/6T5396/+Wxyev2ewdeFr8VotlkgdlUtGsfDVL2nrjjVdJiq3WK7bw/v30Xh49euU9ymoobm7Sr2XLdyZRyqTIX/vHz22/+p7DzaW1nGtHxk6tTx5qnBzc+pMyJjZjFUql5C168OCVkT2LxF7N1waPz63GC9XDgn7nrnyhcOvvzKSImeQpYxx4xVBnEsqsEyvzUWZ+mmzhK5XSd/nBB/Q+OFO+ehIAW03N2EzVmWMVHTVzdQN1ZVWLtLx/eGry4VLLUs5Gy1jBynP3AsxZK1jLryamZzfsHt4yaJmnK5Nk8gokGo04f6+rsZhoSiqDSweqxlpWTt3Rs2uj6EDXm28euHd3rfID/41rO/oe2cqpmNrYqhurmVr+6D9w+Xs+ZTgs3D7rcrlXQSAffJA+q8vLV6Wvmecz8zWOhmub0UijOGJZNrGXfCsvujbThW2uonK8o1Ao+OCDVx2DzWZiNi4vX/kYswj3fP5VPUC2eI1Gr5j9LAyn1UrL/aNHrxjO09NX4SAZM9loLOz/5A9hqm2sYqpgI4e1gq49jb/yg3r/2+/0+GnhNr02k/TpXbj7/Es+smfhm3yzr6qa+Vr3UOPP/iXl4tb0m3+rjxvfrjkeahq5seu5e9by3vDEZ32YmOZV1eYv/V996g8x/fR33j77Z+O1s597rDnvKR20lL71NdMvvKczu7C3utRst73/1/+uiZIPvGWk6a7ndl27sadnz+O/9lNqf+zbHR4WbpUOFz/7rvGPfV5unjQ1I/dd5+4bf/PrrncKPjHcuB/S/JmygbZ3fNKers52mLbRn/xJfvtv/6edtr9hr99cjH69X9/zPar3D735/LG6iaHW7VDFVtlCPViPtq4PvGEd4QvXDmwVlM3sLZ87+q//U7O3v9fV7/rfGPbXxk8uDRwZagbzU5DXNla1VjRRSmzOaGNZKKFsrG6joGpiqqJopWHs0KWKubqpiaqFkr6mYxeqscSlyOdDRy5VLMxUflnfUMONzm0q3GueOhhf2fz4wMW3/vvy9x6lWOTnORv3bXHXcwO7PvJQ1dIdZ27smana0dPRt5U3U7On79PeUzEzU/Omj5WsNI1BzdS1fQeuVc1vJX49be/4zC31fOzCWN2lfe/4jJyvet/byLnrZfQoDdz3Inw0O5Zyxmq+2VctlR241jb0XCf4pbrZ3/sRDT9toubG/u376Uy7tr/wnpl6lNgObN3x1EMTdWsFL//Sj6j/4y+ZzZfqZnLW9l2qmvnQW2YhH+zZsVDSMLKrj5J3fdqJc3e9DGSasZqNnEsHkSp4YKGsZmYVKPZExVRNHseuFCMa/WOPbNHTNFJXsbJjKG9tT9eOgY+8ZoscWsEiXTrwtb/7seXvWWiMLs1fXlj395RaTe32jsvLDA1a6793prwYKjQbVm/e1WgUbhmK8fiVZCYb4LMo0QzlzJC/7/iOdJBlgQ6ZRGWxeKXlzozik0n637Keoax3otBPXrWyhVUY8u+GnGitYKRlq3C7XOdstPVs7JqpWsurRyHzxsZMwcyu9dOxPTVVjDTlrK0WBRd/7+vy39pW+RfvqZbWPH5ifD1V616r/+IPWSl6z1v2dF3b19NRMteKu/LUiaf/8LFG5BD2HFl9JW/84BOqx4fefDMd4uVyQkVvbtLndP8+1mvdH/+S0ouRN3Y7Pqh91nqdAh3a7VdFjrxCujODe8a+ZYlnmTwnY44ynfrJSfrz2cCVJWAdHlL72ue98Tf+rAt7Hnukr2Ws5siFnVj6d3UdufChN4OZmctjoBMR/WNncY++Hr6Kgbpn7hm/cypXear48GGS6XQHPnaoZK1qpmSpamGhqqdoZWSpYKFi341ioST3S5/XjU64mYqNgv6mo63mjnMFZQMtj70WT8mFz3jPQtKZtfU1jFw5jACdtZKFj71mpqZlIO+xHX25yVBB00jVU/dt5FQslE3tY2dn4fnyFfNCQmZrpx/avxo5fXJgObtntixoNKicfqD7Sz/v1B19e5FTObG0tnj2XN1ayVLO1lRNK67xvraxurmqnh0521SGbevKoY6+3MVLs//iL7u0r26k3vkmk9/z77gofvttx1cmB80W86wfrNul2Vjbnp6afXnk8FvXWm98ymxWuE3+fPr0leTp/n32d9daFx+af3lkUNrVf/hQ6/k73v7yP9S1o2BlpKER/XrT0w/kq0vlxonJ5FVoQ5YKt16/KuTMIuGLRbZPPnLxc19XX1/ZM0ry5Oq++r/83d5Zf/pWbpQxctPpq6jvVivdU5OPT81mY8tKzWWvIr+YKbfKJpUjhULhlularV6FlSzma7WPvoK5pbKymaaJqWUwmFmQUF/XyqUjV/ZtFOTie3nNx1aKHnhuoH0rgV8qy9mYDldmXpXO5vOvAIws8jqLFofRYBNs7cyeSxcOLVU0de3oy1tbK2vmm2mZeve53mBrqxBXWk3O2kjbRoL1lpOy3JffU3nzTcOzG5PBxqaVd/hb9+wOnvn6u1s3X6sr3T22zRVuF8/ZjNVqbfP0ifzZuZK69cW5kV1rz80t7XtpGevH5qO6R7/zRG/0aV/60qvI8HY7+Zs/+ugVg5hJmbNEwUzKl0n2qtW0pDWbr4IR2u1XEsmrq1d+s8WCwUcvbX76y17acWhlJedYzzJUO2k223o8bBq8/8Kq8PDWb3xxkZjt+nBs7a6X7rq2a1fXQCs8133lv/QDuv+X36r7L/5em7/zdxUsFcOPXrA21PTcXecOfd0n7Bhr/uWfUv8Pv02lWjD+3Jd0/9ZPMh0qSmz9hRNzJQUrLWMtI6957L4XJmq+6JtjLS44cmWLwXhr8u4TV403LJccdd/R/aGfMVVVVdHzwFhTe3vp4Etfs777pmt7nntgR9da0VjdB95SM/ftfin5jU5Pfz2m7W/Y6zcXo1/vV6HAn/2zqv/Gv+HO9kLfM00jVw70dWzxzD0Du7aKWqZ2vXDswr4bV/bl8cz9ZIx//8edzzuWZwuFxVxRU9PQ0r6xuraRkaayhb49WwW5fFF+vg5eZqRvx1jN3D3lwMBrZmqm8eBdG2r5Gd8VZv61Y5fytopBEc9UvHDPQFPVzENPve8tTzy0q6tsrmfHwK7yV39J+1vua9VZXT6XM1PWV7RWM1GwtbF1bc9GzkDHYbBUCzVPPfTYc/lgbdJiN7cMrD4LZChaaxuG92nuyp4X7nrhxI6+nh0v3VMx95pn+lp+zL+gbOnIJbaGOpYqxlo6ekhFsYsYg5pGGkamqk5jKd2Nz2OTbI9KZvIoW7rnVA5TFXVz1/YNtI0iBr2jZzQbevK1oqE3VIwdurBQddcLBXm/5LOuHChb2tF37Fwe9zzXs+sLvtlMRUffmZNY5kqOXKqaK0S6XBoO10o+cOFIxcyuGx1DK3k7una0bBSNND33wGseqxs5cu4TPvDMfS1jHX1toyQ/0nBt32y1sfc3/6KVrbGajnsmV1VbVdWDNy1ucq7fe2qqp23owLXhj3Wtf9vvcrNu+sTOjXKp6bz2SLNZuJUM8SoxJ5MvHB+zv7dW//gduf6Nfu5Y9d7bvvVbC95775XMolpZOxh8qN4dqt9paO2+bXP8Ss426K7c2Evm+2BUJ8qG2vJWOrpK6sqWpoqu3InPcK1gpmpiz42etpytjTRlLFVNLW0UlExVbCzVzJRUf+kr5suvOXvvPZYTJauUIiSh9hMNRSvtGPoyRLnpylDDWN2+axON6Byb6Dz7onXlsy4uTm47JbJgi5MTDr/yY3Lf/2dcXDZd29O346Z63+Kf+x3W//wnVavpMxuN0p95/PhV033ml8gQ8SxsIWOUSAPxcpkGiAxxzZK0hkMuztdO/uu/La9to6hpYi3v2oG1nJWchZqJpi/6Jkslb3isZmmlaGuj70DJUt7auz4pbxVet5aCraK55Re+aHpwz3BYkO/tm3vi0JlxCHBrIREda3nqxFDboWt5K/n1Ut+OcixgRTOX7ihaGmm6svSapxhYqEYZ9577Xjp2GQEyVW94rGHixq6uXTf2VMziudH0xCPXxuqm+toOdG0UXTj00LNQDUxd/vRP6vzeN9y5ExLq937J/n/3FzztN9St7dnR/0f3FP6F7zYqvOmDn7gy96apkoWyavAHKUBliqKlglXAIAN1rHV11Ey85SNNI0Md5MwjlqJpZBIhL3ecu7Jn0F9796/9lNX3dAwqb94yh1lKXdZFlcvRuv6Av/Wz+ouciYb1T54rlX7O6rv+eYW337q99jJmZ/jF9+V/+u/rTJ6oombtceVTdjYDD1yomZhoyEecTNHGUsHo42vV33JksShEUuNavTCzXG40ylvrVcN0WrhNDOv90gdqP/O3vO1KwVo/UlC7s4rnf+efmH2mJVe/f+tHynqR5vPooXvvscYXf9ZmMTFXVLRQtGOkbayokv+K7Sc/Ld+4fxuIsd0mFmx6fqNobaMaZ+vaStGOnhMvfeyhooWplrylqpGFuraBkbqhpp49S1Vv+ch9Lw20bq/flZKjJz9v+y3fZlp9YD5/VWuQJd91Oulzz5JTc5WyE6fe8FhPJ0J2NsoWcX/lsLL54APnZabVtV11K3k9bV376obGmi4cIqdoafLOSPOdn0JOwcJIRf8LH1sbuvaWlZyD0pxv/VaVN19TKFDsnVp89ETezJvx3q7smypZKcorurZjTx9b483K2d//nNw/W1X57tdvF9+MmeKV5zRj9DIWLUsWzfxWmRy030/Lz83NK09SFiiUhVYsnz7XefdzHnpiEgm9ywBPyKmaunJgqZTk6u9cmn/i4W0lw2zGejq1kDfS0TQ0V/fUA+0Im5qrWtxcWr37nnpp7WvuKlqpmaqbWSv5qs+aKjvx0lLZ0MZkWbH9m19QKW/MvvhVJWV3LLznU+rSudM2MFU11lS2Mg/B/UrZWsH73rRRdNephrGtoovrqbMh283a4ke/5H2fUDOSkzNTUzNLrCWGLy+MHOsYWippmNjR1zJyY++V3yhDfn6Dvn5zMfpGvH7f7+Nv/A35f/t/rzacKVo7cmmmaqbqvhfWCi7tq1hoG1spee6BmpmKqSce6tmxlXP99CYeDqncMxcj2kb+FuWvWrrQtFZUOntiE+xRLobktY2xppK5mYozx+55EYdySpbr2XXlwI/77d7wkUc+dt+plYJ3veWZB+pxEywV1U0UrfS0Xds3V1I091uW/8T+6day1jbdfuzIReC1DS+VreXlFORtjLVimFwrWivpG2v5Rd/mQNeeK+2QDwzVIwShr2msqqsW7NYmTNUfec2xcx1DRZsIGajeenBGGj7lfTNlN/YcO7dWcm3X1o5dXUVLe65VLIw0fNk3u9HxrretlO27kSeWi77DGJSnqhr2LJTNVBy58NQDS6VAnzemaspWOgaaRgrWsRAfWMcD6UZLwUbTKMpq8wpRZtu368IBco6dm2oESpVYw33XHnoewQkr1RAIPXcvhgtm6mpmGmY+6+tJgqmkbup1T6wVHLk0UQ+D+HMj7VvGaKgZTF9d3tzAoa21mpGZiqK5xtX7enaM5Y0dRBT7xHB6rf+Pf9ZGVcWX9RzKFT9t+82flms+Ui6HUXqzpndjPV5YFCrmX72S+8t/wbP+0lhd1Uyh2bb5/f+6T3/7txn010Y//ONyn/u81fLcjr6GiXq97eLb/hXn977dZuehQrWsYBV5kGm0eeGBkqeRjNiQt3Xs3NZGThFbdTMzZau4bjYKGga64U0rW1ko2trqaSvaOnBupmxha/DVj7XNbBXtudEwduXQUFPBRtvQnl7wDUmymWLTCxG3XjILRiKPmonNR18x2DlSrSajfLVKcTs1+DP/lRfv/7CKlQ+8Za5spqQ2u+Af/B0fLAsmh2/d+i+KxSQ5evnylXl8Po/+nViIsp6abjcNFFmwRiYvyRD70xdrz9/pKg769off5MCVjqGmoXtGgTCnZfyOMxs5IzXjkBZP1OWRs7XFrq59KeLwmfteuKNsZceNp75F3lrh/MaqdWg5WDnUN1cNaerWlSMTFZP4tStHhnZcOTaMhbhobaJhpmiu5q4XFqrxZwoBHNScOVGw8dyJubKijYqFPTemanraHnqqY2SubKCj4dKFA5f2fMVnDLVCoDpWMzPSjOFiqj4/V10889Zbr1l9/hft/ZX/RM1E0Sfsu1Y1M5tXnP/Iz+ndz7lRU7HUNjGzNFNN4T2KWgaJ/dJxZVc+ruRFMBCHLq2Vbp8bpGLtooWqfUMND7yMJNBdM2UXjuR/8gva/2zF9dXWYtkwz3VMp4klGfQXGl/+nOaTn3Xh2CLOqK4dreXI9U982fzJSv0zbxg+61pMlg57H9q9+XnVKOaeq6emvXneTMMDlZAepjOi5cJa0UjFQEf33RurxqHqumc5GCuaKsopzxcWvaqzYVmnc8e9E6Y/+Yu2qnbkrZQCaCt77sRQy+add9Q/gfb9W99dlmpZPH9s+fmfN7Wxb2QRAURFay1DSxXrTVHha19Q/VRecefu7Z/d32f4M0/c2LVQtlKQlzMM71rVUNeBkq2iVXgetyYq+nEWbOSjh/DGqZQYULD2wDOHrrx0R8FW4UvPTf6536V08LrJZG3Z7cutlsbnK8Wbre2mblvuaDQKiu2W/eu1++OXIRltWClqKGsaxWyQauSX73xFb//ImT3rCGjIW9kqKFhpGIUXM903eQs7Bupmpuhp6KrrhTS7tXxu+fNf1JuUjKZ504+emKhr2VpFYu420nKzGolR9O119LQNzNQc/MJPWf+2hwaDgrt3X3lg7t5NAM/N9dr44zPL0Vz9KG/3zQcWy+TDyjxm0+mrkIi33vplpbo3a9vnH8sNxk7zLcvCfTvvfk7VtZyNvJUz++aaGkYeeOk9b3rpnrwlCvJPvmpauWvaOtJ9MZbfrOVX65hbtmqmepqeeOBbvIOtC8ceeqYw7Fn+/c9ZhV96pWTXdaQCF106MlSXs7Urp2Bj8LWXcjaaSnI23vem01hU9vVcBNj0mqcK1t71tg+8rmppqqxp6IlHtrZWitaKnvV3dXPk+zdWy5JSnJ9jbVVTeSsLZU88xNZcSSvAlX03VkpqZk68cGPP6Z1v8/r3fM83fg7/p3j95mL0jXp93/eptP8PWsNh6MhTbHJf2zz05TOVoEVbClKb8UrBS3dNgpG4duDUya3sAuHN2YZeflfNWM0oEKmE2uRCk3ztQM5K3sZCTclcO7b5Zx4q2qiaK1tpG3rLB+Yqxqre8wln7vqib/ahN1TN3HXmoad2gwfpGxtHGEPDxCNPFWwtf/RC28ylAytFB67VzLwIX1XdOBqcJyoh6+rrBN7aUzWPoaofEqcUVck2TMt5e67Dm7BjK+/Eua5dbPXtylvextE2jVTMrRRMVPV1vHTXgWt1M0cubOW1DLBVNQ92pOVG25k7lspK5hH2W7dWdGMn/DeJPbp0YBIPq4KNK0fe9p65io7BLWKTk1M38sTD2589+3tzkTpYN7ZWVLBx7MxUXS4Msu+H9Khiaq6GjalyyOYSO7WRU4jv/oGnLtyJAycXWGfPHeeOXBqraRu654Ve9CVcOFI3kbc20HJtR8vIQtFcyaUddWPTGAIHsbhu5W/DChpmcqhIaYC9iDsoWPvQ66Zqhqu8yReeqH2y7Oj+iZsPLlS/8o6mS327GpYW733khYqeQx97pGhuOmpr/VdfsveLQwdf/2mVxVjR0lTNQ88cu1CZfCz/0wNF/8iw+Ujjs/+MsmdxP+146URX26O4D04dWyl6w8fKltGJ1Y4Vqqhoat9FCBEaUrFwTkvfVsVIC1sryf+VwItXsfRlMyOtGNNX7nlp35WCbYxqiZJZyxlrWCvo6JtqaBkqmd3Ka2zm1t2BzlvJNDT5735I/vSxQYSMPHXHU6+DqoWirrqJ5Y//kK+c/B7LyVKrU1R6dGzb69sdXSWNfOdArnOoWCyEnC4lr3W2Y41a3fnqWLdLcTZwczNVaRZ17u8bfHxm9PUrM9Pg104sVAPqGGnH+9jEtVexchPxJ4lt6dh3Y09XDmMNF05M1WzlTVUjjantuWMzNfsu1Aoj8/qe649SiEHeVsXCRBUbfXsBqrSsNGysnNk1V1GMYbRgFYty6bafbazpI29qGamaOHNgquqFQ2VL9730QOo5+9gjH3pT08CJywBiNi4cmAYD2dcx0vTSHTuGGrFA5a3lbN1xafT1zymNft7sxz6nZmqtZE9PxUIOOwb6WrbPn6prR4pYWomudEzDDzfUsFIy0tIxUTcMFrQWQNpczcjHHrh2aKCpb8dKyY6uPTfe8KGGuZ6OVYBx5BR+5nOKyvGUOTQ9eGjS7dF/rui9AMnKcgQqXdUIkKfw5CsmTz42Dh9j2VOFQK7z1g5du/G6G3vahs7tuQzAbqamaGWDhaKagev5ru2qa7XuEkP6UtFIVd7WsDfz4d/7kuHduvYqb6FtK6dl6Jl7RKhQMp/Xzd/7ik3uVL22q11bma2L1r2lTe/LKuYheerY0TWw0nMUDMta09CersrjC93f82/7+HHyZZz+4y876xd17djImasqWlrL2dh66dBS0STSArt2FK0CNEmLV90kzqCigpxTJxbyvsm7bux75oGFnKq5/Z/+OzZvfacX71dtrDSNbOVtLhb6juW9UG/nvH6ydLi6NFcJAGasF8/mqvXts36tmICG6wtPvRYKkZWasUp46xKjurJSULaI8J+lOy6dOHPu8NbrzMYkWIryV7+qrGIez7ScVUgI80pyjr0wsiv55MpGKvH7Nshbz2+snzw16Lx+W9OQ+SPbL7+q+EM/4WTaj7NwY1E9sP6uf17uTtF7X5hbVRq2J/ft7hacnr6KMl984Usu/+bnTWYrB67M1TwsbVVWWVfgiY89ch1BTS0D+y5M1V06DMZ4qKLo9L13nRkF0DgLiHsTypmCibrnHmgbu+PMQsFzdy3PpmazpO45dc++Szlc2zFSkbdw4VjR2lZJ3UQKUdmGq3Lryr6aqbaBhqG1vBceGOj4Lb5orGEr79ilM0fxfedcOFK01jSyW5iYV9kMZnGe982V7eqGD7fmwI28dVQPpLMu1bgkgWBOTteuopXBf/B/Ml8VVH7jZi/85mL0DXv95E/y4oW8Qx94w6WDKCid2MhZxxadjMHjiECYeemOgXY6/GL7rpuaKYWoq2GiaSmnYBt6Vm7sGqvZEgP8wlLeQkEhaP+8lWoMqpu4NQ+cKlsZ3CbYLQx0jINVSMbcFDO+p+vUib4db/jY6x67tutZUL1rxSTlk1L2ru3bdWOtELdHQ9vYI4/dOFC1lIt+om0ggheOvOGx1zzVNDbSCk/AlZppLAJVIy2XDjVNtOKGL5uFzKIaD+BkoGhF/9JVeAnS+jGO+O2UC5iEc2nRLFmoWcSSxZ6+vl13Xepqmmjoa8sCCi7tBQJbVrBWs3DiBdZuQvKY/FoHDl0qWJkqGTmI9zTXNgoPSTNGplS82zR1JBmPLx0R4RBzFTUz+zZ6OiqhWa+a3b63M3dsFB25duDaUlnVStPARsmerntexorb1DDRs+vMHf14pJXCU7WStMIDbVsJrSxZGWtZKsUa11awMVazUHLkStVK1Vg1Uo9yIdUomxOm3aaRgY78178mX1pbPjlVMJSLHLCGmZfuGkca03UwrSlZ8Vjzy0MNn5TwzJ62kUOXPuPrBpq+6rPJyzV65u7PfU1Px/veslR2GIdN146liYapipmpioqZFOuepEnHzu27tlHwNW0LFW1DczXFcMflrW6XzISYF1TMbORc2VOwUTXTjms2Salqvu4TLhyGWK92K9xL0qiyWfgQWYe3cJP+3e1UqbQr99/9DbnutZmyX/Rb/Lxv8dIDBQtNM2/6MN5ZyVNHlqenRhpa/ZeWT98zUbe00Daw9lFy57zxTebrnOKTj8101dwY66iqqDiI95vEiPmvrpW2RXtKuvaMtcwtpJb2lIaYalbX9lzp2tUPcOjGjpmyhqkCFiqqljoGTtU9C5nJvmus/YJvcx7szdhDhedVjdGNsomxuoaZI889c99IM/DmvLmqra0rd6ziGVw31ZSkUXMVZUtz5VheZzp6hlJqZKoEED9FwZVdX/VpHX2bGMp7dr1032sexzOxpGEcMrW6gZaZqq2csqlds1sG8sSp9Vf/iYuv5u0ahq/x3q2f8GMPzZXjSqvYEOdHz1hL1VjJLACxI1tbVQutcBVVTI3NrZT1tQLY2jNR9cJJPIXXaIBzxy7te+CZtpFqPHtXSgo2dgyULF1eLeME2/eRhyrWNoQ/b+wgysJ7SkoW2vqW8gEElgy0wrGXIvFz1lLx+dKVI2sFOwamAVb1AyTbCRZttU4D+VrRPAJ3NhIYUIj1Y/7y1FLRXqgzrsMXeubw1leVTpeKybalNblSmfTtxrB57MxcCvcpmztydQtujjQC1Kgb6jiZnVn83Oc5+jbjEevnfXN7sf4WzBXjWtpaKwfMtLQKEe5AU97WQMdWwY6uO6G6KFnraitZmqi7isCkXdeeeujUXbY5xfeTMytJ0CvxTEnAX9FGazB2NPianJELh/I27nlhKx8yqokDl16648q+gV0FK30tBy4ULDVtHbpx7jBOnqrUpDhz5dBAK87luVUwGInTXJgEQJI3NpdXtVKMZsexZkid805ca5rp2gH7bixUQoEwTCDu9ULj7qu0wMWC7s+/a/9H/7xWnOxJZn9sMSvZ+bF/ZBnc1alj+ULFxZtvWN5/3fMHJ+70v6793/4Vr9v42OvKcT7vLbueeKBvJ3ykdNzYd6NsZRmzUtXMMuayXIBkc0Viaa9aycdyN9bQCvC3q+PT3pWzVW3Vja4GsaCsPAqP9UA7nL9tOSureL5MlU3UbiXLlw6wtFR1x7m6maWaelgPrux76a4cdvVUTXUMfc2nLEIxUrOwkFf8mX+g+mBoUWmYqIYMOikb0ry31r993yVbean/cs+bPnLgWsPUze5byn/g37L9l777Vu74G/X1m4vRN+p1mgpXP/KGnK1HnpkrWyqbSYWl5/Y1FO3rWijdphTlrULGUQzUeteNXXlrEzUjTU1jRYtYLApuHJopy1sFIjizVleySbIbOS0D5fBBDNWVLKwVTBSVAit46USW7LZQlA8Lc5KzbOWtzVR95HWZXv2Fu0GbT1zaU7GWt4k1bubGTjhUmtZK3vCxgaan7jl2bkfXVN1Qw1KK566ZWimqG2sYqViERK3hTR/qGAQyMXTHRRS/1pQtDLQcujJTdWMXbclp86aOG6+bSFGnY1MN5ZAtrRR8xjt29cNIWbPnyoUjjzx14cCFfWwcu7AMavuxN3Xt2jXwhsfueqFhHn6FlWv73vQRtr7mk4YauvYsVHT07OrKWZna1TBTtTSxUbRx3ws5W+95w0DTQtFE3ZFrKYybYxfytvp2XDqQlwb961jEZqoahlqRgjRXC2NkzpkjXfv2XTpyqWVkruJDrzl3HKHqN+pSy9ITD5TCk1E2d+UglvW6nI26WbBndSVLDUMTNSmAJBXHDnTc89yR6xj+r+JBW3b9lcch1Njqa4cCOi3r9bjm87bWCnI2VnKmcU9cOPDAC4euXdlXN5GzMVX12AP7ulaKVgEqpESdjnIcJiULJ14qW/qKz8pKlNP7nWqYKFvE59eLYS4XEq09RTnrACNWouzQWsdUqlieKljbSuH6R/ryNoZ2nLvjRsdU/dYY3zZQiWW1bGEjr2ppoOYmhvTXrt7R+KGf0u9OUDRRjTS0vJV8mPHL3vEZe7oahs6dWIWc6NIxcWdPrI3VlCw1DbQ++nk1BQ0Tu/pG6lbxqVeNrIlBYKq7TRH7B24slYxUFKQY/WnwY9VbZrhuq+TQpWJIwLbxqbxwx5FLGwNTOyaqCtZ2da0VPPVI366mgZmKlZrl5ZXZJUU7kiui4iMPZQXHeetblnmhaBaIfZYyuFCyJcCUubyUN58PNn8RA2uSnKW/A0YatnJqFu46dd9zFQvveduVfVUzLWMrqR8sZ6NkqWYuoeZ1jzx115mXTjz2yAPPpf64BOZUzTVM9KVusUKwPQfRt7YKAdZuPEdu7OurWmvKyVnLhTJhYykf7O3YQNsL5G30tN3YU4t7N0WaT5WCYUq+zkL8d2K0S/E0LliYqd4CJgNNHWOTGJLrpuFhyBtqhNibmrl83JtX9sJfkZjlYUiFEziQVA6p6qF1m15atAzGb2WsbhsCzJythYKypWV8TzkUpdCDtWQ+f+w1DRMNQ8/dNbenKK9gditfrphrmmgaue/UuSMdPTk5ZUttAyl8aCaNwMkzeGVH4ela4ek/USjWAxia+cCb5lIg91xRydbayiLuoZy1mZqh9q3PZ2Udn1tdR99cSd8dr3nsgZd69vQcWKg5dGNXzyLYugzMWioHK72xVLKJz6dkbqAZYGpyUabPZIK8SUhcl6F2qOu7dhh/Z4IbBpZp0TKxUNEwCaAgZ6jlOtifuaLkq8rHM7OqbhSseB4FRSt5czVzTSkvN9V1jGxC0rlWktIf11om8rj3xb+j/rs/6aOPkjxuNl7b/MTnIvFyohCs2Ut3dO0HNFfVMpS31VmfuXhv6+a9rqPySGf9ZVnQQcMwrqqcD71upKUvFcnnbB1F+NNcyZVjE1VNAzvGbuz6mk8YacRZkc6sQpwbWwVFGyVr85C1Jq/gTLVV9MnP/SUL3+zMkSPn+nbM4jmUUnLTVTLQic+4ohyGjYmahZaylTPHlopKNnYVJedxzgv3tAxVzQ20pQTcqhyqAbTe2LNS0n+WqlEWt99XLr7HvHkIQu86t6ebmFcVz9zTenTH+LfdcfJaVf5Tn5KvF26LYH8jv35zMfpGvU5Oor9o10PPlawslMykNKP3vGHhDTNV5w7MVFw6dOpIzta1g0C7hkZSag0bIw1Z0kdGKSfyNKcci07eJsQhJTnrGLELmlIA9ETVWi0EYxUpJX8QJuWaR57GAldVjANyqWAYjMCerr6GSzuOXGmHRGyi5gNvhZ71KvT2vUCDRx544YNA6g90DeyYqbmJA79gbSp/e9DVTcJ7kfxBa3ljDYchy0uMVsKohppmqj7pPV/2We95S8nCFs89MAsG45Fnmsbx0CvJI6UC5QOrn8cDYxAY5DrkAUspuWljraAc6F3F2Jm78rYeeuKuMylZay15mupmHqlaKptYKCpZO3Iey1zBB95UN7EbeOi/4Cc89rqve9tZ6P2fumuubqGkFnbrkrWxpkqwcm09505sFdzzQidkgeeOFB146GN1Uy+dOHeIY6/7yD3Pve1DWcJgx+BW2lg2t6Mbw9P+rcTpXW9bqrnnmaceGWkZqdnEQFG0MtC0CWQ4SSaTcXSDS4ceRkntyiN52xg085FOmAaNmqm5coyva0MVeRsDTas4CGYKEYiRokHvONXT8bFHSKh6zaGFsqTtr8pZuuuFxwFIJOPsQmZGXcvfygx7IYJMB2CSLe5H4fFleMoGIfcoWVnJG0sNejUzD52qm2gYm6nf+svqpj7yyGkgd+lnmCmZSylpVVc6VipSQttIQYosuIrhcT44cym5m5aqNsp29a1tpeiVXTVTBStdbU8dmcR4msSe6bq5tm8ReVQFCzvKSmiZSKll5UA3hzbB5c1VzG6Xj5VcDOETDcm/kg+2MQ3kmXx2as+ugY3U4LaVk1MwJ1jYprqpVrzfhqldfQNNPa3boWulJG8jb2sW1uSSqZWFpT0beTMplTMxsKtY0HPxtMnHQM1W8jRtVWzl4r5PMf1jNdcOVCxUzeOzE+9qayZvohluvkUKGVHXtRd/c9s2xDxlMxMpjnmo5V2fcN+Zelz9SVCYXFeJvSr5qk/G8z9dT3kbd5yG9yZ5hEoW8vGOFqoKtiFfTT9lXkojXSlaBvu4VpS31Ld3K2dLbPDWqYYSdl07dVfe6e3Andqc8pJfsWakLpUvTG7PuBSNvnFtN77PlCa6jPt/w+11krcxU1E1NwsfycrWTFPO0qX9Wy9s1VTBQpJQ7xmrxbBdiu8xsdkpAj2nqhuAyiYYr4qCvEKckXXJpzPWUpP6w3YMlS18wkdWiu564ZFnyua/DGyjaGXPjb6ORbBNI01zlZCE9i1WExNNKwW1YPMWwbila6doHhLpcnBK6Y5Iz77MR5zuwYquffecRoBHco5N4x5M53cDOX0dFRNbuWDpxhomcQ8nf85WSmjMGLqBlomU+JjYoR3JN5yq2NPykq77iomuXUMNi5C4V80ULbUMvGkWTHflFhDOxR126Ugqqd2Jd7CwUUhxzmYKcZ+mM3JfwdIjT2+92bOwEiSVxEivt/L1P/XDLh58q/rdAzuPv2Bnfq5rPwpoRzI5/lBT2VwhVA1J9peE61tMF1tXWmoxb+UDsHnpwMCO+55ayZuYWsR8tZWz71olALa+lgvH1nJxty3VAtzI3m0+zsmGgbWClpFD5y4dahlavJyou6tuaO6RsWaAuXO7rj134swdeWsVSyTfd9JiVOWClaoHMNazq2NoGAqPmaouGvGpbBScOwqfWDpjj1yZK+lqB7NbM1dSDnhsEbLGfEySyZ+YM9JSNnfgxubJQPef+ZRx7jXHw4JydH/98vLo34iv31yMvkGv+W/9HoOjt1Uu0pA4V9bXNlG3CQHKSENfR9+OmqlLuy4dGqnaKOoYGGiFwCHFKJStFU2lfJK6jVTElskGUqzyOhajhNKULcIgWgpfylLdRE8ndM0Jrbuxa6Zm7jwu8XQInjuSKt8KFkqqpm60TTV1DFQs1Uzdc6oX4o6NnDPHbsKI/gkfBVp9bKTp231ZR9cH3rZQtlRRtL4dnrp23Av0PmH8goZOSCNu5QS/vHw2maG7oapvGmibqNp149i5WqAjnZCB1GNN2dG3p6dhFA9wkYdUC2SsaaahHbHKiRMrWmvY0dMyspWcKEtttZDoJKt/3nN3JPM8pThgS1bmap64K8Vg5yKdcOSBn1W08q43PfG6iZpKjEE5XDjQ0dexlEUbl6WyjYGWu5JP5dqxdTCJTzyyH+xPKhhs6Bj4pPdt5TxzoqdjHqhlzdgH3vLCPVtULe26lGKJtzLz7bHzkMp0Qv6RDzSrYmsiJ0VYd/SVLAL5rDm3r6UXUp9BLHDL8OvkY1RIK/MDT/WCOS2Z2yogmd9HUtdQWlqL8lI58dd8ArmQuSR/Xra8ZX6VhrFGyFiLFkaaerFM7OsZx32QDaHbQLmbxqZqru0pxME3j6FwIyeZ3PMOQ8aYkzPViCFtrW9HAauQF1VM7cpJbr+yooGevJaNI080jL10z3OvWSlEQED+1uOWMNAkS12qmEXKXt+OZXxWeRvX9qXGm+RvTMBFLdDk9DOWlG2V7LuMoX8nhu10INZMQzYzVZSMt9OQ6qwcmmjZxuKUTMi5OECF0LGjZO25O7fgTl5Kd0p82dCua6nL5diVPT/v2+Ti2u5GymZeTt5WOcb9vKVlDNZVaSBN9vq5jbqNooJt/HfNUiHAj2UMOenpuQ04aaLtiaqxVAib/VsbRaSo9pqJlG5Zi0TRlTS0LdwoOnVHFtKQmO+E6M4DeLq0T/DyLQNve98nfCRv48s+5V2f8p43TeLaeSWTEz9LzjTwfza3bEnNUs043k1OMyRhFRNMgrXeUTGP72kVz5DElU/tGikqm1qFbDddZUVNQ0lSuBeyr3xY96exMKbP9NKRpYIUYZFSMvt2bpHzsbqKaSShpp8zK9RumLjSjDs3DdXJH5nXsNEL4KBqqWFuqB4DeiYUT8t7J2Knp+rxXktyCurGt2dJqjwfKQa3l4uh9dSxO87kpUCAuYrHHoZEOX8LoCxUpCqJgTVmjmOZOZJS22qxsOSVAqisxmeV0k+3phrWlrHIRixeMAuJ2Uz9Xmwjb7EoFXKvfN2b2vputF04CoZ+ZangwLWRll09jzwPICPNIi0jxVBitEw0fWRP1y/5ZvNgh3f11cyk6oK8B57egjCZX7phGnPAQkqULCLnyLWctTNHplKhfGYZSCWyFRslFWnZqprFs7mugLZuLL1ZJMiVtZIDH4Za4chI3VP3LK6W9q5+xOAL6fTfBNPR07KQ0n+z72EaM08lTim2twxRplCYqLhwpGAlydfLpiouHNgo2XVlqGOiraBvoaxsbc+1sXtmkiB/KRPml4LdzctLAunE0NS1TOy7lsmmawqGWj7whh1dHV0jqXutZehaKvdN/+bCXCooSJ7KYiiJcpYKyuZKksQ3geezOKdq8XwteN8ngslaBHuVs1COebB6Cwams6kiFSqsFYjzYK5qGvxrw55rh27MlY0V1f/G/0OzvDT6ff+qw3/t2+zv/9PN1v9TvH5zMfoGvTa5gu0f+49U/oM/YRzo4VLZSkLcF1JEdC8srFs5s3h4pOMrGV1bhtpGZoquHapIUqK2geQvSmbbloFlPKDLcdAnPHgtO6iz5WolhR4U1J05tlIKnfKN1Gmza6YkNae8bq3owMKOvlSc2jQK+nao6YHndo2MVWPhSMbRjzxy6No/62fdcaan48B1II1VC1XkQ/+aZHMHbqyUTTScOnbgWkq9mZqEnCALoVgqxfsT6PLGc/esFN3z0kt3DLWCxRkbxEBWj7+rZG6o7cSZI5e2wRKkDK2WrpGefTt6nrofbFzq+dnYahkba6g6VYgBMX0vqShyR9+lPWVTw/CkJCPyxIkX4bPYDzo7DUw7+lKSU8dOBKAXfGwtZ6oeUpmshySZ0kuW3ghPw9JU6laZOnPgxp5DF+YqTqPstRkxDw0jLwIdfOKRx16TIjZTiEFHT8NEQYrILdp47mEchiMTDZfu6Id0qyDJJwchHSgHut7XMo3FN0saa7iRl6WGVR27sEXXnqKNXdeKMTwlZqNoGktK29DQTlD7CcPsR/hHlrr4js84c+c2pW8rebRqwT6w9aE3HOiFVHBgpqls6cq+nJVzBzaKJspaei4dmKnGd1mWhZosNTQMg5MoGgdCXDKzUHYd/sIkF0pI8bljdTM7IW9NqGMXG1Urzx0FS5Cz50ZOzqErVcmr1rODnNQ7MrpFL8/dCZZlZs/MQOe2AqBmLKWWrS1j4Uy+n22g+CUpvCW9r74dNw7iuE7M9EJZ0dYskP+GafzeTqj2SzJD+0pBLrDFdDwXzEO2lqJ4kySxaGliR07OUFtyetXVzYxVlK1CInhgGsxAMhkXJEnlXAolqdjEaNkwJYaslYqCrWks2nkpnY2CqjHW1shL6Y8bZSVbJfNYzJNHaaqqZGkbUMxMxVJJxcJWXlEKva0GOrxSVjHztve1jZw7dm1PyVJWHLxUcuLUnq7n7njmvl09H3vDD/sd8fkv3Oh44Y4UgbxRMZUCVyohWK6ZBlpcsdTUt1RWDBZiqiZJk2eBZK8DRW/E/bxC8nfNlALkKUXQQE/dCAWPPTRVd+Bc1l1TNwrEPI1M47gblgqSZHElBQYlsCZvI0Xh1OJ+7EbJwpmJpktHFgrmqoa3rPPMRMNSUSvizgW3UrLQsrIIXj59H1s1Mx0j0xi9F5JLJ4UdzW2UtPXNpXTNlZqFqkEsZslAfq2vZaLoIuCmmXKwQMUAenpWirpSUXcmmywERJSxc0kumiSJ+VjCi5aK8haqt5KyfLCaiV9J5asZE9DWj+U+gZtdrdtlqmcvFoeuLCq+EWdUCtBpyHzDOWsv4v3ULN13qmZqKCV+NoxchuQ2qQCS//COCynV9lDyWy2CvS06capjYKbuyJl9V77qm4w0wruYWr6qUjrn1lDPbsCL0/jZqrefV85r2rruOVOwjnM/Sby2thaKnrvnyrFjp6pmCq7Co91Bklyfu6NrISU4DiAUADNtPSkcZaEZqoYr+0aRhjeVoq3Sd1EIkKx6u3Q1AiTq24mzO6dvJ57z67gG5grqMYPl48m7MlM21raj78JRFHuMb6+hZB+o+Kx3nDn2C77dMw+kDqEU7pBSACuyNM+6sVQhsbVVNFW3E59NSvZrRBXIwp5rR64jyKOqGSEfqf0sgepJWTN2bc9IMwDfmYXkmdwqaBrb0bMJRrwm+RiTn32bVEmLl/w3f8nO/POqv+8P/dMN1/8TvH5zMfoGvfJ5av/qv2L+N/+epz/9ROaheOkklh62NnZMwtiaEOelgklI1zK5R+Jt8rdLzjIeLplPoHZLpm9kRWA5DatAsxLi04ibsWSoZqhjz03oqIfWis7dUTExUtO346l7khfg/LYL5aGnSpJ5shCY/pEbyXKZGJZtoBUPPXGg5340rY9iiSpb+KLPOnViqiIXaPRGwaFLU3VruVvzdNVc28BBdG5nr7GG3Yjsrgd6/cw9/UhRqpjb072VAe4YWCh54EWg/6np457TkBZsdQMlubEnL4Uk5KywdmEnEn4Syp88Awt1i2D62q70LULidRPDe07eroGt9FBNKOfMlaKNtNQNNZy6q2Gqau6puymZRlnXnrWtlAmTGIly/PsXjuy59prHJpL/6pFnRprOHJoq+4rPKlo7dKVlaBJSxY6ur/uEJx5JpaKpybpv14fe1jD0Se9bxL+Z1uGeD72mp+XckSceKFpomspbm6tZh9BvGwdTWfJJLBSlqPeKUhzGh1HAWwlUecdAywhbJamvZBrs30Ze2dJEMyQMmQm9YBtSia2c6zCn3ujE5z117tAL96U+hd0YSismKpaO7Ura/1EMkNf23Tiw78JG0VDLlT3J65OkXHOZVr13O8gkE/7Swl4M4CXjkNZkMth06I0tFQIznevox4GfUhMn2khG5BfuqQYT2jI003ChYTci5Tu6nnnNh95QsfCGx0pW+vZlctCJWgiOVtaSxyqle6UCgC3WSnJxbaVBZB4DflXBXBZXfuJMHbOQVnWTIym+i8QlbhRkKZmzWLi6UjR2QQpqGYY8qmBhqyDz3lRMjFVd2bdW0tEzVZG8Wwl1rVrZBiqe7quWmZKWseQzbFiEBGmqEE/IxCZm/rSSdSDcJZmnYy75Og9cIw1Q6ZX8OnNlTdMQi6ZBNifJiJKkbR5etLlDl8GOpcWup+OFe5IzaB0yrD2f8x028jqGnnnoH/oXJc9B3aFLT53ohTSzaG2JHTeqli4dSulu8/h0VvZC2nzmMLyP12omriPzc9eNAxemMZglNLimYmGoZhUMUs1KCmxJa+R5xMf3NFw4iBUqIe3XDpw419SzClR8rmIa3MzKIvjG9HmNNRQD1Eo8TSWYwJaVnLm6NNzlYwlOAsiFipfumarGAJiupeRySAEGeVslM1k4UVJdJMP4rr4tt9LLiYqton2XGsbyVvH5puLe5GUqGjpQN7Wxsa+naqFvxzoAzWzh2krypJahqbprhxaKt6xPAUsFM5VbUGtze00mWVYCHlIcQceNRqgRRup29HXc6AQwmuorhreMbdNI00Tyg+VMQxZVNHdtz0LJjUMFSxvUTW1NnDq2lTNVdaCrZhysURqQj1zbi56/NJQngOnAlRu7kpolhZEf+1jHyE3Auskn1zOImKkkC6ugGGtXklK+dE+Ksh/dLkudWGRytu46C0n3jht7nnrg2v7t5z2Lc2KsaR3n6kpRQQpgGthRi2dtAnnT86hiHn6jvKGWom3wuWmFTD4b6pIT665zLx3LxxKUYtdHWgamkhx1z42nXotk26asazHpLJL3s3jLTi7s6TtxoWgT0r6me54bannurpPwAH+gaaOgZuzQxkBbcnmVY/pKASkJYJsqWxlpueMsmLoU/LEfz7ekRJlbyfvYa3EKbJQVXMc5MbATbP4kzumtzCuVqkIqpqraxqo2t37OXfOYndJ9eOLczt/8L23+xj7/1u/7Hzta/0/y+s3F6Bv0qlRo1de6X/qKgXtSz3ai+/M2Th1bqtl1pa9hLHXNJMp9o25kYNe1I2ub0JfO4jGSCwQwoacVcxupwyYpidODOiFNTJWDIp4RAQgVYw0DLVM5lEwtJYNjorWnweQkLek6BoaMxWnF4ZuzMVRXCER7i6mqCwfhBUq+jRT6kCXU5EMW1YmbtGdHj3hfTcMYfjchsWCkZScOtTRsJqZtL5L0WoYhW1nZd30r7Xrhnr62I9e2trdegCwoIsVatgx0tAw1gtaumt72qiSpYYoF79pXMbWRTNdsY0lcOXLuxl4MwIUgoacOXWoa+tgbCtZmGnFA7auYe+lOPKCXKuaWCs4de+lEXmrWHgQaWZF8QMn0PblFJs8deeBF+L9avuybLAOPXChb23rprrKlh55rGLmx78q+ilUUu86CremrG7qxa6AlGZqTR2uh5MKJsaqjKH8ca5rIGWjFsJOPqzQxlfe9gCDgqYVscBIM40LJUEPH0EGwIynB6NRj952648ZueGM25uq3RH7W7ZMiAVLr+FVExLeMfeR1546sVWytTVRiiC2pG2uFubanc8u+zJW9dF/R0rUDrALfzRtIwSl3XZrLuwmvT8XKIt73SkNRTtlciixeOncUqN1KihBJSUIp/GLHVlElhrllwBuv0guPdCLCOjt4j12HZGJpZEfFxNK+eiCOmQQ2AyqymOOyFICQvtfkaCjE/76I72cZHJa497JBM3v2DDXD67LWC3YnhWJUpTDeBAes5OTlzBRj3ENg0In1SHKSuoW2Ucg8Um7VREs1fFhpkG1IAedFWcdRwmSLsk6qJDjOSWEB6dfSZ5lh9KUAmhISn7e0sQ0GRVy5uZCNJdAiY5lmwTosFYMdSpLWmZQSlwartZmKipUTL+3qubRnLvlSVlIZ9ExV2So44q2RuoJNLIBF5x7K+pW6WkY6sRSkYXmkFkz4y0hFLCjIGavKUug2ivb0JZu0eAYUVUyduFAyd+1IX1He1lTJMJL+kp+lqmCjbGmk4bH7FmoqpkaqVlLH2SbgCfGMTqdM0VySCtddWcZ9uQjhctXUJgbuhUrEM1N2qGauYGkey9XkVoZUuL03JqpysQyulKW68K2Oka1FfO8VBeMQzNUkD9XWSAotoaBkZaZhLadsR9mVfqSvVUMANQ+GuG1gx5UzD7T1gnNPzEFfLgCPdE4WLMzVJS/oPPiutMglUXjWEVO+vc9rJsE0pedkKnit2CjKxXWT8sCWKhZmypGsmfq6uvYkz8rYRN1Cx9bazKG8lccRO18I1qIX8tiVFNzRtyuJwJM/+J6XStbOHNtzoyS5PrPETHLe9HFIKJPf6L6X2IZ0mLqKE6e/LJm2o2Qh8f9LC8Vb9Ue6OmYOXJqr6Rh5zcc6ehHzvHEd4QNnjoJJXbvj3CJAlop1LKfbYGWrepHeVrKy70qKj0qMSgb2FK3t6dl35aW7UlBV4jTPHClZ2TGSorXT+y/F83QuJdOuFJw51jFw6EpK4a0EWJLsDBULS6WQvqbzc6Ipdae9oxNMc5LNzpw6du3QmRNjH5mqxRMjZxROxFVcQwt5cx0pWTJFqXeM7biOUu2ijeSjfeipqomuI+fuBPiQWNalqo5zb/nQUw+cuePanl19FdP4+7ehTNpYGaibh0qicqt6mQYJkCcKtRN4VLKS/4P/Dv/m96UYwd+gr2/4YvTn/tyf86f+1J9yenrqs5/9rO///u/3Pf8D5U4//uM/7o/+0T/qq1/9qrt37/pjf+yP+Xf/3X/3G/1jfkNe9S/+jOlw4bk7BpouHctLaSqHLqW+ibqxHW3d0H5mB9hcQ99I20jLWpZgsgxGJiVQlSRfRDlkHwkd2lpJsc5Fy8BGE+pdstKJVoGBHWUpTGFH35UdWZJY09hWCjtIhvSEGNTMHLp0x7l5HGpde+55KQsqmKp76KW2cbynqhQbWnRt15m7ssjXUhwXW6kstWfPVMM9L6Qe+Z77ESP60olnHjhxZlfXnq4sMGBP14VDVw60DNzYNdI2V9OQcvxnkl8gyeR2vXRsqGVja8dQxdylQw0TbQOPPFOy8invOoiksx/2LxlqS0ECBdtw+qyUtYylcOuJYSxgR1YGWpYhtagHI5SzlvqUmoZ2nTizigd8UvkXXdoP/e7MjVKIl9IxO1U1U9M0Ug6d/qFL73vLc/d07ejou7FvqHV78KTI9/RTpJjVuoKhMyfuey4ZlwshCZp57IGU5TR3Zuk0ZC7pEJ24H5LFRNM3LYN6T7r+mkYcFIlby98u7GVLjWCGrgLBTGN08glNQ/D3OFLI9lzHWL52qi75YtJgOw+JXQoJKUeM+8wo0K6NvGMXcrbRW7RnL1LO8njkiWv7ruyFATkFn7fNdHSduSNpv2d2wkmVUL6JngsrKfxhriov+Qlzshj1pYG21JOT1zJy5VBZChV4Fr0PKZwlJQrmLb1wz5qAJ5LB/MaOpUrwVHN7UqTtWklKO0velayANLE9iU1LMQlLqVMipUMNNElHlbQWpE9kHdKcZTw3CubB1GS5lHlZkV/fgYaeppG1krVaoO75YA4To1NAMTifxCilFSmh1PVYtMphEK7HGFYK23xe1VRR8ohM4xlZM5OlAJZt1QNZ34ZcpWJsasc6jrkkIiatCrngIRIzmVI5lyHHKpjbi3uhahUsR2JAS/qaMezMb1HyvK2aSTwTttbydt2YK7hSCaBkEqKdiiQfrBup29V1x5nnHljJothLLu05tR+f/Ca0A2lRTVHIJ45dEUBW7pYBOdCKO31HzzJ4umw4mSk7dyzlIya2KAVVlGNszMWysLSSd2FPMdibuUNVCwcub9H+1DmTir63sfSu5VXNHOhZKLoKX0QpJFk9O4qS7DU5HhuSD2luE0vRa57YOnXp0LU9ZOUBKdZjoWprGctBSdVEycq5Q8mhmMbGtAaXpNLSJGFMEuE1VqqSvDVFIK9jqC7LScmlmUfp0rFuJMaljLYdmaqjaqpkZq0h6ygaazpyISXEZd9iIe7Dvo20TKZrdWmliGVcq2vlYE8SWLSKb5Gv+bTXvR/gSi1O63qwmIkjTid1lkaY3CMtE2UzPXuSfHIcEr2Sro6USJpk4GmgvXTmWEq9bbsOyXTmkc5CdNYBFExUtYyduhuSv7X7Xpiph/y7Fs8WsfR2dPQdu3HkzFbGZJdUjSSbwNaOgYaxc4dGmq7tW8nLuhcnaq7tK+lby6uZ2DEwjCCMFD5DS9+lI1tLawUpXa/owJWCVaQDpz6tjeKt4uOu58Y61hau7UkhOAmynak6cW43Yruz0Jav+ExMgWtr5bg/83GtJD/ogRsbPRNtayktk40srCZ52QpSWX2yJ6RnWfq3xwG0Z8+TBMqleotNgEFzNXVzdSO1mMEKNh57TcnGvguLCKXIWL8sWqZprBQs10JJST7mz7WKmXHcz+UAO1KYysbEiUk8U97wkSMX4IV7buzYzmb8w3/I937vr9Ok/ev/+oYuRj/4gz/oj/yRP+LP/bk/57u/+7v9wA/8gN/1u36Xd955x8OHD3/V7//444/97t/9u/2hP/SH/LW/9tf89E//tD/8h/+ww8NDv//3//5v5I/66/6azbj++rWCpbaRpD1NuuC2obte+pJWoO2NWw1oVbI19uzJy6mbSmKYvMwAnCjSXDwmE/axCErz0KULRy7tSolTA0lCM42/OwWwsg7iOT1Wc1LCGZy7YyEVmdWlhvbkFEgHyq6+IxeeehhelbGUWlUKuULPGz6W0sRSLk0W4Xjqjm5QxWk4nmsZhy53a1/XTMW1fQ890zG0E4NoSvWqOnGqbfQrPu+quUeeescnve/tWz9AzlrFRDIOpijakYaUttYz1PCht73hI4euZHHfaZmbueulPNpGlsp+m18w0PbEAx95XR5v+9CNjpy8Azc+9kAxFs4Hnnrfm0axNr1wV9NER8+NjksHGqbKUhz0jV0vnfjAG9bKcqZGGnJBwiN8NySr/0zq9GlFEtvruva0ArW5sevKkYq5O85chVQwe/91Y7u6ZmouHNoNs3IKk0ga69RAXvfMiVN31eJATkN3Pjo2lhYqBtoOXSpZhFa75bl79twoW8jHOHrXS697HEtoX95WT+qBGIU0qxTyoEee2Xft3eAxP+lDXZ0YlpJ0byUvuWe2FupSzHNLPa69C0eyCPZkCp1qGuvauUX6t7aeuWckFeeuFHTtxkOelZaWvqJVGI+TLjsFijTi86j+MulfycZaXyuAgbKxun1dr3smC3YoWVgoRvBFWcVS6iCrxjNhHoNrgktI0paGkdShktK8amZmsTj1tS1lQs50fyQMc2KiESvMQiE08utYQEirUmJzUsxyqntMWvJ8LFivIppTDMZU0yaw+Cz5LP3rG1tZBWFOxTIwzeRQSHKngprR7UKQpCBpBUsR5CmVbxVDQQqZSUxoSuUsmcvJq8U9nzfSUje9XSYqwW5k/W0IHDclnS1ieSnaxv9PMrtxHPAp4DYli+aDJ8mGzX2XmqaxgiYkPEsVfd+b5sE6pfsjeUJSgWwKABkE/162sqMr66Xr6dhIh3QjcOZFMPdp7MlL3q2qQ+cqUrhBYtBSuueRSyMtK6koOBeA2UgdQhWQEuGSnLsaQ3pivJOfomkjecmyZWOmHj9r8l1OpWysgX1NYxs5dWNbWzcO9KSI4xSBnoochOQpyS5Xlhph1y87cOPGfrCwS/v65op2DGVdfTeKKlJeVioV2JNi9WeOnekEsNjXUpB8uQN1L9yV9a1kIGS6BtJSXA7gJsXw70u9eDNdrxlpueeFpplDZ67tGtqVBIXzGO7FdZiu53RlzpUClS/KnHcFFclvUra2q6cUwEoKw1gr29pzrRVw1kNPjbQ0jS00YskaytmGiC59r9k9fei5iXbkf+5YS9l3NTMr5UiTbaqZGGlp69vG4n1jT0rLfd04mJi2nrokJ750R83IQ8/VzEICnw+2P4VC33Hq5/xWjz1UMTdTD6YwjdSJ3epLcTEj1/bjpCsbaHjDQFklGMUUw5B8wuk59sKxraIULpVCLbKEvH4sezUpnr6rJQVIXEiet+TX+4z37eqpmQQIlX49H/d7wTpW5wQWpHCGpoa5mheRYri0p+sDn5CiDxI7P1WylsIOKqEwSc2JSYmz60aqCUgBJtVgni4dSiW5cyN1z92NBWilF+Ez6epIS2bNROZbm0o9aQt7ZmqS3ynVtExVXNoz1XSoayPVKsztymSpWY3LRgrySdEkzQDL0/N3cgsYpba/phQEM9G0DeA0gWV5U00142C3E3t+96/+1f//XYz+zJ/5M/7AH/gD/uAf/IPg+7//+/3wD/+wP//n/7w/+Sf/5K/6/f/5f/6fe/jwoe///u8Hn/70p33+85/3p//0n/7/ucXo5q/+XbP/83/injMvnJspe+SprCQvIdf7Lh0qxEMyFzfjSs2uG2LsSMWjzRjEJjqGSCb0hBpkvEsxZF2bWzYl6fw3Urx15lHKq0kpJDf2Ax+fhjZ0o2opQyhTN1AaolNoRM573vDSnYh1Xt5SyjUTh4YRxZsPUd/ESQQvrOUNtDz1AEnfPFFz6k4klVXcBB2cjqzUP5DR7Slmu6gUC8J//5W3kfVj7LuWilwnJuoGOhaBmnbtuOtUx8jahamqrl3vedPbPlK0cmPXnhsHrmWG0KGWE+fuuAhR3Y2OvqK15+4hk/ekTuq1VzHf1+ERqMQS9MJ9N/bNArFqS83wAy0v3LWRd+TCUiFiU6u3ErClsraeYiDVe3oqFhGf2rLvxo0dl+HROHAZhuiWsbpdA5/0blDyrehA6bu2Y0c3mr6LQaH3dHX0Qu6VjLGpCWIdg2PJ0rFLFXPX4WuZy/w/qednqCWPHd2Q8k2dO7bjfXece+ahiZrbQkZ5px7KyWk7t5XzuifhG2o6dh4oaQEVDfNARyvG6mZKyNmROrFS1Prq9h6jIPVmFZxH0W5HTwofSAPhQi3YsmUcklVde6oWIa/cGGtK1cD07FgGOJC3iZCJ1NUxVbWSfCWveaxq7NyRlCqUQI2FJAscSHGny+BmWobK8TNdBQqcs9EPNrlsYcdQ30xBQVMKxiDzJybBZSZyzMdzIDWUpQ6WVE+ZZFLpUCyomFrfLoVFG1sNU2tuPVZli1DjVwPAyez+iTfJBbtE8niUpfjfzJuTXCaFeNpsZV0r6VfXcT3kg4VLB3JR6mYrWcoCSIrBEDSMgk9L10YuJFspBmIdz7RCcDrJ05EYtCTySg6Toqqh5C9MnqtaMPJJkphQ83X8346BjmGMghUrTAhwJmn8l7GMJSnK1Jm7srTAZdzTTFw6krO8/TxXCrHQ0ZIWgvRvpgabsrmBkr4djeBZk6epFp7HzEOxiG89dzv0LBTjZx8YaYR8Ly3FuVi/Uu7aq36jhmkASk1ZyfMiuOxSQHUFS7vGaZwZzAABAABJREFUOiGZKxvb6FjGt5QxBkkaWUaSuAlWZaUcvo5iLL5ZImuSPmULeDuCflJyWBJVNqQi4EzOde1QKlZPgTtDHcU4YXLmCooh/luqm0Uf2UJWeZFy+gqmETaUk9IU5+GDXWjI2dz+HdXgPLLUtyT/Tf7gtomcfDxDC7dsWxrDk3yvEoqCBIiM7Rp45KkdYxv5EDdPgjGZubavY+TYmaUHyhZStHm6v9M3w56hywg8aRgEaLANZilFrrf1NcML+8TDYO+3hjpmUnl5z56+7a1nMvlktiHU2rqxb89N+Fc/hXuu7EfoSBZWk55gtXAcXdu3VPQJH9rTjTM3Bc+cOYnle+Fjj6QKh7mOaykFbSdk9jfBgKVrKgGTN3ZcRefQwpW7avGZZR1Vr/vYoWsrOc/d19Vy5UBNiiHJ6htqZgbakux2Y8eNaweSpzABbNc+qR/8zEJBz3EsQEV9bXUzu3q2thqhBcrL2XOtFvNXL0DBBJqla+DApUWodgZSuXHeKhjylI441NE01grWrGQqeVQbkjy/5lDPUMtM066Btp5ZgF8jzWCbpvr2DLWCBU0L1VJOW4qanwUIWLaI6z91WybW6peDT2m+2Ch5aOiBZ0qWru3b7078Rk7s/oYtRovFwi/8wi/4j//j//hX/Pr3fu/3+pmf+Zlf88/87M/+rO/9722Rv/N3/k5/8S/+RcvlUqlU+lV/Zj6fm8/nt/89GAx+HX76f7rX/Af/W8P/3X+kEQdKyzBkLikwYKbmuRMLxaBTGUgFpZWgJHPKgcwX7Lsy1NC3duRMHtMYWNLRlB6Bl/aM1RWt7bvW1jeVQhJSTPTKbsR31kOUUg/M8TS6lFpSS3tKxEuCgcyNlNCHrbm1h577Lb7k3ImRegwKJWMtIy17btyLB3AmH3seVa9HLg2lzpqNvImGa7sK1tb23fU8eLTJrwhbyFLosrju//5rrCHFLN/cLqCZXK+qZ6xp17WFkj03Tt1z7MJYw5lDH3jTUNtdZ3HoJpQ6S75Lkrn8LTI2DRSoaRwPn6KBHbv6SuZh8Wybqss8N3N1VXMdXXXDMHfnA4mZK4TkYxvH5UwlGsjLLh0ryOrUprYK6iYyD9eVfSslWbxw0UZTT8FGzUJXilHfDWasryMV2CUR1VTDuz59K8+YKps5spbMyFUzH3ojWIuSw5D/pc6NeSCfCy8cR49DkjsUpF6QJFIbO3QpdZzsyYdEZ2vj0JWnHoaWPMXZp0Uh9aAk7mKqZ8dMy1ALuZAypfjiSgzGE5UACpJ4aWUjS84r3MII6VCvmelru7JvrH67zJXie0/dMw2ZcTUJKJP8aarqzKFR/CzFWBQ6MSynAsy6tp5lsKlbPPa6a3uyLpGk4U4St7aeVfzehEOn4SVp8K+slEw1fKwd6Ow8huA967gPGsb2TM1iSUySsJKRlYmWYnwfd5xKHoUkdSrEdbGOxeWVQT4XaZWp4C+lFiVpY2JDMm+POBTTSpN8VsmCmwsmoyQxOE0jM2UzJSNt07iv84HQ9nRk3TVzRTPtkHtttCSPXeYzqpncshlpiawYqqMsK+3c2kg6+CS5TDHMSbSUv32u5OK+J8V7rwJcSrLLuqFVXNXzYPAXappOTR3GEpE31NEy0TFQs3Blz7VdKWGvHAtSur/XUnT6LLiKUuDpeQ3FAIWSXDQN2GU5u3oBTpQchJwuMVmF+Bz6HnjuRseerkM3nrkbQS6pu2qhqm4Sq9bKUEc1mMLsOZscMTlZh1HZ4naJnqjdLkZVswC3qlJACU2pDy1JgFIUe2JmE4OZk5MFNBRiEEyr+0qSHu/KouzTVViSdc8kFnQixfMXtEw1DeNEyek6sIk1kK2xlqlSrPALKQUud8scTbRMpb6uFChRun0G7Om5thf+krQgJhYpSaLrcc+kIJQU3bwKzqggMY9Jr1HWNFQzMZRqDRJKn5e3jfMqpa/l4rOvmTjQ0zZw5cCFI1NV19Fvl3rDqrcBDMlLVbpVl3zsdZl8dRt351xdTyngnKxKl7m6lApZD1ZjqRD38J6eEy+cOnbmTqSdXjl2ZivviXvIqZna0TWSinjz1hpGDkKWlzGmGVNXso57taWrHT9n3lgqdh2qa0jewxSMsAw/8V0FGweug9koSjK4Zfzt69trdRv/W+ZrShLnWaSA5o00oqpiz0zRjX1lK3txXyUWLgF9ycOZaXsKdk0cuNINZrIfYQgLZVtbVWNFhQCVS7HiL4NhupFD08i+G1fho02Je5UABSeOXTl3qGaqF8/AXX0bU6mvS5y1STKXnckzVS19b3iiYB1TSknZ3FADCagdq5mrqBoh5zpAgHbMXjVjY21dnWD7CwGulOUlj+tcLVQqKUgpVUfklG0spWCvuXcliXbRZpv7H5ig/+d/fcMWo6urK+v12vHx8a/49ePjY2dnZ7/mnzk7O/s1f/9qtXJ1deXk5ORX/Zk/+Sf/pD/xJ/7Er98P/k/7Wq9t/o//YTAbqV39wLUzJ8oWnnhwi9xUAu9O7ejJU5KKzZ7K0mDG7hhruutM08Q9L0PXWzKSemiyNLXUFV2Tij8bUgHmVMvMHaeyiOdMqlYxc+TCSs5jb8ia1ltxwGWSiKKlswhdOHbpoeeOnEu98xNn7qiZOHKlYqZnx5k7Xrjn23zRI0+l5JmEoH7a133odUmnv1I319WWEOO1ppRvtx+t0tkrS6HLGKRf/kqm+31FC9NAwJInpG8ipWv1tCwlG/hjr8dNPHYWmTtFm0AkUwxsN8Ja7zh36tiXfcZGTtswBp6pS4eBmFdicK7bdy3JGq+cO1IIpiAxUXvqZno6UkTphdQn07VRvmUHNtpSrELRjmsVMy/dN9KSi0GtZmodQ0pK80tStkuHcjbaRmpGt6xGknWkA/C5B3YjEuS5h7Zydl1b2TpzbKxpYxNsYjJJL1QduJIlLGXJhENtVzpuYtBPfRCT0BzndaUCyUzqderE2z7QlFKesgCHlaKasY0dyV4v8PxymJ1T6lzHSM7KjQPJ6L2S+iQ21uFzKAbPkUWfVi1jsMmHlr4qhfdOvOaxU8eeB1NXsbAxlfVKjLTiuiiE+Grjwh1TTWy96cMw/Rb07KjHQt82spJTMY2Ba6FoYWBH6qFZxOE1UrY2kFKR2gaGavK454UUDbtjJ1DSSweGmrK43xSbX7KxiWu/GexTOsLS+02elrROVHUstSNi9RVztEE7FvOkNE/yh4qVljRUpV6arBByLesqKoSsIx3LCylvriAfy2pd4q6T36EeA2oultSJjrKUApZ6ntqmwVYnvLgU+Hq6wpbygZYPNQxkIsaCTTA1CcVfKASfvrhdgFbBJm7lbpejppk911LyYxmZTDkX7NlMkvAlRiAnryG5Y0oWnrlnLuVYpXeU13GjJqWxpc8xyZj62rGYvErKa0QaZDkAj6qpzKRNcoBNFTQtYrBpERLtvLKGFI2b+rBuYlktWivZ0/MZ79rR8743fNm3SKll9VgeC1Ll60ySqcHKQl3eUip+Lchi3LNeoVTcOpGSAJOUNiUZdqRS3Y6mgRQvnNjHshSzvVC9Xf5YxWeeGLqcFPWbgLJKDFN5OQtZ/9BSyUhHIc6wE6cBjiy09cO3uNEN6dFCNe7h5IfKclwTf1dSs5CKQ1OgxlhTR1fWG9TXkeoCchoWeqqmgarXDKUuo9QgtlSQ5K0ti1uAIIWBlwKkTIW3uRBCp8G+FOqClIaXFuddqaA2xf7vKgSDtvUqaa1rxzAk8UPN+B4W6obBaizN1GI1SoPqKgbcbbAEySc0ksrSU/HAWgpfPnCjY2gjdUCl9zKNJVQsGel6LknR8smb+3U9Oy4cSgK4UjxvVu5HxUVfRxb73Y3FoGQh+d6KAVJUgyW9NtZyad9ARztEmbtSsEO6BsvB4E2D/VxaSQXlWYl6FlqVagP2lDS9dE8u7uyOnqXKLZOb7uuyHYNYHpLUdsdWL9QU1yF9nQWonGolRlLNRSpPLgaTW5a361mEVyXu+rmTUBwkl2kz1pWVQsgLE++f0vcqbrSUbaQerJJMRZMYmry2oawzrWffMuaZbTxNihZ62nat47mY2Pe0fo5sbb3yBA6VLCwl3+pWMaCwVTCM6aTJghwS2Di9nVGqJu451wt3+74b+Xu/epb/jfT6hocv5HK/cjPcbre/6tf+P/3+X+vXs9cf/+N/3B/9o3/09r8Hg4EHDx78j/1x/+lfP/mT8i+eKnhkqRSLzpWOvq97S9NY2cyVY6wN7IVA50wlbuwUrbqvYa4TmuokGUg3daZlr5vcDhLZUJ6VMFbjWN0oeOGuZL6faBoqSIbUrn0z1bC5TyKtJB2YzOIBsjGNgeJ1j73mmZqpj73m3Im+hq49NRNjNbuRLpfFIX/kNR1D97yQC46oY2hP33N31U3t6WpGQt1dL+zoq0veh3RQ/8oUul/rNVHz2EMlK3e9kHoMcro6YWGteeqBpaJHntl1o2HpfZ/QtYuNiXoslMkEXjbXCbP9RZSPJgZqFYMJTalNehroq3hYJgnDzEQyc7ZMJEnP1mueGgaCNNBwHHl3F07ULbVM3FgRD7i1kn19Zan49sqhlDCTAgyyZTQhanNze9jE2JWw1gxBTF1VeQMNLSMlN/YiIv3CoZSwdeqep1546MCVrDMjMXs7Xjox1NQ0cuKFubrHXrNQtqOnbKVjpIiqcWCyAkXLR4LeMwON6N1Zu+eFoban7gZSvNIJxCoXSPiZO7Z44LkUtzy/NaSmoSIfzOhaLnDYrEdlKfXMLIM5WVvadWNgxzs+cbvs9ezIo2Fso2gcsoVCSMRKcWSmksWytpF9V67syYzbaaGq6EsR1vP4N1NhYRJj1c0MNeVtFS3je00LzyCWkGoAKyl8YCJ5UzYOXdvYGtpVtIqnQUVOXtPMRM5IWSuGupTWNdIzN1VTsw3PykoWTQ47Uv3qQsEkgBWS2Cv5U1K0cslGU1cqeZ1L8fHpOZQaj/yy0SstbknGmI73LSqBX6ZkseQfSGlf7UDci5KzMrEIGUKZSpmnUo9W8lPUjOJX6yrBqqV/vxnOpbwUHrAOsUdKOMtL0eDbOMArNhq6brTDEzCLn2MpC0xJ/SfJgJxdg2n5b8krymK7m7cCyhQ4MZLi5lMJbRpSdnUjxEAwvGsFy5Cl5OwaWJrpa6pZyQSB2WKXAj2qxlpxnaTPo2Ogbahg5Y5Lb3nfUsGVQz27UqppNX6W9GkWpV637JNOA3tZ3dK+btxnpfiWi3HFze24sVHQ1ZbytVJvztbWSMUwlBHVGMeLRhbBmKW4j/STZ4EY2+B5JsHMluKZm/k+WsEwp0LmBACmWP0br3sqF4tuycrjkF4l5mIhS2G8cqAkC5BYBRO3ul3WBHyQgJMkq87SDGsmWiZSMlxJKnqtS5IjrqP7LKVEruVUbFRsbIxjNcoSXZ97IHW/pYiReiwbKSxlaM+NhqmXAaoWgp0b6dwydCn6+k6AHklulzHGaSxOsecz1WCt0uA9V5TCJRaWwaYW4v185C1LRScB2mU9eymMOck4s/TASweKAXptbT13x0LVnq5UCr0w1nBtz0xZOZji3ViYszCALLEMiraqUuF61cJGKhPIY6Kib1fVxEzldplIzOBGSzeuzIoLNXu6UvfgIJiZKymIquPYhWsdffsBoKSwlVQu3ZXSb3PmSmp45LELB/rhVSpbeOp+3I8r01A4pNTbtHpnBfWl4KB39e3q+jZf1DGSvIY1/8R3uHagpefEmVTYMA2pYzVAn626meTJ22oaulFSlUUtbLV1rZViDixqm2gauYkQohQJX9QykPkbEwM/slA00NZxYxurwTi8o2lNnN5aErbKUp1GTd1IVsScjxk2Y5VT8FTJwrUb+9pSemflM2/+fzNN/8/2+oYtRgcHBwqFwq9ihy4uLn4VK5S97ty582v+/mKxaP//TV1upVJRqfwGUiuensrio7t2lfVUzR268Mx9Yy0VS4cu7Oq50tPTudWCPnfftT0dQ/uu7eubSbG+u25cOXCjLZUWLqROmmwYX4VBenN7eKSG49QMnkzcBTkFOwbxGBSChrkTF3YMXTgILX+SFOzqSYWRCYl86oHUu9FTUbbrxmOPvHTHp33dga5dl4pxyL/vDWyCXB+6tu/QecQJV29ldVm6za6BuqEzxyoWama/KoUOBppu7JjHAvbYozCwLgMpSg+vedDShy5u6felmmtNF46UzWMIGCvHAHfm0H3PXNtTMTPUkbcJdOjArq6U/5MCHtYxqDx3x0RT29BG3gsnQWAvXDuwo6di6tqupx5KDeYzU/ecu+uOvJ62mtlt4k761FqqFg5dq1g6cBNIY8nALhhpmyhJ3olkAL50JOs5OY4I4a/7hHoclQsVh26MJI9O3cihGzmpjyAh5Qk5bxmpSgV4VXOpAHjfvgspzrkoZ+3SUUSmJ3fAnVvJXTrgUghCWcHShSMLFTt6dvXCR9N1ZV/byJaQcRYkv1XLVC1KM/vh3cqHj6hwOzSm+OyEX2XoXyoALShYuedGR89L9yzlI5hgLi9nIGUB1gLlL4TcpRisRD6Q820cM6t4jKZhemlpY2hHaiofqMZSSc5L9z3yxCLWrbx1GLgbMZonZjRd32kI3dFXtNCNMuDUETGKCHouHUs+xHagr0tb5VvOLTP81pUkacyNlokjqTy5aGWsJpmWF5oWDt2Al+4SErvktKrLWcbzJaGC5GXFuumz2CgHUlqN8TAJzqbG8TOm5o0En6TEtlVgrkPn9onPdxi6/iTrWsT4nFeQCnGTxGY3OJqtrGS0amqpYmtkInXjpECHbMhKsp/D8DOkJMRyYNOrW9RzqSRp+POB/hdukfEUVtu2kZcC60U/SlPq7UoMSAbMbGTpaCmL7dCNAzfW+NgDI01TbQspnKFpaoBKPEcTW5VCIGYBFjVMQma30Yglc9+Vz3rXVE1Py1OPNEyktL+8fTdO3ZWlhCVmrSzJhdKynsX+phj5hXkgxMtAvpsGwY+tXAYQQ4qbzzpl0hK1klphiqpWUghGPiSeZVnpOFmwePZ/WcbWMpanfDxt88Y6WgYqlvbdhALiIProqjaKjpy7tuO5B8bqcsrqUoLWgSuHLtXNdNy4cqRoYdfAsRdmGq4DNFxLTOsylulK8HxLRZSM1Mw0JZ9TWv3LIULexuKRk3ngFhZqLh3qhSJgqaCKAy9DIp2SFhNg2Leja6ruzJGRlmfuWqh76IltME6pHH0ebFAhluuiqR1bawMd21goE+uTNXmlVL5FLLxZAWoKsGlLZbYlH3ukJrFhN9rWCjpGUb6eGMUkxWxaKUuh+EsfecNEzZVdW3lZOX3ypiawKMlk68ETLsNTvHboLM6PlOqaqg3u2YnFJ/mrG0byUjprslCkbrpUl1GyNo3rdUdX6vw5kQvQcKBuouGlYzk5dVfWksGg40LZTGImG2YBbiQGtqtg6bE3ZbHdq2Ajk9x7phxzSrqPFg6CWf4OX5C3cc9Lb3pioOk9b1jHGZ2WyVmcX+U4VxnE/dKzE3PQ1MCOXPybGZiRPtMU9FM3vQXqpmrawSvOlJXUNYNRzxyh85CKbpTMpMCIsrkUR7HWk4pra8aqUgpqij7ZCfgqARzp2iLr70oBLHs+9sgnvKtoa/4H/rDfQFP7r3p9wxajcrnsO77jO/zoj/6o3/t7f+/tr//oj/6o7/u+7/s1/8x3fdd3+dt/+2//il/7kR/5Ed/5nd/5a/qLfkO+Qu63Fw+0rh1ZNOt9T0xUgl5d29r6lPd90Wc99Uj2kBIU7koqPD1wpSnFSS/VDExNAh3fSJr4ok2gKDUto/j789oGGoZeumti4kjXfc+MtaQwhGYIug5dOPSa5+566Xk8LIpSl0Ff0Zk7MUBU7RroRkN01USSIM0du3LHubLU/ZLQvqIv+ays632pqOeuppG6oa59K0XHLn3Kezr6lkpSh1AKBqgFhgk9bb/km3zZN3vmnjOHUhnimbsu3PNSztZQKyI30+Hwtg+kBK26la0r+7LYUVKiXMM4BpFK9JCknpqNvANXOoa6dpw7MAmk8DVPb6VFyatypGcn5DCVWwlNQo5mXrjrJro7qqaa+m4cGUsN2ne9tA66vxSHyZV9qX2ip2EYyYElbRPJCDlz5DJkgS07rrUNZPGjdVMnLl04iJWo7CJkgFmIw66ujoHxrWCldIuuPnHvFpVKaNBYzdSbnpgrynqnJmouHMvZuuNUz65VrJvr4BCGOt6TItFXpm7smaroSFHW05DgXTpQMTWMzzW1kWepQBUNUydOXTtUkImmFiHZSPdFGiOLSjEQp/6cRRweFe04clLfRc4dL3XU9bRNgz1MNbDp+nt10NTDsFpy6DrKPFvOVCPSdRjs4tJIUyZnKcU1nFwgO6Yhd1oH35RDx1DL0AsnujqxRCSZU8PQ0o6xXcfBCgylGPYk3c3JWVgEapgQ5rokBksdTMeu9CMBb9fE2z6MOOWaloGhHVUjU1XJw5WSkdLnUTJVMdNQNrWJBW8Tco6cVONbCEZgI/ksktk8Z8+Nmrm9kIfeODQPZvrGjmmAGC0TfTWpcDX9C2tb5WCRUt9ZX8b05oKJbplI/qeclr6WrRtJ1z6TEt1qUgRtPSRgRYv4xNv6UrFuzVhWkbAJpinT1GfSkRSUk3yVK6XwTNUj5bHsxn785IkLShLJlLZ417nD6IPb1Xfoyi9Ze+auuuSPmEiBBAllTVK1nHz45taB2y4sQ8bSCsHpL/ktzpy459RU1UDLBn2pbDKlUk6lgJHyL1s8kscmPZfW2vrBorelYJuehYaqRYBcqfC5Fvdoem6mrqKiFI2dzqaVFMRSlLIdB1IS1mE8eQqSWLBIwDBuV9lSwBLruAaKSmbykjejbeiXlzLPVMKXWnCgG6BjM8Y4qlIBcsM4fj2NZ1mP1CZkaB2922fnRF2WUpiG67KypX5874V4RqdAiqzZqaEansqUf7iOxWPoIvrF2sYKUkhRM9y5r0KHxl7zsZRKlgTNA21NExPbW0AwBWQkyXjZQlblcebEQkUmHc/CJDLp3MomfmrEs/84QoASr9eKUITkX02irrqbiPpOMdATjzw20HLqDVUppGmmFqBwglJ6OtpGESJUVrQyVVUgALaknsg+nySfLpphrRLy4IbEfFVkGb0p9TCnZP7/Yu/Pg2zd0rM+8Lf3t+d5zDlP5skzn3PnujVLKqlkkNBAY0lYBizLEAZj2cYgh7HpsLsNHTgwtsOGhgjATZvANjIm2oaGliyMJKOpUEkqVdWtO58x8+Scued57D/e9eTa5+jcW7eELi7C94s4N/Pu3Pvb37e+td71Ds/zvBdwT2uTESfFmGWO2ecSMOUG7xJhRp08fTIObZC7SAhFMEiZ2qDE3MoYELh5MOeAdaQyfO5sVc4leg3SahWvMTHU52xCjBQ43rKtl1OWGRLnHa5wnx12WaProH7ixcoGtakQZkabDEscISEbe86BS+LMUNOANhlXJ7Q+WAcsO58teVHNkoDVCqcYRNeqUgFTytRZ4Zg6eWpYH7coM4aEXGIl4hKFUZLUmdM3CW630q1q1WSOCebPXVLLQiZLig5+3x9iFon9UzraH+7xoULpfvzHf5wf+ZEf4dVXX+XTn/40f+2v/TV2d3cv+hL9qT/1p9jf3+dv/s2/CcAf/aN/lL/0l/4SP/7jP84f/sN/mC984Qv89b/+1/mJn/iJD/Myf3uPz3wGgoDEdMg6+zxgi1/nRd7mBsYZyhBmwib7NMixxzUa5DknT5csGVpUOSXB4CK7FAKucA/jARje+j47WC8CkzseOKKjkThj5Bw0JeGMxpgoObqscUjmk68wvPpxMsM2hWyG/cdTRj/7ZaLTPkcskaRLI77J7Fu+nf44zPSf/CqxUZMHbNMjxTrHhMAtMtPbb5OnzD0GbrMFHKzBgH91ipR5lwBTtHnAFntsEGNChXNS9KhwSpoeLfLUyXPAKi0y3ORdMnQNm8qUL/JxvsILGBNo5uAASc5ZYubqYFnaDj8/o+i4FNd4QJg5D7nEY1ZpkXeZ5tmFY5pkQN7BHc8pOkOVpETjIqtVooFUo+y6z/kqt9lliyJt1jjhlAKHLgAylZgyS5wQdxyQliOajpjzgB1OWCZJjyZ5xgQkGWJ9nfJ0ESl3wpgUZ1g37KQrao+IkiFEnjZVzmm7bFyLPEYhN7T0GWW3SVmPqhOq7h46pDHVpvtcpuxqGOd0XTViRJMiHazD9yqH1Cizxd5FFfGIgDABeY5Z5RiJGsxoUKfgnLA4JkncYIe7hAlz4JroDlEnexMbnhOmT5w2prCUdtCWOTMytBiSYsYYawZsilqWThhz5pxb44qpN8PUcWfmpBg7eEzANrs0SdNiE+sM1WdGlBQDRi6jmVoqEk+EGe+fMpqGMaHSqXP4Ym6cTelOm3eLNCHn5phkvPW8KVKjS9ptFiYtbk54hLDjjKxzQp8oK5zSIAuYHCtAhTpTQg4YknWZ3gGCE84dIGrkKofjUIZUEGI4GWIcLpPl7ZPiGJOGzdFyFY8QOTqYcHzior5yTpEhJrOrRqMxOi7pYRAjG48pBbou/RGQQeqR0wtOnlUfLBspkQwjuY8cOCdGho7LZxcxZoKt0ciFAx8mwtAFlHIOphSd6EqASU4P3d/zNAgzp0PacX7mDBxfrU2WqXO/LfudwLo62fiVqZGkxz6r9FBWFIx7YspPIRcgTQlRc8IhOOfVcPYDN6JWgWqT5ohlhsRYZ846BwSY3K/xtqLkaLpgHQwqZFXNEFOGpDBumSV/FDS3L8DVKTpkMQ7pOQUa/Aof45hVMrSJuutN0qOPydfHmJJiQoZz+s55ijEFBmRpuT0kTZYu13jbwVzDF3NEfELNc1M4NRjj3FWDLEQK3Eyyare11J27JJ/WkAkPqKISIiBwbuuMCAmGLhFiR8rBHE0QI+ZgrdbP5TZ3ydLjkGXnTEZpkWOJY9L0wWX41ZT6kGXCzNhgHyONm8z/zAXVHdJY6400M+cA42qBCdSgO4KR3MPUXTUzTp8+CdJMydIiQvoCVhRl4qofWWBOgRpLnLrqbZc0D5F0Qt8FnucUXcLEWjE3yWHy6hmSDFnjgBOq1CkyRx2rwpgsgNRqk+CeWYk6xhu1KkqfJH2yztm3eq9xSE3Aps2II6oOwWHqjiVO2WKfh2zSZZWyc7CjmKpjlAmPWUfqjnEGbn6E3PoeU6LJmIAaZfrEHcxwRJlzbvAuj9jimDRn7rvFBxs4X2jqkjJDYjxkizg9AkKuZYQlFU2+fcwqRwyJXiREBs6yDx2yAIzrNHczckSMFeouwSnosHExTXTD1OFCzFyFN0SGJgVa5GhSoskpy+73Ol/kVV7nNqqaimt+Toxd1t0T6DFjhjWerzEmSYgpI5JMnJDU0FXILI1n+nW2rixIb7qqe8AU65s1w3To2gRM2SVHgYar84RpuhRTn8ChVdS4POoqphO3SweOtx53lcso1isp4ZKxPZeI6jvr0aN361M0/+AfIRz+p3OzP+zjQw2MfviHf5jz83P+zJ/5MxweHvLcc8/xkz/5k2xtbQFweHjI7u7uxfsvX77MT/7kT/In/sSf4C//5b/M2toaf/Ev/sV/vqS6f/mXYWq8DhHNQ4RY4oQepk7WoMBDtuiQ5C5X6ZOi5QjTAUOalMjwmBJHSEb1ATuY1n+DDF1WOHbmekQL63cxJUaZGiaX2iKB9SoBk67cZI84A/rzOPOtK0yDKZMHD2A2JfLtn6acnbAUP+dwXKGdukQ0GjC7e5dkqEeGGmdUjSwZihK+c4f5175KmxQTIgwv7jXMmIAcXaSUYtKYXaqcO5ZThjJ1HrHBQ3Yo0GLiApq2c+Z3HQTCGsgWuMJDzqhwTol7XHaOnFWCljgjyYg21lXJKgwWXIWZk+KBK/ubK1WiTsNh/s1kh6hwSp4mSVcLsOpH4oJgnaDvMv5txwGBJc7okWKXdZoUKNAkYOLOUGCMSVgGQIUaHVIcccdV8tou4x7h2MHtKg7a1CfNEWV22XBgqjGr7FHljA5pWg4ukqTBEidua43QIkOEMTd4QI08BeqcOd6QGaguptiVdAVyIwlXqJOmxwkV2mRd1t3ALuImbbBHgwJ1cjziMlk6VDhD/VSKNNlnhTwTypxTp+CEZeM0nGJPhh4lzrnKfXbY45wyKfIMGZCmyzaPeJcdpGlmW2nMOadjjilhCokhVxewgCPOyIUUQzePLJvmnSirZJmsdYOACVmsD1aCPvusMHAAEJMaDREmTrJShlSWSShgGoLi83lSX/4FRojsO8B6yZjZN2crSZUzHnGJmQucTZBgTtlJqUppMM7IORsZ0rSdwEKdKD2iBK4CWCFFn7JzmkPM+DS/zpcZOBuSRtLpxlEwaeQUJlI/WrnJKHuZ2WzKtN3hZLJKZDok17hHhrYTljBVyRWOuMG7JOlzjx1a5C6SKmAhwMzln3uYAiSYYEmcCWmaWBPNNCb0EVxkClc4IU+TE5bpk2TElDQDBx2yykyJcxKMXRXKGmTmqNF11xi6qO2adH+IOasccgCMHYeiRY4y5y4YSdL67O8g1zsnNe1ysj+m34sznwZER2Y/wKoSkmXf4RFxuuyzgSlEzRzM2VpCjgm7gMHqj1YlM1VFgxHO6RNz4z/AFN7GzjVIsM4BUSZOQTDELhuM3dwrX8jkV+mSInBnnZIArHGyhM2NCJ0nwpQckHR8hBYVN4bGLQ0z5xZvInlstTLou3urUSZCiDjWHnSJI+qUabnMc5VT4kxokCFCi1WOqNIgxJwKxxyyypzgQsJ74qCnBhuzhtVg6pkhJki11OpTkmqZubpc/CLQFtl85mae1ZTiLhUxJs3IhW1xx8XpunkVZUiONMZRtQpfiCRDGuRc4BLmiFWWOGOCQVUtu23uXoq+q5pnMBnyCWAy5qbDaA04jTNoIhMK2dXHyiqJKYe6MDj3xAWGUju1CmaYInVMOMIgjWNi7LNOjBGXMFW9jEMyDJlToMHUrcHAJQWiSDLZ7GHSObUQIpONM2oPLs5jyUNc5XTGhJhLUtp3DV2C0OTKE5w6DmLYeRkWyJg8xAQoOf5hjTLW6sOC4IdOPjxg7laDrYusq6aHMJhzgToh5qTcqE+I8oAMIUIkOHPppTkJl4TsEOecFeaIBBBzIx9ziIAxE5f0mJEiR5tDp5JaoEEEa+huPLWxqxONOWAVQYE7JKlTwPiTAwJmLHPMDd7BFFOTRBhSp4wJK4wv/IIYI6wpR4KC88f6pJjTYYtHhJnxJjfYZetCVU++S4SJq1VZk/Mi1iusSIMUPc4puTudMnHBF+AST10Hk7MAdOyqzVXOaLskWsLttdbUdubmrfFUe6QxUSATUAmYUuWcLgbXD6PGCjMXnEVccteqalZpbaF+cwlMLMWg3EPmn/08rc9fZzz+rbvX/6yOD1184cd+7Mf4sR/7sWf+7W/8jb/xm1773Oc+x5e+9KUP+ao+xOPw8OLX+2xzTpE0XV7nBoesOQ7MlLe4QoO8I0sbdjkg5KhytiBLTq53mSNy1C8Wrjn3NfcZ9UKYYj0T2iSxXtdlR0JuskbaZYLDzAgXqgy/+ibtn/nHRPt1IkRZZshKdkTh938/vZXLlCMQefPLnP3CTzFnToUabQ4JM6M5z3P4tUNilAgYkqfJMaZYYn1vis40W2uzLB2KLg8RZ8QpZU6oEPrc72D6T45IDg8JuYCxEctQu/YxeOddVscPmAMjEpywxJSA3+D5i0x/nTLWjHLEiKEDd2VoUOQK72C8CJPrjNB3MJmAMRGWOCdPHfVHl8BAlzRGPA8o0SRLmwlhV70JU6NImwzqO9Aj4cy7NUUbEeMe25gS04AZc1pOsGCJU7qYKlDWZW6thD0hRY821utgnSNCHPA1brjzWNY7QZ8meYq0KdNgSIym67cUY0KLFBEmrLNPgRopelgvngl5WqRp0CXHEctMkKiAVfXOKBNijuSnZ24zW+KUDG2GpAmAAm3GBJRdmFSnhKk1zZkQ45CMCwO4yISpMdwyp5SpU6ThXOaZg2KaBHcXUxLM0mCPNbeKLNOlftxmwE0uPcGIfnWNXAEyvTGD/RPAyMwN8oBI9Wr0O2CZU8xBaPGQbR5yCcnAxstl+pkS/XCeTicgFoNYAKMRJBJQLAXkXr3M8Nd+jQYlF/RYF3htXF2XBc07BHsPSdaa6tsxK8QYOwVAE+W1xq6W/x4SpecgOVPCDEkQxSTLrXoQ5ZgqGTquCab1nAgxcdWXmKuojOhSgWgOplAsBjRDeRoNiMYhmY/Q271HZD5AMqtDcq5yYtCMPtaTJ4aBycCEIALCROiDqzZOneN7AVO7fJPqZpXjhy0YTcgc3WUKHFOl5bhWJsYRUOWcNH1apEkxoESTBmlqrGGchCGtCwjOFMFCJ65mECdLhQYRxlQ5d9U7a25afPU2QTFGbHmVq1dhvQnvvAORCEzefoNg910a5JgQoUTdhbem1dalzQiTep+hZqdx+qQRT21GnBQd5y4a18okc3suidVz2eMYXRfUmgMxIOccXQBrQZmjCtziLjPe4S3u0CDrYG8jApe0abkqkhJJYQacUXRZWgVnptXYI8M73GDukgRxl4jpkbzg6mVpMiLhzmVQOqvghBiQZIkzIky5xB490lQ5dWmnDlVOsHYLqsmavEKOCSMXbLWdAl/KJVpCHHLAGh1XfTKY6QTjB46ZXdyXOjhZH6lULMwoXmbUnjKgR5YOLcc1WuEIawexRowJMHAKYQmXzJoQY0CFESNX4Z1hzcfNETeerCnHWqPKpKuZKHk2R62MQ7RIO5GQuEt+dEhhzbm7zrm0SlfUVSjjjIiToYmR7TOuImeS2KaIF2fqHMoMXTK0aDiRhR5pTNTEqmstcqRc4tGCkBQZzsjQY0jAIy7TcUHTlDiD9RtMpxA0Ogy6Xea9DhnqCBY/d8HoyFVLrDPcGJNq6HBKBTU4MPTDxKFRBk7mP8sWuy64VZeoCYLXxhxqxdrSh4hiqnZDlxBIMXCQ5j4BEwfDG2KS0ylS9OkT8IhtVjnh0/w6j7hEhzhf5TnqFAkBpkQ6dgkkAwmOMYGBgLlT4h1R4pQwMx5wiSjWPFiiVaaGauNaok4U4wqlHczNVHpNUj3C3O2jpg6XYsAEcX1NsdEapIdJMCRHk0/yqxyzzBvcIEeHIudYI+cwEwy6PiLOKodI2RYCrnIXE++IMCHFJR4TZkqNAmkmJLC+gDFGrt7TcSJGVu8s0MK4Snm4eD7WH87U9vr02GCSqZLsPEQKib4dhAU3AQJIz+g4fqU1NJ64SrSNncE6oUOaEufkXrlF8rnL5PNmf2fP7rjyTXN86IHR/+kOxzFqkeExG/SJ85hNZkRZ4owR0YueKRMiTkvfml/mqdPFGieeUmXscOsjovTIkmLksiumoBWCi95FZRpEUOtBy9P2MGneCGPWOaLpnOLkqErwD/9XTL0kQ4qWZU3a59T+6k/Q/N4M6Zeukfn//j2XTR1T5pwjVsjRIYVJqYaZYg0CG7TJce5orbYZtlwTziVW2ec2b2FNSAvk6BAul4n8yOeJfhfkjt+htj/kdFhksrrBYBhQuLRG9qdeY0KUAg06pJBGv2UhbWWZ8Q9c9rpAH1PEMZWVFHUSpLAeF8csEWbOMqfUyJOjR9jxsfpYo1nD82ZJ0+U677iM38RlbWrMmXHAMtbYdMoKR1iHa8Nf18lzwhJpuiTokqLPkDinrGC6UQMSjEk4YI6RrDvUyWONLHtOiODUwZqmblsdu/9GSGJKfl3iDpYxpUuMORGs4ezM9ZpvMSdg4DD4I6w/Uctlj0JYu0EjGRv8KkkPNa402MSEJc5oM6BHlAhRqnQJM+FtbrDKCSVqDEiSw2RtTa7XNt0IEypO9U4BYIcMb3OdOH0GxGlSxaSQjQOwxBlvM2NKlAQmcW1GOEaMPhOX45uk84RyFcJFCDIwii6RCdUJnfUotjtIgWzM3FWOzFDHGdF0gViYMqbsOGGULtELleh2YDCAUMgCokQCkkkz5pOVLdKfmjL+4j1WZicMiTq415gRaTf+K25eGrdkVlwhWIpSf/shRl63gDBPkxI1ZkTJ0CW6AAdK0cdkeUOOpxVxoiFR3uQmMwKWOSBP3blwFkwlGFDgnBhj6pXnCMcCRiML7sJhyOVgPIZedJnZrQqxUZ3mfMTyEuSuLNP8Qo/ZvWOMyBvjEgfsE3bwtxSTIMcoUSE0azHuHxHFxOpLNBiQ4Wz9FaK5KpMppKtFxieHdAnTYIk5EaIugDL9MRu5FY4dIyHqYJcxl52fMSBFhg4zl71WXc9k0A1yWeSciIMozQjTDxdpX36ZSGGZchpiMeh07DkuL9vGPG1Hie0eOEfZYJgWWGVpUsA0lga0yZGl5TL6UcJ0mbqMe2SpSjKZZPboAWGXKZcalYjKESZMiF9AKCcuyzp1jtASZ7RcUAMmvFHijJLLoh9gmlMVjjBhAeMdqqmuuSjhi4DG+iElaVFgiTNgxgPWnBMfdly9pHNjwqToMXeVDJPezxJlTIaWyyZHmL3yKpFQl+RgRPDWMaWpJWXeZYdHbNEjRR9TYVRgHrhgZ+g4Ihmk8jYkTxeTSUldVLtDkTShWI7YLGA4nBKERoTmMyKRMMWlHEEQMO9COJNj3KkzcKBk6RxmGHKHt3mNmzRYw/qOmbphmq7r+zSgcxH8jZgRouM4SEdUiWOU85ZTpszR4SFrHCevkigkSRzex5o+tHhIjAExsjQcJC9MmgEBIWcTDFZnbCmIukqGeIQF16ramh74IMd4jqdUOeZNbpGhS5+0Q1mcEWJOkxxDkgSMyVMnYE7OJfA6VC8caGODBMwGEAoFkMxDKk8yMaUUPaN30GZYMxkYa9UxoE+B3HKS+fERI+IksJYNbVKEiDj4tkG5RoyZAF1SXMLUMm2/ibLGIWAw4iJhp15XRM15re0BbHBMmWMmBJyyyhvcwlqVTMjSZY0j1jjkiFXe5gpLnDFjTpcUTfKMXJUxwcTVznKuWj3HmmRbJ6yCazpbJ0sak/Tuk2LEFOM+T0g5SGoC4w1XOXMpnCkbPOYelzlhmUIwYEaawrThOHgJh5SJYi51mGVO2GCPMCGucY91HlNxtjrBgBxNOiQIMKEd454aaG/sAjAlxjKuGnrEstsnLdkSuJB7SIIjlpgRZo0z8o7LKJnwOeOLynzA0Il4bBJhQo46OXpc4jHzj32GdnaLyUGW5XfeoO7shIlAWBLH4IsmEiR+o/lhPTe/zQ5NCTEgSkBA+NZz9MvrFApw9arto+Ox7anfrMdHgdFv9/Gt3wobG0wedzl3REWpT01cVq1OngYlVzq3RxB3hgAiRBlSdxKhU4ysvs4hMcauPNsixIwqDUe6HDuOiGWwmuQpuIpCljY3uUeRc97mBqPbH6P9y18jTJ5lTEFvl202HFQrR5v0L/y3PEj9YQadgBZZkpgS2YwQaTo0KTIg7gjnlpNXczFrZtsjxJwGOXpksWamPdQTJsKY8R/6NyiUAiYzmJdv0U1Cax/aJ4ZEHBdvEnz/v8X6//4/kGwfYiTyDDEGdFmh58jmMQcesKZ/M8fFmLuy8JxNdpkScEKVcwrk6PI2V+iRYYM9snRpkmOfDWoUWWf/glAsPLVlSS27aVntulNFGjl4W4ZTluiS5IQSE2IUOCCM4f5nRKhwytwZ6zCQZESNMmNMPbDhJMPtXJah65MiQZ/neIMUffYS1xl/8ruIxGaEfvZN+tMUc2qk6DKIFIkWS0RPHzEiyiUekWCEiY1nGRHHQEMjhg6uYRWiKCbz3CeCdfGOMWGJc44d0KVJ0WXN7SlYoJRxZFrLmJkRNBxxlAOXCR0yxzggj9lggjD31kE7RsppM5Yo0OKIZUw1aUSVYwdBSTgeSIwEXawJYp8RCcLlJXI5KBbh4AB6vYBovkLyMkTGUyatFv3enFkQYX62x5QJLdKYpphJuS5zxhFVBhSYRfJEA8hmzWjH4zCZ2M9s1v5VqzAq7FDe2mJav0l80CVRSDLv9Ql+6edZ6T/gmGW6pAkRkNjeYJpfYZaBeTdC7PGeg04ZJ2jN8bF6mM4XRCjR4pwSIVc1MuiJEYTzTo3pnAL7bLDFPhl6HLLqAmhrXjksrrN8rcJgAMfHFhRlMhC4ClgoBLNZwCxWYQgUr9u9Dn7gR+Cnf47CV2sXldQoYyZEyRVipCsVej2YzXLMy2lm8xaxyYh+coNZKs90GpBN2DNpNqfs7TWIEHcwVavqnlMhwCSwxw5atOScPphyzApjIjTJuoqjicuE1zaJRyL0d7tMmLHs4HnpaIjB9nMMiwmIpolkl8mMAgYD24ALBfuZyUA6bRtzJJegzBl1SkRcgCURE+uhEqNHklFmmXBnyJyRczNhQpjJyialrTLjMUTCkH7wZbokXeY/cMC0BGqMbFDXLBlCLkCKssRdNrnPQ66QYkSH7AW/oejUSvuu1pKlSYKRq1wXXYXZqj8GF7ZGjRMiZF31+pgqBZpMSVwkeFL0mBHhlDQDMqQ4ZpkjeqScAlqGObDMMTOisLlNN7VKvAh37kD1YwMKf/MXeI3nOGAV67vTdZAZgwQZ9y0gzpg4HZe1Nxn2mKuih5iTLuZJ5LK0wyV6vYDhUNXZgFAoSSxm8zYSsZ/r6xAO55idLRHbb7I2P8R6FEWp5Ebw8Y8T/YURiVHfwRz7WJeltKPkD5gjSfUofZKIDzFnziodTN0xQpMCBlPP0Y9mYWWb6cZlJoMauXCbTDdPZDhmtHeCfVvIwXOjjNMlsvM58VCM81mRUDRKPDogkkgzj8bJzCakdw/pkSFOlwhTt4sOWeOQO7zFMRViDsia4YRzV40q0GEatOl/3w9R/crPUHi4h3WaC+i5CqOxDC3QjjKk0+kwDvJEo7YG4vGA1PIyydVl5mdTmodN5gMI0mFC2Syt2ZTxcRvr8ZWk5yoDeepMSDAi7KD/kQvI41vc4BZvOyhVjCR9apQ5c/cxxAQFAKqccZ23sLB7QhKTvF/jiAPW6ZLBhDvGbPOI5d/7nYQOA85+8YQTyhy40LGPCTYUaTEgcdGYNeKqjepZFWHEDOsFZ72RakQZOUmfPmNCFGiToc0ZS0QxzlWRJik6dMgTCQVsfvY67dWrRG9fJtiH4WtHjI4g1OwxmoXpzDPM80VS7VNizTpDUqTpATPOqJBkSJ0CTReMd12wYzDWKZd4RIQJe2yiXm85OqxwQMj5ItbuOEEO9feyGr+p0fVcNdm40FVOMHltq+eMMd5ulzRjIq4KFqZDmfCLHyO1tUlxDmfTdfrFFQZ7LYb9OZVEh+VMiME8zmk7Rng4I5tzzZ87XaazMJNUhmgux3AE3fMuvemMUgEK61kqawE7O3DzJrRalpz6ZtdS+ygw+u0+ggD+wl9g+oN/hHNKHFJlSJJ9h8VO0nO5RcPyGsTCZH+N/N9nTMqRk/sMmdJ1Dr+ybu6LGLgNJ+aACGWGVDgj55Tc7nOZGQGrHBFhwtrnX6B6o0L/jf+Zc4okMIWgPse8wOtc5T4D4vRaI1pvnxKQRf03uhd5lYA0LWpUOGaJOSZFOnELLcKYDtb9eZkTSjQZYhKaGXrMqitE//iPMbz8GaZdy+beu2cQl+HQ/n8ygWYTYtVblH7wR2n9jT/vsvsGCulg/W+WOSJw2YyuQyjnaXONe6TpscoRZSf9fE6JU6pusxlRpM0tXmdOhLe4RsyxGKzaYspZ264vhqRG0y6zFWJKkyJlGiy5Pj9GGA/Rdv1s6uSYEaFGkTnW5NM24yWS9HnIJazPlWkDycHZ5DHLQYPo7/5eItNN5vVT4qu3OQ8XaEYvM5sH9AOY/M4rdN5u8s7kDvXqnHFmicnZOYnTB7zIayxx5hq1WrhqAgaGLT5mlQGmvBdjSoE2JtXcd5jlKWdUSNPFmiCGrIp1Kc8ov87kNZMqL1JjiWNyrnRvMLwEFQ5oU+IK98m5ilyXFAdsknNKYjUKjIhRo0KTPHmajjdiqoM5l4e2Du95QphErqmETSBfJpEKSCZt3gwGFsCEw7YEu92AcKpIOOIof9UVwqfvOuiPwQI3OGCLfbvulRX6g4AgsMrCeGwO9Gxm51TlqFyG+RzC4QC2NpnPodeDaARCt6/ROXlAYX9KrVmgH6sQDQJmQztfanOJSGRG5+EpLTIUSGAS02OamEqdZQAjxOhRp0yOFjEmjiSfoHXzM3TeOr6AdBWpE3KwjwJth38PEa+/TbQVYZTYAOwas1kLWCJuTPp9qNXs/s7P7fV+H05vfAezyojI3UPm0yzxeZFhao1MPka/b+cKAkilA3q9IqE4JOMQntvrGpPm4wYBIyc1Yr0u4ozZ4aFLIMRJ0XdVPaukaB7IeQaYhtJkb60QWV9mNoPuSoXk8JRKLEN5KcppbIPjw4BQCOZTCDX9c6vXzabE43ZNiYQFR9PiGplfilLpntBjk1OW6ZMmyQBh6KckmeWqRG5XWQqOadcm1Mdp+rMC8bg58gDlnRWyZ3Pm7eGFU2oMOJPxDxGm61ZJnYKDVXWoUeQdbnBGiQw9TqlewGtXOCJDk4ApElkIuypOwvEe8zR4xDZTosyRslZAGOsjNU2XGXU7WJtYg/4OSRLCBHCazBgRkGHqWIAdx7iIOqdyxNLtIr2iBdLZLBQ+9wqd4E9Q+p/+VwrdN3nIFjgw1hpvcMwKEyJ0iVCnSALrXVZxXKUmWcc5LBCNV8jlC0T69nwSCQuM5DRFo7a2x2MoleDSJbuObmmZ0I0Kw94VUv0evcor7L5i6zexPWV1b58HX21zemTy4SmGzuZUiDEgRJgmWef4B86JNqjYJdfjrkmOh+wwIE35uWWGI5jOAsKlKkG+SrYNsSEcx6rMRnWGwxChWEA0n2Upaln0yQQ6x7YmIrEYkXKOatXW3nnoRaaPDhmQIs4hMYbEYjGy3/u9HLx5icO3zi6akTbIuYDbWnKHnv84pWyMpRdXyDyss0SfPTZouQabBVquMpgHIDSZMpzYegiF7Kf/PSBdLZGY2nUGAfROWwRAjhYNskwJkXVQt1NXFQwzvcCm5LAWIS0nADEloOW4xGFX1TAOkDnwPReOhwnRdlzFZc64w5skmJKgxyErjIiRisP8h34v8398l6Vf/B94g5sMSboERoyYSwSZ8IzxZlMO9WDXOWNMgqhDm1gCQWINHcrcdynDEGNiLLtqXcvtQJZYCPHOc7+Hte/8FvIRm49nNZiW14mGIbYO0TF0T2AyhnB1hVnzGFPCjFGjhBpbzwhxyjKREFQuV2jct15QMRfAxRhjUDXjpW+zR5o2h6zQJ+nW/5iSa6cwdjghk1nH2R3jCw2IMEKNZR16gTiZkikRx4MU00icbjzD42nAetfWWSQCk0lArFwkMoPccolIBIYNyCRsTXYntl4rWxVGIxuTcBiCIRDKMZlAZcOSUteuwcsva1/28++b+fgoMPowjh/4ASb/TYzzP/YO+/0yWRoAtChwSoXABTcx5zCOiZN0JfMREc6xplvW3MxYMSPitDCiaI4WxyyTpUWLHHFG9EmxEjni6g99imqsxXDvmL29MsNIksjHv43Q930Pa5EY/Z/5RfqucVydAlVOucwjB82IcZ/LQJilTJc6RjKeEGGfdWesDIJlctZ1Vjihi8lpjogRMKdAnbSrHsz/vX+f3qMj7lV/J5lXo4zWX+WkGfDovi3AbteCoELBfoJtHNOpOTS1vSENtijQoEyDJF0u84A2WQZEHQ8rRMNJb1Y4JYrJfuaw3ga3eIe6I95u8JgsXd7gFg/ZIutyijd5lxFxF171KdC4UFczjLIRGptYd2t7TgVKrkVcgSY9TOK6TZwjrqOmdwWaLhduPSQKnAOmjlSjRBSTgS66QCv9fb+D7voVNkPQyK/z+nydSAR6DuIVDsNwFFC+ZAYrYv3l6KXLTKN5EuMeD9niEZucUyGC9bsKHCyvQIMDVkjRI0+bCqcMSdNyuOgS545En6Hn4GETAqJXd0h84pM03t3laJBmlQNijLjsxC0OWKXCOWGmHABZrP3gyEHFQg6/P3J4+omD3JisuMEB1jh2sM88UxIkGNFzVa4p1uFhml4lki+QyUA+b3MlnbZsaL9v8ygcNkduPrfXGpMyLM/JHT8gQptNDrjGPbrJFUZXP81aoczhoSop5tRkMrC0ZBtBEMDZmb1WLsPKiv178AAaDUiloFAIGBaukizB9KsQw66jVLKNYzCASX6F6J0q016TTmKTeDpKOgwb/TGhZoZENU9slGP22n0izFjlgDhTekGJ+rVvZbC1Rmd2SPKdNxk6+GGDAjFGmFh2lL5Dlo9erxF5YZVkMrjYlIZDy9ylUnY9rZY5oOEwbG/DxoYbr0aMYHOLNlvMB5Cc2PsHAxubaNTGKR43Zzaft8Cj3/fJjVF/Shpr9CtJ+BR9crQZYD3k22Rchnfk1kPB8a+ylG6skVy5yrS6Qi4f0GxaAHdpOyCfX6Hdhm4UZh3vREci9gwFH8zl7B6rVbvGZhPabahWA4Lv/x6C//EfOw5TlBApt1YMalrYLhMsBeTzkF9aI7YKoRpknRPQbpvd2tmByEGU5Jt79Ii5SlGLOaDGml3HW5w4mE+IGWeOxWjiuqpomGLXwPGOYozJuWqR9Y4aUrm+RKywxn4nQ+LRHLotIpiCmQU+AdP1K6TXKkzPMswfvEvCQbB7JJiQYbZzjfn9I9d4M846+5ha2cglnpZZokV8e4N0zO51d9fmceTKxwj/By9x9KuPSXS6nI3ydIdhxvEO+VKM+dIqhf/uv2M+ilCkxpAEgBNHSNAnaQ5aOUsmYzZfAXU6bc8wGrVn1mzCyQlUKg5JMLZ13e8HdBOrLG9BugjNlv29UAyY5i4xX4HpF/bpvnsImEzxmCgJOpjI0exi7kUxNbA9NpkQ5TZvMyXEMVWm6QqJZJJkyq4pFLI5PpnY/M9mAyqVCufnfu6Xy3adjYYlIjIZe31pyebL2RkUd1bgchVqZ5TW1pin0iSvXWL89lv03nrEkBJJx5IaEb7Yb0alSzDbYnIClWyBETlabHDAqtuDk8QctC9OnyhTZrkQYRcQae2Gwza2/b6N/XBor1UqUM636O+f0SHlVOJM+c3m5pipQxjY/E6Sp8117jEmRp4G2+xxwAq7bDnIWtIlVLv0SHLAmoMTntGiQM314dvEOjn1iTtY8YwvXf9hSm8EDLNX2QtucjhdZYuHBFjTWlA3rQgZeqhf09SBbm0MZg6mLmRJiFZuh2HrhEO6FGmRZur24YFBhomQoUnIwT9n79zj6PDTxBPBBT+m1/OBZrdrz9yqngG5yjbTszcYEWPPqeNpXa1zQOR7fze9wi2Ggc3RLmPaJDCe4oiS4/1MwSEKrPVLmh4FmqjHYJruhVJizO3zabpMCGN8xiEtNy/GmIhJPhUinMxfJACjUc/7SaV84mxtzX6GQk8mCrXnWvXR7j0IDK4ci9nroZD9LZ+3OR8KmS1OJu093+zHR4HRh3S8c+374I9N4VcOuXs8ZxKK0R0GzO+97RRaAiKkXAndmrlFGfGQSwxIEUtlmN64Quo3fsmRyYvEGboskjWwe47X2eCALikG3/fDVP/1f5fqSmABRx3aX7DJmLttRjCTgvRWhhEnLis9ZIkzStR4yGXus02dAssckfnYKsPfeJ1a3/DwplAVIYz1UjFyXtIReXN0SbPGseMDGNE39slPMIknSV2/TPjOZfpXYf91u5ZKxRwWcTmqVVt8MtStFjx8CJxVKHKJDB1MVabN7+RnaZHhS7zsVFomLHHKNg+IuaJxixx7bJKnyZAYccZssUuIEE3ynFHimBW2eUg7XCI5a7LMCauccsAK6ndjUrRJzilx5pr+zZxDbxWZDGscMAdyNNzfA4extx4V1sHHzmYyskMm4RirsxqnZDAp2hnZ2JyV3/MdzG7dZty2Mcnl4K23zJgEgRmtoyP7ubNjRujszMZweTkgm32ORz/zFhlMG++MCn1Srn/MgMesE2Lqgr4xXXKOH9R2AgItq1pxyh6b1Cg5rHOU2sarBKcB2c9/lts/+be4zENmGNk25uqcIWo0KJCjicm2G4QyYM4qB8wJc8yKIyibA1mkzogYEWacUmE5M2TnziqvfXHAcB6/yOJDjN7SBpNYiaWKd0BkpMNhM879vv0tlfKZ0VAIisUKketFStMj1tLLtLOfpZ27RO2rAbGxjfHcihRUKmbYQyF7/c4dq67cusUFgXQ8hs1Ne+9oZM/n+BhOT+06wJwhbQbaVOLxgHa7RChdYhpAKgvhEVwNm2MYj28wurNK/e4p+ViOIJcmvbLG+NDgYbPiKtPbYbpvPKJBkaSDJzUouz4eUeKYDHF0UCcarVzcS6tlDu61a5bxm7pMcbVq9zEe2zWsrMDJ8ZTh6Qnh7oRwIsowU2U+D+h0bLw3Ny1QOT83hyuRsPtMp+2+Z+dzJkddRqSYESLBkCQDhlj/jygDJsQ5ZIUEA8obOYJCAda+hWZ0nUIxIJ/2cMZy2exFLGY2pOMCokLBvm9/35zRQsHe1+uZY1oo2HM9OzMK6HBo991Ze4HuZ1JMfrnuMs7GExiSY7yxSW51iY0NG5eVFVuL/b53hB4/trErFiH/w5/l6n/yJ/kir1LDmkB2XBV4SsSRzWOODzFygJ+YqwgO6ZMhjPW/s8q7NbbO0yRgTpoOM2KEX36Z4LJplUXOYLMIycQSD99sM55MCCIBudUcoVBggURmhcrvrJKf7DNsjwjmWShXmE8ge/+r7FHFevykmBGlRJM0A0LMSIfndLqQDQz+oiDz9BSWlgKGS1vkrkKhDdNzOOpAaAizR5B76TsIf/FLzsGdOBESa0A6JUqqkiWeCIhG7XkWzTcmkbDvUXUvl/NrrVbz1dzBwBIO6bStvenU5sLqql3jeAyV2+sEKyv0T+qEG2fEj08dJyXmAvUpM6IMSWJNUk0S35qkhlmphGneucnSkq0dsHkniG0mY9+TSNi1dBYC9GTSO5lBYE5mqeRtQaEA+/sB8e1lmqFlJhMI7U+Z/eRrnHAL6x5VcyqgGw61MIbaCaONbfr9gOPyJXKJDYaDsePlQMxBKgckjecamsNyjnDfrmU+t3+npx5eOhp5p3g2gyARd851lAhTNjjgzPWjCzseI87mR92ajjJ2vNqRQU2JsooJUe2xxpAiNUqoT1iHtFNsm2JiF9YAvU6BDD3XjL1Ac/Mq3S6cnwc0nv8WQl++T4gwMfoEzJw6YdNVY2KOzzXB5KlNhj/h+ExRRhRp0rv0IsE4x4Qp9VYdU7A0ZTdTiEs5hq1VbsrUSQ+/ysHxHmxtXwTx0ag9+/Nzq0wPBvZ6KASTbInO8i1yx/dIu8byPVJMwhmK3/5JziLXqe9BdH2d6sYKvcenTN9913GhGlhrh4YT+s6hpu8pl0bpkyFDmzERuqTprt0kO60zOz5k7uDXgEsAJF0FPAVMmQUxSiW7zvncV3tUZa9WbU40mzZXQyFLjGiNZbP2/8MhF/BXBVBg8z0cNnu9tGTrRZWoTMbPs2/m46PA6EM4Tk7g7l1YXQto3d7gNGyBSm9qTIkCLaxzedKZkBFd0sQwudcUbRLVCsNxjPn2LQoPTwziRoo2aVY5okCDY9aZAKX/67/FpX/lO+j3vWMIHjqjiTyZQPS554mV83TOp5RouKpGmAJ1jlhiTIxO7hLx525y40e7pP7K3+WIZaZESWMdvQOsc3T3W7+P4UGF0b1zt+Wb1n2YOelPPE/7M7+T+Mw2N7BrSFjykH7fjImyvJ2Oz0yAbXiNBvRGVc64wRy4w+ssccom++Rpc4N7nFBmk32SDk7wVZ4nwHrdmEMf401usc4+l3jEG9zhmAotctTXnuf8+u+l256S+fV/xFWsaWcZg4pZR44Y99kGTGUp5QrU1nvFGhfeY8up3bSdo5MgzREtspywTnvlNstXCxR7pyTmPRLVywyL60yHUD05Yj4YkC1FmVbXOcwHrEfMkFSrZlgULPb7tul3uzY+0ag901zO/l4oQDoS8DbLBC5IzbqAcoNjsljz1jlzNjgicHjmaDRMZTlG5vHrzAiRp0MU6y91izeJM6T5ye8lVo6RSsHaK7dYuvXdjP/6f0+8cYD1TMq6oLnHOWXSDjPfIsuACB0yRBIpEj/4vcQaPWKFFPX0FqnGPp2zPvHukNX1GeTyBJcvk8oGpK9PKZztk5h06AUZTsLrcBBwdmbzplYzw14u21jU62aEBXHq9bwx39iwcRqNAkrVdfKr69Tr0D6z95ye2liOx/a+cNicmF7PnMKVFYPybG6a8xWN2vw0WJ2JUT5+bNeQSBjJtNXykIG1NfvMYGCf29mxv5+f27NbXrbNQoHK0mpAu7dCgxXW1rwyntbR8KhDxPHqTDsq4/DzQ8KY4laWHq3OjHHSZ+/mcw+ZGQ7tnCsrtlmdn9s1BgFkj96i93NvMphY09eAKZlYmLPrnyK2tsXGho3P+bmdN5v1AQy4zPNnK5y/1aQxHTqEu7mhcYbUCIgRJkmdlSDMze9/nvbG80QiNo9XxxbIzGa2OY/HPvgE22ArFRtvBSty8rTRJ5M2nktL9rPZtPesrdnc2d2Fg9hVQq9MWQqdEZ/2SWSitFMrTGdetGI2e9IJDofhhRf8HDg9hUIhyeSlbS59eY8CdazV7DIxBlznXY4pOwtZpE+MIQnKnGJKiwbpsqbWCULkMGEcIQuGRFZWiX3rpwmFAvp9LyTR78NwGBAvFi6q7LGY2dTRyN6zsxPQ7V6CEeQc3PT49SNgSJU6UydhX6PAJR6zyYFBfmZVeo+OCK6sU63Cc8/Z3PuH/9Ce+3TqkzRKQIxdgqH84g7tCEy++AWakyRhwmRosxxqEbp8nW68fBFI5PM2xrmcd66Wl321d2PDBzvhsH1vqWTBfTjs7eJsBnt7/t6jUcgXAqKxCpOVCvOrO/R+6VeJ0ifNkDBjgxQxIE5A2CWuGtufIPv5V0hHk8wPfGIFbD+dTu2aYzEfqLXbtoaUXCmX7VpaLVtnqjAlk77ylEza2tvddRWzgwNGowEzrJfQW9zkhCojkqyzT8JxUUKDBk3KhMMB0U98G/Gf/0cXfJMoEzrksH5eU2I3rhDJBIQCW5uXLtncr9ftOlMpu69czq55NIJ2qMpKFJbH77pzDsnR4iFbNClgEugRx4C2nm5TImQ5R8pkJkDUJsaIM5ZoOhjpHGsL0CLHMSuY+ts5RepYzzHrj3WfK8YxHIYZnptP1clfInkngHdOGY3HqEHxSqRF9LmbdHPr9I4blKJtGrUpZwcDIHSRHJ2RJHLzDvHCMpF9GKeKkNkiODikSYEaZeL0GBN1CbsmG+zTJssBq6xEaxzPt5nPzaakUmb3ZUcnE5sHsvPzeJnY7QLRWQ1GQ9L5CPH1KqNSQKRnds44dAH1YIVOaM6Vd/42l9hjj03iLjlSp0CFc27yFo/Y4sxRAnK0mSaLDF+5w0nqCqnslNbf/RkmszEb7DElyhlVrJlthhMihAiTqOSIRn0ScDz262c2szmpwDkIPLTVknZ23wcH9nun4/c8JYmGQ3tPNmu/q8KqZKWqbN/Mx0eB0YdwnJ7aZFhbs9/BJlm5HDC/tkbo3dcICPMSX0M6/BCi6zbMLDNiKwVicYitrEDp00y+8nNMp2MmxMnSZpN9tnJ1Bn/qT9P7hAVFpZItttHIvv+ll3y5PBZzAVMyoP+v/TFm/+VfYJvHxBlyj8vEsKZgESZMf+gPEIkFhD71CVanYdI/8fc56XRouGzPMFEm+MyrRLeu0i5dJX51xPTBA0LTIrFyEm7fYr4cI5/0Jdh22xbS5qZ3JA8PzfGcTHz2YmvLjMrZmX0mFgtI39hg/vZbDgo2pE7JBSJ1AmZsckCdAkOSXGaXEaZudZE1w5pb3uUaYeZUgi6Hn/9DjArXiQZTsr/0PxEwpUmWKJOLhrAzwhdcoDJ1BlhPBFMJjHFKmRAzHnEJaw5pG1jj6mfpRIvEYzHiowr9gXlzy7dXqFTsOZ2d2X2mttcvKg/zuXcAEgkbr3Qarl834xSPm/Mdi3lndDr1nykUoP9Wx/ERDsjRIkuLKaaSVHIZukOWmBMiFY/w/L/53Uyv3WIyC0j+/b9N6x/+IgETF9x0eJWvUPveH6H4A7+LVMquZzCA0PJn6d/8FPMHb7IUOWBYrBBq16n/3/5r1jm84DQ0ydMjTY8kwbf/LqJb1whtwBhITCBWvcy0YM8/2LSgb9CAt+9CJhOweesSZ2dw+hiGNVeJmNkc7zqOWjJp/y+nX4IMcoxDIfvczo6Xa15bc981sM8oWxYK2f9Pp2b0x2NvyHd2bA2dnNjfplMz9Pm8Oc6Fgn32+nV7fto0BwPvyJ+d2XNcWdH8tuuOx+3ffG6OSxDYRiKnT4FRPg+12pSgdsxl7nFClS5pZqgfvAkNRxnQJEMoFqFateuPx30lbHXVc7IuX7bfk269Hv3i27T+t1+iRJsUCfI0OGeZ5KjH9tf+PpVv+R4G0R3abV9hEkdkNrOx3tiwLG/tE69y5Qt/jx5p6pQAiDOgT4IxEUrXtqh+7jaPegHzcxvDet3OWSh4Nbl228Zdz6xa9dW8ft82aiUJ8nn7jIKmVsued6Vi47rofDcaEI0GlMvL5HJ2H5m2jcventlPJSc0/isr8LGP2fk3N+05DwYw+7P/Hmv//l9h6Y3X2WcD6yqfokeSGstMiDF1PMkA6JFjyIQyZ8Q4c7ntGDjYb4EGJZrMCBgeDZg92iN3Z5tEwq67WrVxevzY7k18u1pN+43NxW7X5t3Kir2v14NqrEmXGsMLdbeAKifkaaP+QhEGnNamFJwwx9GRnzNnZ/b90ahfK+ArJP0+ZO/s0N3eonJ0yKXUOalqipPUDrN7AfNT+6wqQibo4blwy8ve0YpG4Y03fCAyHNq9iTuWTvskw/37do+zmdnZft/+zeeQGZ8zwPT4ck5/cI8NJq6CaQmvGIP1l6GXvEjaqQqwvGzfqQppOm3XWqvZGCh7LrGPSMSuczLxAbvgqODtxsaG/Rt94ZDHPCbGmHNK7LPCkBRZOg7CZr2DcuEOzVjZeIKr19n+wRHJf/BzvDFMYA2CTVI/dmWLTnKFmKucplIejri+btc0HPpkRhAI9heQTT7H9s/9v0jS5x2uUKRFiF0OGBHCmigMXGX0RV5nRIQOaSKOSVvmnChDdrnEmAg5J5AwJsYJFQIHUU+5Vg6mMpflEgeEmFCjaBXX5hiann8cubROfeUHSPWOSDcnhMJpEltFwpGAeB/iW2UKxTLpMcx2p/ROW4QjZSr5gHG2ymAUUHcJtdkMuoklatc+Sfjd14kxYEoamFHlhCgz6pQ4ZBmYE+QzHB/7QFm2fTCw3zVPBMVOJKDZChjEq+QLDvLZtDkBNnc09tMpcGmV8cb3Ufy1v8qgdUqeNjd5ixFRTlhiszIm/Xt+lF98sE5o1KFTShG7tM5aIiDdtP1y99Ur1L/4BkOs79sSxwTMecg6DUqkLy2RzRqqSGqd+jcaGeJhNDJbsrFh93F+bteqqqjsbKFgv2ezHspeKtlalJLrcGjrZnvb5nu9bnNR9/3NenwUGP02H1osMta1mg9OZjOIZ1aJLnVJnzykRN1xLiLk6NIgS4gYqeevM88bsTyfh/DGJbrb/wqx+gHJ2j7VzTy5z/5rzL7zRS6tBxwd+e9Wxnl52Rye/X1zKJQhbrUg9bFPsfp/H1L8K/8x9WPD6k6IkiymCf/+30f7+svUambYkx9/ldj1l+GLu/QeT0jlY0RXNgjiATEH7YrlYkQ+duNiwksWWCTsdNpvIsmkGY9KxZyVycQWy2xm59LGmkz6zW95eZ1IfJP2Vx85xG+MBnkXGE0ZE3lCAVCZM+t3EmaNY/ZZpUWeW7xJa5pjjjk1G/27nI/foEeSOGNyWAAYwZowjoiRo+3kTI0vc0YFa5bW55wCpxRNRCOaJvvp58lsXmHunMZsDaaubKzgTxyVRsMMkRTQYjEbC9cf+MLAVipmkAThOjz0zs9g4J36XA5SG0nK1MnRckpUY1ouOLFeQ0YGDzOl/UN/kOvf+hyRiM2Rx5/6IXJbzzH82v9OtzMnuH2Jxue/m/3DGK3XLTAQzPH01AL90HPPcRx7Dtx4VsMhEn/xP6N08pAZJ7TJECp9mhd+8FsZ3Llxgb1vGf2L0chXv05PzYnLZu2eymVbO3fvmmOcTJpRnc1sDLJZm0MSDUgkbPNPJm08olH7/1TK/iboQ7Hoq0t6b9Z689Ht2piL56bzqVLR73v+yuamvbdWs3vKZODRI+/QZVJToo/uke00CeXyJDeusLoacOOGPcu9PfvZaj0JMRDcJZ83p3w0MudXSYTi7IQxNUaOUFtycvlTQjSdAmGDEmXaXLqev3Dsp1O752bTxkyBgaotwyE0G1PC//hnWaLBGTnmRIhjPaCGxFnimLUv/W3e+f4/yclJQKFgm2E4bHM5FvMVzPEYKi9dprTyndT+wRdojwfsscGABLnQgM1PX6GevcKXv2rXl8v57Pnlyz7AbLWMy5VIWMY7Hrfr1TxaWrJnoOpeOGyvdzr2e6Nh62152Z5hu22BYTJpDn6tZusol7Prj0Y9PDWRgFdeMQglqDpk75XtunTJvqNWg9Af+aO0jvt0/5cvMj4dM4wXOVi7zeFhjHmvSyI8olAIESkWmJ6e0H506mCGU4qcEmVCngYhIO6I7HEmdEmT/srPUvnOHyWVNr5Vt+vnZ7PpK55aPwrGFVh3On79TsPWFytHgzxNZkRZcRWse1ym7ZpVDkkwHNqzteqUd6YnE5uno5GNm+ZSEPjgPhoNuPzyBrH0BpUV6O/5SkXaSanL3o3HvhIj5zOTsQBMa+TRI19JErwYzHnTGhJfIhy2OTEc2vP+RLDL21/8CvtsEnWiN2HmtF0riB5Z40M2x0yKT35/u23j3evZfcZiHuqcz9t6PzqyNa2K/vKy/a5MfLHoE0vg52Oh4FAd5SwZBlR4i9e4xR4bTkK877itCbJ06YaTNBqeCxJsPcf8/3KL0N1Tcv0RnU6WXpAjlAwITZxQSsqvy1jMB9LiVSrY1h7VX75K4g/8y6z9g7/Kl5tJIMRt3qJFiRPyxB2ioEiDNmm22eOcIlGG3OA+j+lxn6tAyAkDBA5mF9CmRIkGReqObRdwTokTp6KYpU2LjOMQpYkMfAV4ddUSLieTdVJbkJ3DwZF30Le3fVX39DRgkCuSXS9ecJjbXZ+IkgjAMFUhShJrKDwmzcA1Yh7SJMOQBOlMlOH6Faav23OWzZRqouZcIuGTa+GwD+bX1rhA9CjYns18YkF7TXjpKvMf+HNkv3qP+PiMafSQ8mqK3nyD5nO3iXcDVp2ADth9zGb+3OHtKwT9GOO3/gnL40cOJZKgHKnS3S7TSa5crA1xNhUIFQp2DY8e2TxNJHzApMBfSdmlJbuGvT3vuykRqTm+v+8DoPHYV5ZKpW/Eo/4/5vgoMPptPlQuz2bhl37JNthCwYxit2vvGW5cZXkzQv/Lh0ynJrG7zS7TbBle+hfg0iVSKXt/o6GsZ0Astsn6rU1yv/dTFNah4zaqUskbfxErNSHlCJ67bGyv53CiNz9H6F/6OeI//6tc/ZXfIB6e8WDjM3TWXiAy9aXRTgdOawF7XCZ+BUou060yqxFhxeHwML7JxGPH83mrBM3nHlKgTbRctp/7+3ZeObj9vn2uVHJO7e1LTL8a4ohlKk4iO8ScZU4cfCDNGSVijEjRd501BuyzzkO2nOqbweOOWSb5cz9N/JUr9HZ7LtseoU/AKQVXYZlciDe0yF3Aw84p0SMBzgl9wDa1y5+GpSrFq8t0hwGdc+8YKos0ndrzXF83Jy2dtmeWTtsYnJ9b1jsSMaew3TYnTFne2cz+P5+3z5yf20aXSHAhS3xyArPCNZYTP8VoEGefdQJmjs9hm1KNEiOiLP/Y7yX0iRc4P7fPd37lK6T+7v+HbPcRPcIMSJHafZt5fpXEzsfZ34df/3X77tVVLnoSpFJ2XfO5bUq5f+/z1P7Vz9H+uV9jenxKM7ZK6c5L3HYB/Dvv+Ayr5kMm47J3rgKkys1o5OFZKufX6x7upiyUnJ+bN22jV8VNstSZjJ2n1YLbt82ov/66natm4j6srNjP/X37KRWu5WU7b7ls2ejVVXseIvEnkzYmDx+a86hNL/brX2D1//3f0mhMGTgycfnvDCn++I+S/+R3UKvZtaufgypEnY452o8e2fdeuWL399prdv6DA1hNtjilz4nrXVGmxogocQaUqXPIEgOSpMpphsPAkiEpLz6gexCUZ2/Pxi8ahcHdPei1XEuBMjd4h5f4Kj0S7LHBfa5S642YHh2ytLTBeGzPTRueArDh0J7R889Ds/k8jZXblB88ZmnQJVOOM1nb5vQs4PRt79QUi/b8Dw7sOeTzNiZy8F991eZJs2nflc3Cl79s83511X4eH9vrCiIFV1EgXqnY94gnoAAxk7H7aLV8Vl2CFDs7dn+9njk4qgYqIzoa+Wp9qwV37ybpv/o58lGI9eH8rl13KJnj0lU/N8fxVaL9NqOTGAla3OFNWuTokiJFlx4Z0nQImLDBHqlhj1zjLvlrN3j+efi1X7Nn9uKLNiZvvmnXWC57CGkuZ+M2HHqYz2QCqUsrxONzpsMJI6zx5gkVMvTouf4lhciQYK1Mo+F7jpydeU5fOm2vnZ97joqCHsHKajV7Lmtrzs50fBVQxO1ezwc5gnyWSva7YGraK05P7XclicJhmy/jsWW4IxEPwSwUfMUmFoN5qshlHjIgSY+US6SFSdJzoschEoyYpmIXzq4y44K6HhzYOdNpnxjp9Wx8bt70fNkbN2wu3Ltnz2YwsLGIRm3NyR5VKvYdtRo0C9dJZ2IUOgcUaZBgyIgYYcIksN5fsQA6iTKjjreZh4emIpYqr1CtQPMujOo+cFtf9/tuPG42ZXPTnlGpZBxW7engA6dg+yXuX/tLZL/4mHyozuHwX4B/9IA0XXBJtzmwx+aFquqUCO+yw4wQTdfbsECNGWHSdDmigjWxbVOmToscVU7pkaRNlj02yNOiQANiGSbXqgxHNsaqXMi+SxRHiYBKxXM6Ox341KdsbNptvw/LB+r1fECTSASErm4zv/s2HVK0KPI2N11/xixZOsS+93uYTIOLQKbRsOtRxV8BvuyKEgSa10J8tFoe4i3FxcHA7KZQDt1eQOal62xuX6fg/MbZGRfB8I0bZh+1ppVUnU5tbpXLm8w+vUb74QHtfo9JPE360ior9YCHD20+Doe+op5K2XrO5TwaQoklietkMn7uKsGdzdo5JKoAvvKrim00ap8/OjJ/Qfbzm/34KDD6bT60IJRNE2E+nX4S9jRc3ab5uzaZHJ+yFGvSu/qdzLaukDwIOD728Adl/lRJicfNOCvqVpZCAc/TTbOUrSiXfWMtEd/C/+D/x+F/8l9QOn7kyPNZDiov0P3X/13GH/8WOh1zNFRxAs9DmM8FQ7FrmU5tASgzK86HJI7X1mxBalGOxx5qOBqZUZjPbQEp87+1ZYuu3YbOMEyBAX0nGy5BATVC7LqNztSgQgyJEWXCNrvcY9s1dO1ywIqV/CdtTn/61zhfX6UEDs8fpk0OmBNxoupJBoxMTJUmGc4o0SFFlDl94hAkKH7qOY5OgosKobLUcugzGe+8t1o2pum0GaWdHe+syMFKp80o1WrGZZjPfWPOe/f8eNVq3pHr922DW10NqHzHd7P7U19w198z2JxrEpelzdKPfh+Z7/jExfOcf+VLbPwP/zkrHDEkzkO2aJOj35ww/Wt/l8jvi1PeeoHdXfuu1VVPJI5GvYMk+MDaZsDwhz9pTvKeGVDBXpTNu3vXrl3VMskqK8gXl0DOXbfrsfmDgV2DFOPAN2BdWfFO2nRq464M7tWrHi6mfjarqz64mk7NuRIhdXXVZ7Z7PfteOUNrazZ2cig0pwsFqP3yG6T/3t8kzpgs1s09TY+V+kOq//EfYpD9awyu/w7SaZ98ODqCd9/1NqPXs/ERbGFpye4zlYJ8OUTiF3cZEWdI3DUTDZFkSoYWA+IGZEmvkgt5gZOecct56SXvMJZKtskeHdmcCve6dEhwzDIBc4o06Dhp4+s8wJpPL7OZbpC8s0Eo5KslUqeT07u15QOwpaWAs7OtCw7MwQEcn9j9bGx4pyyft/sX1HZpya5zfd1zEZWdXF21Z/bWW155bnfXAj1V3CTTPRhYkLOy4nlo1apdx+GhPU+w8zSbfg6trdl7Ox3vuJyewle+4sU9VK3N5ex9ChBmM2+zBXHu9XyWN5WC2Uae+skRGbqk6TAg5hz1sZP3LlHllDEBdQpw0mMj6zO8Jyf27MTVSSbNFqiaMBzaM7hzx+ZXIuG4iOmA+Xd/is7f+wItskSYkqBP2LpgERDi/OonqaSDiyBzMTOsYOD6dVu7e3s2fkreFIs2xw4O7Jns79v1HBzYeKnqI6ECwegKBV8FDof9Wl1f9+dW8kE8p07Hk7vbbbO34gK1Wh7mc5i8QjK5wk7/gWvhUCZHF7BGvHG6BPEUqZeWL+xUpWLnPT72FcpSyUML83lPXNd8vXPHQ4qyWb8XKkmTy9lrmgvK/s9DAYU/8LuI/tW/SNo1Ja+TdwmPGqdUaG2/QiQaXFT+Frl1Ep/RXBQvUpW2ft9+//jHbZxCIRvXWs2SPpcve6iU2hKcngeMV7agssX01x9zlTeJMOSYJeqUOGGZIRECRlznLmn6dJzUdY4GTfKOhRRnTgjrPThxLUDyjqM0I8GQMmcOdtdhSojd538XdIMLRICqDtGoBQfHxzaGN254my1Is4LXfN7uTYksVTulFJhMOv+puAo7YSoPvkJjnuCAFc4o0Q5XyL1ylch4i+hdD1Gdzz26Q3NYPeLAV4LAQ6TX1vzvglUfHnpkw3hs16kkkbitQpWoAvX2257rk8t5rmsi4WkcjUbANNgkcNUdQac1BkIwSXlVPma3a9d2cGC2Rf5HJGJzOpWy611b8zzATsfOKxRHJOJh/pmMJccyGd/y4p+H46PA6Lf50MRvNGxCvPOO3zjEI4jHbaPOZgNmSytUb63QC6B16jNmR0e2SERWCwKvFtXrmaG7fNkbw/HY47wXK0Y6tJClLhL8zE8T+WN/nB5ZMphXkqPN/Ow1Hv25P03zj/1Z2tc/cQHXEBRDWRZBBHI5vxjKZVtUk4nfrG7d8tevjOrxsd8cBH/Y3vbOqjKG5bKHScVGHSdbHqFHiiINNnlMgqHrZzAmwoQDVgkzcwKdJg9sIgRdMg6iYkTPMunXv8jsM/8GR/EdusMQyxyxxe5Fv5WBk5ZVo903ucE5FULMiDPkiDUi3/otTGYB3e6TSj8KJFXxqFTMMe907NldufKk0pM4LNrgl5bMAL71lp3v/NzGcX/fczrkkCaT3vAMh7CfusXoYykKX/1FBuPpRa+YvcQtdn7wFe78yEuuVwHMp1Pyf/bPs8GXCTPjMesUaHKfLQakucwDhn//H9D90Tu0WtYr5t137X5CIa/SVCo9ufHI+VskbyYS5iwXi7Zhf+ELZkylHCYnWlATVcI0B7S+olFfiazVPIRIEqOqSIVC9t5Wy+bhd383/MIv2EbZaNh79N2np7bmxMEZDDyxeji06y0WfTPZTsfLXytT2O0C8ympf/R33Qyc0iJNmzQQulAKmv+5P8eNn/88jXbA+bmdS3DbzU271lYLvvY1u66NDS+e8tJLcH52hVQiTmIwJsycETHKnJGmz2PWiTJmiQaD0p0Lu6Es3tYWF5wjOWQrKx4uNEymmBKlQJOoE8K1RoABTfKEnCxseTVOJGe2KJ/3Fb71dXuGuZy3BcoyCmorDqHgkuImKbhU1Wl3196v6rHkwKWwl0rZ51WNl5iLuBvZrFeQOzqyv29t+XkkJ1awmunUO5XdrncaJC87HNr6e/DAnpdgfcpmL4pRnJ152zyfezWyft9+lyR1eNpjTp0kHR5ymR5JYkyIMSBJnyYReiTokqVHnCCcB+xZKSMtAr3GUBwywRqbTf9MRJaORmH56i0K3xVi+rNfITs+I8rIbFo0ZuI5oVX29+0ZLt5LtWrrTP+fy9l3Hx35Km2/b9eo+bF4z5p/4um12zZHUylvC+VASUyoVLK9VGpg5bL9U4Y7mfQ9UpSoUaZbUKDJNODRx3+QlZ//HylSI8yUAjHmhOiTJE+dxHd9P6XLpv7YbHqRAgWb2aw/r8bSAk2f6AoCe71e98G1koKbm2b7VT1TomBtzarO05WP0/vX/ziRn/h51rv7rhdOkoPwFt1LN5ikVgiGvp2FhCYEwT07s2tZW3sSupdMml3RugiFPI83GvXOsaCoSnRubVkl8uAAZp0+xywTYkKYMFKXS9BljQOu8YAJAV3S3GWHHe6zwT4tsqxzlxMqNMiC6xtVJ0OWFp2gRHZ6Rs41+d6PXiX2yRcZprfo1b3/ooqLOFza9xRYqDq8tWX3eHBgr9+44RMoUpCbzWxsJhNvx3Ory1Q/+Z0kHx5zdrrDOJQkuVIgVAouhEX6fV+RbrVsbrfbvo2GEnK65lTKj632uHrdbPrZmT3zCz6SSxprXz86cjzkhYqO1l+l4pU3azX7nHwAwU4nE3td6JKdHS6qv0FgSVYlK1dWPJ9WSXyp0q2t+arb8bElQ5aW7P+VgFCyYpFrJb7v6amd5+zM1uw3O78IPgqMPpRDqlYKUFQq7/WeVK4RrlQ47enUQ3OUKRsMPFRFGdAgsEWztmaL7OFDn7ESpEUkf0Gt9vc992k2njL6s/+p66NRIEmfHB0GxKlTJM6Ylb/1XxL6r/4WkYh5+OOx17xXJiAUsmu6fdvr1K+s+PtaX7cFdHDgSXdLS94p0qZ365YZ5N1dv5gzGb/gBwPIl1MOE9+kSJ2rPCDvHM2Za8AaZkqNguuV0mRKhMesMiXserwkyNHlhBKnVEiP+0RP9zm+9TkSX/4lijQYknD9PCYUaDIgzglLTu4SjqgSZk6dPL3VG1Ty10kHT0LKpDgUDnvc7o0bPhOaSlnQ/PChJzTLgMohEB9EqlfNps+mDwa+elIo2GarQPNXfsXxuC5vEb6zQaW7y1r0jHE6T3TpCpmNgFTKDB3ApfPfoFc7pOUgA30S1Mm5HloBe2ww7YSZ7j4mkdi6UIJ78MAMtCo34q4synCqeiqlqsX1cf26z6iCD5iF21Y2XplCOSZy9pQFlvqUkgJ373pnXGtFz+DoyH7u7Nj1i8N1euorsNpkdV/Vqv3b3PRZ70bDOD/KKg8G5qCNRlCs3We1+zZJhnTI0CMJREjRpUSNJgXSR3eJfeVXWPnMZyg6Qq6cGWUNT0/tWppN1/ekaN+zu2vcrsrv+Rba/+MvMCDJwLUnjtIgS48Z0Lr2ApUl4zPJYZdtUGV3OLQxkYR1oQDhS5e4+7/OiA/aLHMEhBkTcVlerLFvckby9g6ZnK/GCPI2n9u579yx8Ts58fKvsolaG6qaLD5rQTt1KLOpasDZmdkK2aNWy8Zmc9MC3qUl38RWCnunp2Z/vvQlc0gk897tWrJiY8Peo8raaGTzI5czJ0sO1N27PlsrSJ7mT7frkxzilUpURhUR8Hj+9XUbr9Y0TOErR1SoEXEqaXWKtMg5CfYibfLEGbIVr1F+aYvdXc8tEoRPHBFVYGU/5MCPx+aQVyqWpNvbs/stvnqT9W+5RvTxXc73e5y3q4zzq3QJmLr7kvS0lAeVmBgMLFgRV+vRI99HKh63Z1mr2fjJWZXynKCWgu+oGqfeMIv/mk0vd63Eo5J01arvXyZBCkFGtZ9KASsUgsufu0J683sJ/73/hUTnjFX2KdLiN9KfpfFt/yIRx4PUnlwo+KSMYEHDodluVRv0bGVvul2flBGnNghs7JW8ku1aXvbqmtmsC6hf/hj5qy+x+eVHhPYmNKZZOvElgm7AeOCFWOQTxGIeHiaodSTiYdidjo3LCy886UDP5+YzCIK1vOwr9vW6DzpU8SJmUkZRplQ5o4d5uENStMnRJsMKp+TT8Fo3zJvcYoPHDF0FOkmfdQ5cw/cMCfqUqbMS61L6A99D780Qg0aRweUyJALCXRtL2Q5xQjc2bD4KRheNmkKhApaVFb8X3bnDRY8p7S/ao9VaoNfz9ggCguU1e44tKKdszquBuFAIkp7OZm3M1aJBCad43Oa05kexaH+7ft0Hw5Kal0qgKqOyb1/9qtm1S5c8dwd8gK72C0JFCGKofdL6bHkfajSycylQlmCN1pmCT4nTKKm0mBwoFLy66Y0bds4vfMGrq0rZMBx+8l4aDS9W81Fg9H/SQ6X8w0NzpmYzYe1tcSpDVqlYpUSwh8HANqx63TYLQYn6fQ/5aTZt4il70mj4KoV6KNTrNuH7fV8q12Ko1aDzC19hdjwnTIImOR5xied5gwb5C5GBk7MejS++S7Z0k0zGPi88vuAD3a6db3/fHAzxQ6T8pOtIpbw8t6ohgpaVy7ZYkkmTg+12jcuirEk47Dgtly8z+F+SRNtnTIhd9JwACDNjSIwiTQq0OGKJpuv6naVDnTwR5mywTwBMgV3WeZcdJm+ECS5dIpoc8/DXZ8xGQ1Y5IEuXw8oL9L/9d9H/314j0TyhQpMKNY5ZJ/TCywxjWxdVPVW/BH+SU6I+N7mcjeH16z5DJNiLMjTagI046oPaSMTzee7eNQekVLIxVG8VGe10etH5CLj2qctUq5c5PYVq1MZX0ujDIXQP6pxSoUGeIg1OKXPEKgETQkzpkSHCnFlnSJDy/IxGw2eAGg0uYGGLMpzxuMchL2bdpVJ4fu55KamUrxioYZxgoHt7trFLlENGX86+1MvAw9mUkZ5MDPsvcYBSyXPhmk3fSyud9lK2CvQuXbJNWJjrQsE2k3b7yYZ44o+FwxDpN0kwNMl6OqxxSJQRIUKEmDMlIMrYFjh23kePfOVVsDo1PVa1UNUtEeHPV18i9l1Jov/4F1ke7F6oCI5iY3rPfZLy+irPPeeb9Im3JQ5kLuerXQcH9iyNKBxw+NL3EvsnP8cqh0wJuW4lxpMq0qL9vb+XIBpc8CwWyfMHBzZu29v2PYIaaj0owJeEv4QmtOmrX02/b8+lUDAbdveu67Re8bYHPJRXfANVJrTeNLeU6X/82MOSi0UfENdqNs6C66gSogak87mv6qmqL2iKHOJOx+aqKk8HBz4YUCCn+ZJM2ji1CxtMfqFNpbdPlDFHLDNxEMkTVumRdG2W+8w+9+1MpgGpwDsxmhNa03LoVeUUv1Hw5J0dLxWvylcmE9CJ3SBcglVX/RIHVNUZBUeC2mi9qSqhsdecFuwmm7XvODrioneKHHrBjgQvV6BXrfoKiNQEr161sVZCTTLYmYzd39mZ/VOAqqaVqjpev27PAyDx8ZcYPv884XfvEYkdE2xkCfWfZ1oz2Faj4RES6vkD3plW9VJS8v2+XXOxaNeQStm60N49mXjEhypb4BNEjx7BF79o1yoIdrkcUP34DqnbNjdPT22f1b4hIZlFZ/T42MM6tQ+nUj6IffDA7Nnqqn3/zo5dyxtv2BhfuWJjeu+erblYzP5/Z8dBCcPL5CNjZpOxk0jIUeKMPhmOWWHAu8RKWWo/9EdY+ms/zTFLhJhTpMaEgB4pYkwZEpCnwVUess5j5v2AWj9Ke+UKcYcuEHQ6ErFnreq2qviJhM0t9ZATT1WQYcmnK/EmHlKrZeP14IHnIYonqDU8mfiAVvQDJduiUS9Y8fLL9r563X+nxBeU7NSh1wQ/7XSMHxmPm0+1tOQTowpwUym7P7D3P35s71ls1KveceIbKXEqey9VTknjb235Cuvysp+vi+IlQlNUKl5iG+zcL79sa3R93eaFqtS9niFJej1PkxBccVFZVE2Pv9mPjwKjD+GQk/P662Ywy2WbpCsrNlGUIbt+3XNFtLkp4yhIhGRrBTmREyaynYi8UkgS0TgWswVyeGh/V2PQ4RBSzVMitJkQIUmPA1ZI0mNMjDRdzqhQo0iVE8aFmzSbZlAfP/ald/DqVnLgj4/NeGtRDId2rSJR93q2EBdx8bGYnVNGbnvb3vvwoRcXmM1gPA1Y/swNrv30TxF3HZ4LThxBR4wRFWpUOWPgslltsswIMSHCJR4zIEmEMUucmlxoOUI4C6P4FZL/8jbV/i6xYYvuWpx3PnGN81pA77kpicN7xHsNipMy+51tgklAcWL3pA1UAZDUffJ5MyDptN2jHAMZqs1NG8Nez8bk4UPf6FZZQcFIwmFPLpcqnHq0SABDCjgKUGWQwPeu0XOLxWxuPLh3mSbfxpQw2zxiSsAhSwTAhBA52gTMGOZiF3OvUPAS2croHh9bBunpbJACn91dD40bjexeBTuaTs1gK0hptz3MRhu2KlyNhofoLDajE4F7ddXGQ4RYOWGTiX1eQascrmbTV33Aq9cpE398bP/E07t/3963vu6ffbvtZYdn5LHYMESUyUWT4AQD4oycimKUmCMNKWmxvOz5EnK0FlWiIhG71mrV7i+VgunaDdqvXqXz1h65dpdIPkmxvEXQDsjlfEC4v+/HI5Px1TRVqZXt3Nqysaq+cplWZMrhr0F18JAcbfK0iZey9H73v0b06gsX9kXqRNqAr1+3eS2+yGJgrMarzabnHz1+bGMnOIaEDwTh1X0Ly7+97TO27bbNjY0NqwbJ8RDkQ86D5r+qCWtrvrKiQ8+337fgxuTGvY1T5nTRQVNbBNkoI8H7fj6CkyowktRvNmufsWRWwPgHvpPcf/9fMyJGmg7vcoUxUYo0iNMnzZTlz79E8ta1i4qJIGXXr9t4PHjg15YU00olu35V+QWpVICZTJqAg15XZVcBk8jeSrzp2lMuiy4hD8EaRcqW3VYQFI97UZNr1zyUT1w9JTnUH0hJm+HQO/JSfxMvUNVeXd+v/qpPREngQRlzVRBV6TOYUUDoxnW+tH+d/BA6PZsj5+dmmwR5VCJSlc5i0cOKslmzA+ozJ3jhos2VjVRAJcXDdNpXb2s1+31jw1c433nHzqEkwvXrVq3U8221XCPRBbumSrrmh5oiKwnxla94m6LnPZ1aAK1K1uGh7c1SsDPIv2xoQPTlF+n96m8Qdg2kU/SZEXWKbnD+Q/8G4+dfZe1HA+Z/55dY6x0wIUaVc7okOKPIEWskGVCgwdhBGdOj5kW1Q0Gkqodaw5pPcvhVsR+NbEwbDb8uz858A2oFutq/JFagQGJRLEFzqlr1MLtFfrcq0YOBUwgt2r6s1guqKuoapawrPtl4bHvh7q59ZmnJB4ESAxKHVgIzqjZKWGYxwaSEo8ZJ9yrFRyVjFmXFBTusVu2cixQJVcdiMY+YSCa9sqUq4WtrftwkxDCZmO0Qvwu8iI04nU9LxH+zHh8FRh/CMRx6jfp22yb1dGpGR8oqGxt+gapnhnDwcrLlyIi8K1njWs0ci50dy6SKlCdj1+uZcb9zxya0YHvC37NiadIoE1Y5pk2GJll6ZOiRoEmeKqdkr2QYOKiPNsVWyzJMgihJeEFGSfwaZT60AJQNbDRs4bTbXva4XreNU9nJ1VVfLhZfZXN9ysqf/6vkeMyIKG2yDKkRZ8SMMFk6BMxokiNFjywd1z+kSIm6k6uGJc5I0aNIkyupc7LfucLZmS3qnZ2AZPIye3twModySGTsgI2r14mkoP8ujGo+k6VeF8WiV0tT5lQZE0GBtrY83ndz096zumpcEsndnp6aAbFu397wT6f23MU5U5dt9cgRoTKV8gRcZbc6nSdlvYdDO8f9+3BveJlEbJnZqEeNEjkaRJg5CGKEJPcZJopMypuE2l6SU9AnVbRUfn/WIWiSqqDgOXH7+8ab0dwWd+3tt72hvn3bPru3Z/Nja8tnTaNRy7hKMlmEW805yWFLLl7Ee5Gf19Z8skLBkIz56amdc2vL4J6CJGlui/gsh/v4GI5GO2wWSpQadxkQ54BV4gy5xrskGVgFc+UWsU9+8olnpt8VwIhTJOVCSbl3Ovad5bKqwAGT+fbFxn1y4p1JOWarqxZASEBAwYeye/O5BVE7Ox6ysl+8ysGVywTz+ywVD4hVC3S2noPTgLRL8uj8i/j6jQ3fo0mKmaoWS8L47MzG9mMf81h2PafTU5vnKytWQa5W7f+zWR/wKiGkZq1yUKNRWzPCzV+Q2ufekZE61LM25kVenDLQjx7ZHG02bWxVsZRDpfcrCaRmpHfv+ky+HGvx1yQkIaWzk9jLDOL/Nvf/1j/hvB9wRokMfaKhMEu3Nki++gJLGwGNhs/2lsueS6Vqhea95pKezcaGhyQtqkGKv6fgTWRw8eskAyyRnXzey38ryC0W7X6EXrjg80y8apoc8PNzW0uCxgo5IdspnpGCYsEVFcSVSl5JS4keOXKZjHFuVVGU/Lrms4Ix9S0TPFKVn/HYnoeaNCu4VbZcia5FuW7wqpaDgdkIVSUFbzw95aJxs5xlBXmVildj3dnx81DOcKPhE1/7+x5pcXZmvoL2WknLKwEpAYpr1zzPr9ez75hMrCKkRJAquQcH9k9QMQXeEsEIAgeTr25RzI7J/PJPczJo0iZHhRPGkQLn3/WHGFRvkenAYPsVsn/yRVKv/wyVv/OXWOKENmkmRCnxJl2yJOhzsW2spKgG3r4NBh6yH4k4KfyQ5y8rgTQY2BgLRivhFgkjKBEiuPDenr8/9c8S9y6f91BEHZGI3y+kICeenKCIOgf4pJaSDVK8PD31geo779izXV/3CRP5geI2CjXR6fhAIhSyZ3fjhufsaL4IHi8IrdahZLf39jyKp1Cw7y8UbD1KuU+VMdE9pAAqnu3Skr1Pe+b9+75fnCrMsj36fK1mvwvWKcTIN/vxUWD0IRyCq1y/7jOeKqlrA5PU63jse2kEgU2+RXlnQRbEQ1A5VWVvVRQWeyWFQrYJSVZZWHzBQnj5FVhapn3SZZ9l9tkgxgSYuy73M0rVGInPvEjh0GcIFzsaawNS9kqEXPDZYkH/gsAWlOS4k0n7/OGhJ++LTPrwoWVTBHMRHjf2xpeJHe8CEGVMjxQzl5sPM7uQ6O6SokOGPknG3/Y7SP/8l6hyyhnliz4QMwKiTKj8i5+jPQouHAOpXsnhU/ZJkD91tgZvPCSEoAABXA+bjO9TMJvZ+Eht7do1P1cU9KqSoey9YCHC3ssJkxKNnMB22869svKk2tNgYI6CnJazM3v9zh0P8zk/h2g8YPjKp0j+k5/hlCpjomRoUyTOIZs8ZJvMS68Q9IILsrc4cPv7FrSo3C4DqjWgzN3RkRfoEHxBkstnZ1aCl2KcsPfiQyjbpUyyGhWKZC0pYCmSnZ15iM1k4uEzyjan0zbGIm2fnfkATHwQ9Zyo1228FjOq4jMoY6sNVtnEcjVg/q/8KN2/9J8RZsYqh7TJmC5TaExpXqf/H/9J6q3gAn6UStm1KzunJqaC/62tedjEyYnnvtTrfp5Opx62JVuSSHgIrtTjpMp3emprTTwHwTjEgUulYONSQDJzjUb5mkFFU/ZcBN2oVLwalJxTKVLK4RSfplbzG3ehYN/32c/Ct32bYdTfeccrNL3wggVqys6KSzkee6l7SRFfueKDlXzeV3mE6ZdDI7K+xvW9DjmBItZLXU+O/sGBr2CpNcIilHJtzSuodbu+siAFJ3ECpYCoRNNg+eMM/+ArxB4+Jn8yZRhOMsosMU0HJMPewYlE7PyqjOhecjl71oL2ShZXPIzFSpPkryW/m0waukFNSxchvhJPUVVIjo32E80Hjb8gh4viEHIkpWaqSpsCpGjUV/7W1p6EFiv5pmqPJNXPznz1RPN+a8tLrD96ZHNBgZkQG4tS8nISVRmWk7u56RNfktAX3E9BuYJjNUu9ds3uATwvWNn9aNRX2ZUgqFa56B+nhp+Lc1D322r54KVU8nNod9c+q2qOxvnoyM794oseqSB580SCC36aqqONhkG6lHRTbyXZHVVOZZeCAGbbV+levszg7WNGrTHjaAzKS0x3gguYl/klAYUf/E4yP/vXGZ/HCZiTpcNN3uSADSfxDeFinti3XaN71wcCCubkY6hvmCpgg4Fdl2yEoNFScxsOLRn34osesSNY2uPHdm8vvGABg+5d/pgCcFW6tXeJ7iCxqETCvkOBtkRDNO8XfcHlZd8XSAlAwaIlOKLnrKSLhF1OTz0/SgHfouy1Eu3a+yXMEARPqrwOhz65Ix8zlfIwQAWEuZzfY6dT+05JoCspk0za/iG4uwRHIhH7KVGhaNTWkxINT8Ptv1mPjwKjD+HQplMoWJbm/n2vNqYNVxunMMrKmMkQyDhIxvbkxBvLj33MFsnJiX3PyYlfSJGIrybcv++lEg8O7HoAhpOA0z/0H/Hgz/0ED9kiQ4sVjilQp0mJLhliv//fYXsSUK3aJvTWW16CVdhllVLV/E7ZClUnwN4nMrngMjIGumewe1YfGDnVIkTOZnD+oMmIdZY5JcyMgClh7EvijMjS5pgl8rRIub4U49/9MvHf8W0M/uu/wtr5PeYENMkxrawQ+b5/lfgrL9I+9nAPVRaUTV7s4KxMlRTYlFFbVAdSdknqM+22nSOXs81qfd2XxcEb4uVlM7AyumtrfvNTkAMe0qMqosZHVaVFiVBtEIIe3Lxpm6C60qvDdSwGqdvbJHLfyuznf5GTQYV1Dthil0awSfFTL1D9+DbTqc2zXu9JAYhWywKwbNb+vr/vHQgFY4vk55UV+97zcztXqeTnrwJ3VUqVaXruOe/c12pWTVKWvlq1e9RmeXLiq5eCS4msrc1dAYNIr4eHvuGwMpSTiQVEOr+ufzSytdRq+bkp+IXGfPUznyS5+u8w+6/+ApOzEUnOiDBluL5D4i/8eda/57uo1ew8IsGLn6Mqs9aH+ApyEuR0LG4u6l9WLvsqZrdr51b2WA57t+u5VaOR3d/Vq3YeBWTxuO+1Uq2awxkEvrKQydgzkKOkaoiy5MLr6xq1ecqpXlTNLBYtA/rGG/BTP+Uhbwr6dP2SZ97etvuQkIMCsI0Nu7YHD2zeyZmXI7uz47O673eIF/f22/b/qsKAjYP6yh0e2vyQPRuN7BqWl+3327ct2FPQrAyuYGGyF/W6Tw5VqgEPu1ukikAPujUY1D3iQAGIYNWC6AhGk07btajiKeiLuCVqmKtnUKvZWBcK5hyrF4z4SsvLvleXggPNw/HY+Aayl6WS7TcK7iUqI4K55qigSYKbi9+3teWfqypVa2u+h5T2EtnDRdl1zRUlrwTBk0qWKltS45pO7TuOj+0et7bs56/9mudtSXVSc0B95cTfFI9WAYf2q1DIxllVIql9iZOZTNr3ra3ZWCqxsXhIabDVsnsTzG5R6EXqXoIxqR9evW7P4PJl37pA621vzydnBdcXH05wLgWpUqlUhWB726B4vZ6SUwGFT63x8KEFGsXAVwUVpFerllxZ+X/8QWY/9m/RI8GUCEVaxHjEKVWydAj/+/8ps7WAxwfetygUPIpkka8sro44RouIGkmqqyIspVRVxWs1X2VRxfzSJbOvaoWh+Sm4oargz4J7KpF29aoXF1BSVUnKVsvm1saGf77iwwkCr+as4gdPpzZ28bihSXI5uxe18pjP7TpfecWLg2j/UaNx2SEp3YnKoCStIICPHvlkoNqnqPJbKtmY5XI2nzTXwWybqraCsItT+uab9pkbN7zgiFBM169/88Po4KPA6EM5VDI9O/OiB+I7CLcqic1797wcrQIiObfq4SFo3fPP20K4dcs++/ixd/qU6QFPFJSUsQjsIqvX67C/+S2c/otFSv/w71PpWv+aEGGqJRh834/weP1lik0vZ6wKyfm5rxwpUy1c9P6+r1zIKRK5WxlFCUCoJ4VUg6SUdPmyrzTIcdvfh0FrgxCfpMIZESZs85AlTgCYE2JAnFMq7LFBmi4FGqSXqkw3Psns5W9hufWrcHJCI7FK7fIrhN4MqNUs0yclGZEIFUSK2xOJeEiESOuS7Wy1vNypsnOJhBmwW7e8Gp0M+MOHHsuvzOvxsef9CD5w6ZKN6xe/6ANd8ZMKBe9cxGL2jHd37XqDwAy11LSUAVfvjddes+cvkYjVVacEd+k6s09eIf3WLolRi0k8TTG4zPJqcMEnknMm+WGp/7z2mm2cjYY982LRw1MUBAn6BD7wefDANx5VVUzwHgkoKEiRClMsJsK4x31LrEBOo0j7ynwrQBLsQtenqsrOjq2vy5c9IVkVnEWIoCqyu7v2nsuXueio/tZbdv83bzps92e+g/Bnvo38O18i3z1gWFxl9kMfg0xAAnse4pwkEjYPj489dEvQP32H5ubqqq11BaNKOLTbtq5UURCcQZvzaGTOvrhVEpgQZ2t93VfV5FQfHvoAR46IlC6nUy+7/3R7AFU6n94A329DXFmxOSvOU73u5WgfPfLfISlvcTQEPRVvaLHaJxW+nR1fxU2lvj6UQxVR8PNRFd3Ll+383a7dv6Bpyq5L5lgBhWz4wYGv+LXbvomz5qf4apJul7KZmiPquQuWK+6qsr1KWGxv2/slCiGOgxpASypb3yv+hpxM8WAWxV9qNfu8yNiLz+HxYx90SWVTanOLc1ycK2WNo1G7VtkSBaRS0VtaejIoAo9EkNiKoJE7O3Zv3a7No3fftTkj6Kmq/GoXkE7b/rK0ZM9BvCEJVCgJIMETBSnqwVQseh7i8rK34dq7pQirKqlUwra37W8KtpWYUkJs8ZDSmfoNSfVS+0Y87tEIxaIfOwlXqGeZYN3DoV8rEj5SBUsBlqqr87nZA/FzYjF7xpOJjauSVlJ+u3rV7lc93qJRj0wYDoHv/m6S/83/k8F/9F+wdHxszYNpMqhuMfy3/yNSn/8cIYd0WVR0k1KkgjclBpaXPWdGFWDNXfGrYzFLTgiaq4SQrlPPRXy70chXpksls+OPH5utPzz0ye7r1/0+q7WhxMXurudNa3+RqMjSkoePqxIlLqCeb63mm1wvL9trk4nNUfHuKhX7zN6e7RPLyx6eO52avyG1uXDY/i6Y3t27/hnX67ZWxY1bWbHnvrpq59JcVgsWJXW1tg8PbRyUHJQ/oGBa6CehjcDO/8/L8VFg9CEdUr+6e9fLtYonMRjYRFtZ8ZNfZUdlwkX4k1Ny9aqXwxZeVtKgyjKLiCrstTY5ff7RIzMUksTNfvIOue+8yfTtdymMakSXsyRevs32LOCdd2yDuXbNFteLL/qyrnCxizhfqQXdumUGaRGD3e3a5iXlHCmHSUFG8CkRnFWqBcskd7uQK25TZsSUMG0KdLlNgwJrHDImRoIBW+zRIUWDAo/LL5NcepXNFZjNAvp8yjgOUUh3oNs3w6CMngKd83P7/p0dj82XipOCGlUDHzzw0rVSnbp61Tgzg4Fl3l599cl5ITK6AtvXX/dBojZV8S70rFUWV/PPft+eiZxAwZiuXbPrVeAcCvlO4AoMpMgmkQfwG9KEgMT1y4YtrsN1ZySbTZsLwlora5fL2TWcncFv/IZtGgrQ5ThlMnafkqrXRiaRA1VFd3ftvem0VyF67jm7p37f5tHamid7ytkA3x9LErOLFTEFHaurtmGk0166Xk2EdV17ex7KI8jZoppep+Mz5hIdUHVEvR6GQ9t4LcAIiF//uL1nCOGonwcHBzb/CgXvXO/seGclkzFHSrwGVXK2t302MxTyAh4KHJUljES8zLd4Yf2+zWFt/mDjLw5Pteqvr9+3e1RT1KeDH3GHlPFXUKuKnM7/QQ89T/FZ0mnvDKgaWir5JIMcSUHBVDmoVGwOyiFWkkmOOnx9KIccFnFkVKGrVi1h0evZXJHTrAbGnY7vcaUAtFYzJ0Lyvr2ed/bfftvLWYfDXjpZVS6wc+sepQgnpct83gfNCmjPz32mW69JjOKdd2w/KhZ9XxPwDaeVzNCcPDz0lWlxu6pVs2tqMLq35+E1L7zgKyty3stlv94XA6By2feQUrb96MjGV8TzxaBIqluCVz9dfUynzUZ97WueYylOg2DsgkOCr2DKWRO3QuMZi3lok5znbtdL9x8f+31UAcCv/7rZfl27vkNqo08Lfqhx897ebw6MNO7qW6ieOYsJMSnoqTWGoMayhSLRS+kxGvWS4FJHlLIe2Pdks14wSb2wFIRvbJgtffjQ85EuXbL5oGRduewTfWryORhA79PfQ+Lnv4v1d36Z83fr9AsrlD/5MTp9z53LZu388bhdrxQHhYSRwpyuWXNSyVX5OuprpuqWYKgKTvRs02lf9d7Y8MGhKpZLS/49gs7q3GrMvr/vq1ClkrfT4JMz6mPU6/mqkoJjCWKpD5D4lYeH9vqVK175rVTyVW/18BIiRfZYfbRU/VMVU+1ShBoSVLBc9ty7UMiep4SPpNCqXkiqymttiwsoeyru8o0bvtGs+Mjieglu/81eNfooMPqQDmWn9vY8GVCSuC++aJOx3fbdm2W8F0uSx8c2ydfXPcTq9m3vBO3s+MyeYA7aeBY/N5vZZwcDT/rb33fY1dOA6PJNwkUIpWE6sOuWgdDCES9I6inSrV9Z8dk0SWCurXlMsPhC0ah/z2xm11GpeIy5sNeTia8oKDs6n0Pv3gEFzLMsuEatHdIcs8SUCFXOKdBklRNKNJj9mf+Q1lJw0SxW2TtlVp9/3juVMjytlo2XpLGFcdcmN5vZmAmzL4hbJmMLfnXVytvKogu3/LRD2WiYU6TMkdR15BQJIgLwiU+YAYzFzBDJAZcRVsb1+ee9sVLQ0Wz66gl4KVcZerBrEDxPToaCF/E3pGajrKECAlWE1FhQQaAqMycnPpC7f9+PheZhsehhMIIDKZstmJ3GZrF57NMS4Np8BE2Too6qLvq8ZFil9iPYKviA6fzc1tXT3yEohRQaxb9Q8Cduz9mZbSyLvIGnKyjDoY2HssBSJhRBW9VLBcPiqEjmXBhxwW1VNez1zPkdDPy43rjhM+SLTTBTKXN4BHNV1k+cwdnM1sfq6m+G+mjMF7lDWlfiBj7rM+93yNk7P/f3qrWhjP6NG/Dt3+6fh55fs2mfU+Wm2fRQEo1ZPO5hRF9vU9b4CI7zNPxP46Q2A4vPVQGziPYSUNHcloOn4OPgwMb/9m17LZfzgg3i5K2s2O/JpA9mjo7sWS6OtYIHiXXoUGZd7wGf/Zd9U5IiHvdQOjXY1py8edNX5+TMtVo255SE+/jHLRFyfOwddjl0cpY1BwVhXlnxhPDNTW+vFg9VcFThevoZissjlUkFm/ruwcDGOgh8L5X53BAbEgJSlVrfd+eO58eqMrO66sdJQZW4ixK8WBz3RW6d+F6Lz0xNNyUsoyqdRJoEmZcq6dGRzZfFPlBKkGrtSp1OfoWSCpqDi/uqECwSzxAPTEIYuk4FjNvb5h+8/rpXEBXEbzazZ3npkodkSYijXDbOUeL6t5JYGBetpe1t++7XXjNbJYSBxCYyGY8AaDS8dPaimJCqJKo47e76akux6BuuqsGqeKPi2kjBUXNtUeBHHDtV7TQXjo8NOhaJ2HzZ2/MJxNnM76tSpP3yl31/SvU7WxTdSactOEyl7L2qHgsKrXmfSHhEkP5fwbE4pIttXASJk6qpYNNSXuz1fGJMIjdq7qzgRrZTiSqJgOmaVD3Sfry05J+R1svTvQ6/WY+PAqMP8dCEWF/3pWnBKpTllwrP0pJNGGVBQiG/eVy7Bp/7nC3yRYdD55VuvA5JbGox6jpWVz3pXE7e0pLP6onXoOtaWvJBkpr4nZ35aoYMy2KAVK+bcVvMssiJF7xQ0uKPH3vHQ1lSdZFWBk0qMc1HbZJ0mRNmQowRUTqkOGaJF/kaQ2I0yLPCCfEf/3fg93w3gYO0lMvP5jjIOJ2fm+Hv9XwpvNWy79/e9nhzYWzFu4pEvBS0jJcgOwpWJcW6aNDk7EtOVipI1aonO8qxUT8YSXersqY+N4OBf85yJBf7ICyq2nS7Nl/E8SoWPTxvf98+L0dPwayUEkslzztpNPyGoqyTeBKDgc+CCWam737tNU/6ffzYV0AEjZCscbFo9ylImappMqhPK52p0iqS/dWrHnanQ7wgqWDJwdIh4rkUduTo6DsUiNTrtg5F6BXEUdW3Vss7rO9VQanXLbutnjiSMRXGXVlxKRwmk/aeft8HkAqkFFA8eGBz7fFj+w6JiLRaHuZRqTzJhQuFzDFTQHJ25gNPEeHfL8B5P+7QN3qoSjgaea6KNuHDQ5tL6n+x+B2LMrySi5YkuIIbiSbs7HywStZi8P2snhvdrj3/px34eNxnRhMJzwWYzTwkSBlnOWnLy3a/rZY9n5s3faVK8vXibEj0RokYKbStr3vu0GLwoOP42LL8ql6I06r5cf26/fva17z9lyT2V75iY3zzpiVK+n2vgiaHXE03tR8Ihqx2BUIEiHvxrEPBjJACz/q71vjiutYhOyepYKEt9F45p1JQVbPxdtvWjAQiDg48YVx2SByOdNrWvhqmyn4eHdlz3N72Slyl0pNN1RchTIvPrFCwZJoSJVLxEtT15MTDEJVQEp9YjvyiMMbJiY27bJzs0qJjKq7ifG52pNn04y5BH8HlBaWqVCyQfvzYnG6125Dio+zj2ZmXvo/H7T6kwKvjveyG9v3ZzDv5qk4o6bJYARecUJLqi0gUBfRah0piqWePBGrUoFkBjfoCrq/7SoxsoNZxp+NFC1ZXfWN6tS8AX10V1C0a9fcmhd/RyNsD3bP4UZGIV65NpWzeLY6hqoGRyJPjurNjY39+7v0K+ZS6bvHD1SRaNAi1GlGStlDw168KnfY7JVgW7aMoFLJlT3M6PxJf+OgAniQ0ypApMJDogqQpZYBVNdDCX1vzUrpPOx35vIfIyYgI8iFS3mKGVMZlOrVFJ3WzUMg7/42GnWdryxZjLOaJmnt7Bhfo9333afCSoImEr1II8tTt2t+WluweBW8Ih42Xsb/vORHq7yMHXoozoRDECkmGpIjQI0GXBH1GRGlQ4IwSq5xQp0AyGZD4sT9OnCfVseA3j58MdLnsxw68+EO367OFMnTCbougKr6FNrNw2Du+jYY5JcWidzTlRG9t2e/qU3V05OUy9XcFUHL0pV4oJTRdl2BMUl8SqVcBhbgaEmLY2fFVCxnWcNj3M7hxw7J+Ik6rq7r6TWmDUpCzmBFS0KQg8uTE5oSkaff2fOAtUvLysq8einyrezs7s++Vypie29PVCqmyKaB4+hB8QnAYHaoqSOHo6Mg/FyUEFAQqQNXmtXjIIVx0QJ5VQVGvEMHc5HwJUru40et8Otf2tnfIVlbsWpVRldCFpKYlA65KmRSDpFSp9TabeUGAl17ywdg/K6iDkhOnp+Z0SXpeIh7hsB8HcbwWD8E5FmGeKytcwHM0P+Xsf9BK1rOC7w8CFZQDv+iUJxK+TYGy2prLsZhXkTo58a0KJhObz1eu2NwTJFYOnzgK6n0imOnTwcNwaEGROHiC/qkyq1YJH/+4X6+Cku3u+r2iVLI1omewKPUuQQIpfylAEmdS8ONYzJ5zqeTh5YvP8f2qec+qFC8eEsbRPT7dPkB8kkTCbJPWtGSEF2GEgv2KUyHJcKmHKVkBPjEl1bJMxgcWgi7reNYzAx8cKakiUZFez/aBt97y1S6NO/j9TcqkkhJX1Sqbtfd0Op4no2ciZcUg8BD8eNxLT6tXWC7nHeJOx1eXJWzSaHh48eamV1oT73axyvGsZ7p41Gr2bG7c8FU2cXX29ux6trftfa4/9gXMVI49eEGS27dt7zw48Fyq9XXfIkQ9+JSwVhsEwbClBLuIZgCvgCiuYT7vuYjiX4VCNi8uXbJzXbpk13z16pMqcP2+rXFVZqR2GA57mLrgkIvjdX7ufbinD8mOK/CU3YrHPR9V6+DxY89n1PyQDLkqnFLPHI99hVBtVcSpXBS7mc2eXfX9emv8m+n4KDD6kA7BGtbWfBZGWVk1klOPEkXqyq4vLXnHVNnOWs13rF481GhLCmrCJi9u4Isl/eNjr/kv0p+yZMJZy8E+OfFNY4W/FulafBgprAlipYyKyt+7ux5aJPWYTsdvJoeHXplOWROV7Y+O7LzXr0PhhcvM/+cU+cEhIWBMQJgpOVp0yLBLlBkBkz/+R0juBxfO9wfJUDxroaoHzqJxUcZIKjLK6m5teUMg8rxUlapVDzfRa6qOLQZVemYyjFK3EaE8kfABnByNszMrt0sVTA6VrnNRNU2ZVBG5Rfg+P7drFL+j1/Ny8JJIvnHDwyaWl70SkqBCko0VOVnGWplMSfQqOybojn5X1k7z4vjYC1+oB4TgizqezjouSryqWqDx6PU8zlwboTYIyfmK2L287CE1uj41ZlbV9+5dryy22BCv1zNI4yuv/OYKymJ18u5dXzXQuNfrHq+taqsy0wpAQyFfPZCy3v375vguwu5kRwRn3duz96sHkzbARdnbxWZ+H/T4IFChr/d5ZdUFMysUPOdpedlX6+7ft3GTstpikFKp+MSCqqYrK35uCG7yNI/j/Y7fKlTwaQc+HLb/VxA7m3lVK0F3r1/31SUJaKTTPvl0dOTP9bQtkyTze8FM+32vXroo3Q0+2Ds4sO+/fNmrmT54YOtQFbj7933/HYkTPHzoleOkmiYYsJqXKrGg6qiI61J1UwLqg/DS3i9YFc9JDSifVREWtGl93V5bXKMSN5Fal2BKsr+6hwcPPNRQ45lOe8ln2Su1GHjW8fQzA79vSpDj6MiuZXGeKfgUNFOQKCEeRNpfXbX5Pxh4LrA4wOWy/e3ePdub83nbvwTRW1ryUDzNzV7P96zJ520dyu5JyGYRwhUEFmg/LZ7xfscih0zP5fTUc7vkNwhtIz9H+/RiICf1QfV61PoTgkF9jR4+9BDjTMaLWKiZvRIKgmTLXxMvVegQXf9o9KRCqfYRBZ/i39y9a++VPZJYQbdrwZwEPYREuXvX1uViFT2bfbL31bOOxf1S9AohCSS+obYT1655WF2rZb9fuuThjBsbHtmgitqzxF8UMCoh9UETSt9sx0eB0Yd0KOMt7LWyQFJoU9+BRdGBfN4c0tVV7xBIQebRo2cHRtrAxUsSUV8bODxZ0l9ft2BEPU2EuW237XpWV31zPXXaFsk/HPZN4oQdFiwDbHOQMhl4GWL1Trh503NcFCBKyaZQ8NWb4dBLLit7ns5AKNRjSsCMEB2yBMzIUadBgQYBKxyT+2/+S8K5Gc1Pfp6Tk396ecj53I+P7lmbrCoycsS7XRvb8dg2GDXprVR8g8jFYC0atQ1Kjpwyfs2mPe+XX35yc1nkOICvDoB3BAQJ0bhdv+6hDKpICv987ZoZMjUuleCH+F0rK3bv4jmor5acb/UruXLFvufgwDZi9aARb0tEV8lvLy3Z3HjnHTvf0ZF36tU5XsGS+Bg633s9SwXviwpfmrOCFQpa8cUvWrCgXi1SOFMAB09md5UVTCbh85+3c7/zju+zBJ4z99JLv/kaFwMAOTRSHbp7196vgEUYdpGBBXmULVmEt2mjUcCkZpPiqSg47vXs2hQ86X6EyxeM8BuBOCze0/tBhd7vUJd3CYIkEr5Bq2Aimt8SqqnVvOOzGKTIhj6rmtDreUjIN3L8VqGCTzvw5bI5WosQ6dHIJxB0j0qQ5fN+DE5OfKVXypaLx9NV8ae/W6IhShRd9LJzRzLpq7qSupYtSKXs/MfHXvBFTp6qJ4JyLgbUSoDt73sVvEUhiEePvKrXN8JL+3rB6uLrTwclqmooQff0IeK7BAU2NrwTCPY9atgrpIcSGcrAS4RH8KWng7P3emZPryUFjt2ujRXYuQV1FW9OinESCBB8ScqcgjQrSRSJ2PrK503YRsG2evBtbfnkiII38ZGkGJtImF8gSJVg1uIgS3Dgxo1vjGe4CAMVrFzwWlWSlHxRYlBJPEES1W9H3CvxqtW7S3BqNQyORHzTXFEShKxQXzz5OhIMkU8jflkuZ3NFia2n7YTguGqlIXTM4tiqSlcu+4S1uGHXrvlegJLWfv55z0n8IMfi3ijp/cHA7vPVV71ioXhHxaKHkgr9oQRJEJgd0Hp9WvxlkaLw28E9/T/q+Cgw+pCORViDFppK27GYn9TTqe+9sblpE1hOpAKdctkMp4iVTx/vt4Erw6KSvgjKqsgMBj4LK0iEIFsipd6965WW1Lle/TwEx4nHvYqRVMDkeLbbvookMqw2XDnPN274DIkydcq6tVrQ/9pd0v06u6wxcv0QqhwzIsqUEH0SJOgTO3vM5E/9h/Cn/3PmH//c131O7+f0PL1hSUpYXaOrVZ/RvXvXB7HK8i+eT3wfOSnqkaFnIgjIovyq+hA961rhyYrk01USbdCVir8Owe1qNbuOQsEH53IAxMHpdOzn9rbd88aGz/bu7tr3gTkRzz/v53ezaZuoVL30WjTqNzdltkcj4x2J+yOiqIyrNo6NDX/vi8/m6WqFxnSxWqDnqsqn7j2TsaBzMDCnVc1vBXtaWfHjsZjd3d6Gf+lfgl/9Va8wmUqZEuBLL/nPLR6LAYBI65JpffddL4ShgLlYtOcqhSA19X0WLEWVRCVaFp+xmt0mk54zos/LOdezfi+H8b2OxXvS8V5QoWcdi0IBuh5VFwQTPT72ayOZtDGWMt3TcL/FgED94gSnU1ZZzsA3evxWAqpFB162VYqF4khoLciRFh9CCRg5FdpLnuUIPY3bf/q7FxVOn/WMF+XCVV0aDHx3e/UvS6VsPKWipwTKeylNLfIsVfmQ47noWH2jsM332+skn/3okX2X9spFMZH3ylg/az7ruamHThDYmlQlJhLxlU4pdtXrPjHxXnyop5/Z098tDpEatQvCrCbBp6ceGqc9Q0Hd1pZXq5NTq0P9+PTM1W6h1fIiIY3Gk9wazT2pbwr2r6SqfAT1kVLwHAQf/JnCb4aBil8trm8+/2RfKfAJVSXUJPQjZUPw+/fWludHq6ollTlBnwcDD/dSJUX9g4TuyOW88IHsm2yPkAmLCe/F5JXG5do1+87Hj+3aJxNPM4jF7PXBwPaITscSj+KzLQqYfD17pqqTBF/q9Sf3xtHIC0FoHETzAK9ueuPGs0VodLwXReG3g3v6f9TxUWD0IR1PwxrU9FJN12ScBI0RWU7HwYFtSCIki5T98svvnSl4Fu9h0fnQewQ52NqyTWRz00th3rvnOyir2Vk06qsHgvoJLqBu68fH9v7VVVvgglEVCp5rJbKxiMJqYPn4sZ1TCn2LSmDVquPVPGxxzApNcqTosc19snTYZ4MhETK0SNGnTZYwc/J/+c+x9nPfwngcPLPS8EFgQE9vWEdHdk1LS3bN5+c+WyYyu0rMz8K4h8Mexy4Y2uqqvSZlmETCnG9lHyUp+/S1KtMk5ZenORUS1FCfDH1eioIKkBWog9+QF7OFEniQg6mAVwRRyXmLg1MuW6CvPkJS0xPUTJAPjYnw7FK+0Qa0vOx7MMgpkSPxXtUKceTAP0dVMcSf6HS8oIZw5NmsH2tBNjRnns7ugq2F7/9+WwOq8Czylt5vDQpOpAqx5FAVDEiJSuvm7Mx+Li/7+ba4GQrWOBh4mWpxEyVyoWaCypBKbUpOuLKVH/R4ll1ZPJ4FFXr6eJbKmGA54hwJSrix4SuNcqSftRmvr5vdvHvXzw0pCPb7ns/4zyJr+bRzsLZmtlUcQSVClDAQLEUZclVO1TtI53z6eBZuf/G7l5c9J0PcTiVPJOaiXktaP9Wqt9dy9AXXkoyzPi8I99Pcr8nEcyOVOVZ1Uvf4jUIvF49nzSuRzxMJb5/h64uJfJD5rGpfv++J8OJmSBhEdmaxefSzAqPFZ/Zee7TU6LRGIxEbp27XV4HEFdvc9FXToyOzv5pfi4f4beJBaZ3JqQez5ZKY39nx3y/7rZ5WCmS09yw2PBVU+hs5nvaXVDFV+wz5S1JrlKiSFOdUVe90vDDU00lhiSopiSbubbP55N4nLo7UcptNGw8lWCT4okTDB4XdLgq6KBktwQbB69TaYnPzySSx+jupCiy427OST43Gk6qnsZivQquSLFSG4JtSJV1U5BP3cVGC/Bt9pv+8Hh8FRh/isZjFVElWmUuRE1W23tvzRPDDQy/DvbLiITBHR/ClL/mOx1/veC+VIjm72ihF3hfHRMZ6UVFpddV31i6VLItxeOi5J2AZXWGbtSAjEU9cVXlY+Hptiufndr9gG5hkoJW5ymSgEI4x4T5VzhkSZ0yUPgkijJkzZ4eH3OQdZoQJMyN+MmL++q/QvPOZ37RpfxAYUCj05IYlSEoQeKK8MvDC/p+fe0f+vTDucjhWVz28RhwhSUmL8KpgSQHa09d6euqDa6kCKnASAVrNcvV5dfl+9127JjWSlTS5uGYK4tRTZn/fzler2carfh5qHHt66vvpCM+s4Gky8Sp64haJsKmstHrlgH9d8qidjo2XDO17VSsWqzXiDGiDikTsnlMpW2v6LikYif8kR1Zz5v2UdN4rGFo8nrUGJcss4qsCIvGdJJ4gWNPmptmKZ8HU4nFbM++8450TQWMkxFKpeHlZOT16tpmMwWreiw/xQe9p8XhWMPn08SyhAPVe6vdtXlWrNvcWBWHejzMo3l61+uzGsx+kkvXbfSzCX/N5G/tWy8vsLwYGhcJv5hHKPu/vf+NCEAogb970lUSR+0VqV1VY0EutWfCwZxGv9bf53O7l0iWbd7u7nve2eF0KRLQWRej+rUIvP8ih4EiQJY39+zlpH2Q+K0kkm1oo+KqIYLqLjvAHFe94vz1aFQ4hARb5wNms58+l0zbnJxPbg9591/bnpwM9QQwzGXsWWncHB08+c/XCqtXMVqoh9Pm5r2zs7XlbJfGBR4/sfWqa/o0eT4+ZkrVS2svlPO85lfI8Njn1qmSFw7854JSin3pCpVK+8ibRGnGcFlXtTk/N/l696hNQJyf2b2PDV6Y+SJXk6fvb3LRnfHpqwbaep6p99+/b3Hj40M6lRqtSKX1W8qnRMB9RVUYpQp6c2Pu2tp7cG7NZ31JF/pqgfrWa7z+pRvb/PFZ/fivHR4HRh3gsZhIePPAkYE1C8Co/16/b7y+9ZJug5BIHA1u8kmmt1WzBvPLK1//+95I4XQy4pGgledDh0JMdlUWfTOw9gv/0+1Zefe45O9/5uedsSFFKEqdSLzs89BmKZNIymfm8vS+Xs8W5sWHnU8OxfN42hnweguJzFMshoudT8pw6nlGaPkkydEgxACDpfgKMD08JXvjNRvppaJPI38WiVa3ArlkKK8qs6ndJSnc6Hku+uuqz3F8P4y71Nm2KwokLLw3eIW80nh0ELC/b37TBqWIkoyxYhXhfkoAGr3R1756vIuTzviq4u+s5A+22PU9xxNTZWpUe8R7EXVHvEkHlkkkfmAgXL66DFJauXDHMtLrZ69yL6kZyJL5edrdUsvesrj5pyJWFl7ysNnTxKiRTKkdEc+afVknnvdagVAxbLa/0pM0/FPIBU6XiVePg2c69qkOCPAlGBr4hZ79va1TV28nEJzT6fa9a9kE2vve6Jx0fRJb1WUIB6rUhByQWs9+XluyeHj2Cz3zmva9Pc2PRvi4eH6SS9WEeiYQ5QO/nPD3NI9ShfeT83AdN1hvmveG2Ope4FoIuL37X8rKd++FDn6xQYkf8yIcPveCMoK6COssmPnjgK5qVypPXFY/7KvVvFXr5jR7Pqiq+1/F+83kwsPUpNIeq4Kq8wrOf5QetIrzfHr2xYTZactrityiwUkCwKIku4rvEIASfU49DVcQF0Zf6oWDGtZpXF1MQ8qlP2byVTLtUUdNpX20RB/T01AdX32gl8OkxE7pCiT7wdkUKsIuCJIu2epFPu8i3qlbtWut1uz+JL4TDPql0eGhje3Li1e0Ej9N++ejRs3nf7zfnnr4/yYcrEav9fn/f3qP7kVjC4aFv7bK5+WQLCx337/seWPIxBLmUsMedO0/6CZqD3a5vjKuqmKrtSub/01R5/3k6PgqM/hkdUnQZDPxiF4Evk/HdjheNk0ixKlnfu+ed0KtXn803Wjye5XwsXk8mY+Q7cVI6HfubDLV6sWjjUrVHGRs1kRNWXLhcSYeDJ7SXy8ZF2dp6kqQnmc1o1KubCf8qbkqxCKdnAeV/+98k8af/A4bEmREmzpgNHgMhIkyZ8aQn1s2uUsw+aazkPEmaWcHEeOw3ejADenTkCYvKxslYPy27O5n4apkyrM/CuKdSvlqlKoXG8ejIwwAUZAgH/Kxjbc2yg6+95jH/Mu6Dgf1NHBg1cVVDx+vXPXFYm7WqhnpmUmKSIVTgsrHhYQh6fqoInZ97ue9FVbAvfcmroMkp16ZcqXjss6pk4pi89NKTAhQftFohqW0dUkycz73SkWRYi0VrWKh7XV/3Sl5qEPxbPZ61BiWpWy57KFI26xt5np/7axM5XjDEZzn3iYTHoWuOzuf2/krF7uHNN/3GKFl4jckv/qLNve3tD7bxvZ9dgQ8eTC5mUGczc1LkOKgCKFGI2cyTsd/r+O2oZP2zOD6MoOzrQYN3dvz6fFZgpSq17LLGUL3axHmVA/zWW97mSelMc+pZwdo/LfTywzyens+LSqSCm62s2J6gqo+CkvdzDj9IFeH91pISiFI4U5VAPefUk2bxcxLfkWS99ql83tt+Qf6ECrh0yT6rKrZsdDbrIYSdjp1jNrP3yEdY5EUNh57/J8GOb7QSqMqb+KZSnBOXamXFJza1d2p/FcIEngw4n+ZbCf6nKozWiyqAUtwLAt8wWkGIgolKxc7xXrzv9zo0J6SOKi7oZGLPTdfRavmkrYJR0RtSKfv7YkNisNeEQhEUV4iNTsdef/zY+46SrFd/y/9/e28e5NhZ3v8+WlpLL1Lve8/q2ZwyngDxWhNMAg4QlorLMRQpQwiYULmUcVJZTEjF9q+S67rhF4o9ISlCqlKGUDgmZeoSAjcBMwQM2DXG/LyMl5np6Z7eu9XqVWq1dO4fD1+/R2pJre1IR93fT1VXz0inpbO+7/ts3weOMxjePT26hujs1G0QGax1lNeN0DByEHvKVk+PWupQekPUBjcuOovHYirBjIewvd0UdsKLg34/pTyQu4X0IV06Pa2DGQoLoZ6GgXFjQxsAHjig+4awNOqnICEpkp0aBq/T9dfv9K6guDGVMkX+SDPJZPQ9NKBcWxPZ+JVbJPjX/4/0feovJTA3KV7JiCUemZBRWZV22RafWCKSkoCsDx6V0M2v2bGohUoXvCJo1Hbxoi4OkY6DkHswqEYEBvsrV0w0BIpMIqbeB3Uy8/P5c9zt0SoUYWPgX1/Xv0PhcmenXpdCC732dtNfQkT/FjLMwaAOvsmkSc9BgSmMr6NHdTDEe0h/GxrSz97eNs3oYLiiUH9qyqR/omaqt1e3xX2JRRbqeSCdaje2e3uN57G11fTjgOhArrpROdGK3AUJmvtBYQ+9i1D/gHSnYND0WylHcrYQucIAqCfc3NTjPXnS7M/amt5nJ06oId3WZlIRUUeUz1OICdfekwuLMHhy7Qsj1Bytrhp1PNROlDLxVdrnJ3efYQhNTOgxolEmCoHRFNReg1OIWkSy3AjksqGGZndYbW6aho67KQQWuj9E9Jmfntbxzes1RigiHSh0R/QO4x883Rhz8kV/msFgRd3f+fPm/MAhgf5hhfpH7UY5DgL79YMaqMdjot5of4B0LxitIqZOaGhIa5GRudHent0UOBw2kUGAz7BHKJCqBhVRu0JZb69J80Y7CPTrQ28rGOulnKNChj3qDu0tF7a2zHyNCGZfn6by2895R4eRK7fXW6H+9/hxU1fX0mKyY3COZ2ZMNB1GPVJR8W/7OSyVRMKktyNjpKtL9wN15W1tZpsDB8w1x3yKtEX7vQXnrT0NUcT00rT3bBIxTkso7/r9JlNmbc0YhIcOmbWAk1FeN0HDyEFyayHgFV9Y0IkHKm1er9HcX10VefppMzjY6xigLjIzozd4KTdlqSF9KNSMjen3XL5sFv6QXI3FTFQFaT54gPv69KFGHRXyWJGi1t2t+22XvIaEKGS7kYKFgnMcXzxuakySN94im2/8rkS/+imRv/3fIiLSIavSISsi4pG4dIpP0tL1v/5Iug/4dizskDIAeWXIRk9NmagX1PrQDG5qyuzf+LhOnkePmkU+0hQgsX7okF7L3Bz3XM8pCnfhHUqn9Rz39+vxYtFRaKGHourBQVPXgz5TSBGYmdFtIUttN8p9Pv0epJ3Nz2vkBMWYIvrdx4+bWqOpKdP4FoMyIg/z8ztln+fmdNtjx0x6JrzKEDuAUAMiVF6vEbXILSAuJVoRDuvzYfeOQ4J+fV29YOjePT1t1P2OHRO59lqTWgIDulRZ1ELYn0E0MvV49DuxoIxGdf+efVb3d2DANF5E8SwaROd6CnPPTy7IGV9d1ecaESNE1kZGzKR87FhpE1+p40op5wYiIDMzpp+IiElf9XqN57uYYVSrSJbTlKPWlEjoPTE1ZdQskeqMgv8LF4x4BSi0gCn0faGQpgyJmP5xiBxZln73jTfqvXPlinlup6aMup5I/uhPsxisdsEcNLZG3RQ898WOs1KKPUvonYYi/bExdSJATAMKtmi+2d+vcw8cPPjM3IbTS0s6T7S3G5VOSOaj3hTXHRkhCws6dqJ5ONL5cpuSo3a51HO0W82vvV8OGhKj7xZqgtDSJJPRuRnOmVhMf6DohxoepMRdvKiffeqU+V5kQ8D4hFAS2iL09BiRm2LjUSGwLoSjDsfc0WFSWlErubJilCCjUd0GjsPceQlrq1zhJ4D2DFBBRcYI1mpInYPQxvPP63eibMB+HRsd5XUaGkYOkS99IBTSwSMaNaFmhCmxmLAsfWAvXNBBMBcoNWUypd+UpYT0IZcLRSs0fLOHmdFvZGjIGGxInUPHcBGdYNGvA9GA7W2j9mKXvB4d1c9GnQw8/RiwMemi/mVtTSS24pPOP/gj8V51Stbv/7hEZ8dlRK6IRyzJjBwQ799+XILv/M0d5yEe14HnZz8zqQEwhFDfgxx8eNahsIc0krExHcxQ7GlPU9jczF545Z5jeE7T6ew0PqjH9fTowIyIjkjxhR68u/AqQiIWhaZbWya9Doo8WKR0dZmGhuif8swzutCBhxn1Rhsb6oGE13F+3qR3rK3ppNPXZ8L46MuAZwDqgv392YtdGNVoXoeUKRglhRaxxaIVHo/pBYXPwuSNyBz6fni9+rcHDujPyIhZUODeruXiBwbApUvZBoAd5Pe/9JLeezhPkYgpGM71FJZCLKYTnYiRfkXdyPi4EX/AsZYy8dVSlhViHhMT2SpSYHa2cKd3O7WIZNWKYv09SmmIi0jR1JRxHtijh8g4QI+ZfJSzgOns1NpVCERAaRMy+5DyXlzU/UXPJUQYCqk4us1gzXe/Qi3wxAmzUERT7/FxPWbU8nR26t/VMspV7FmCwtpLL+nrJ0/q/5NJfS7Q52dgQB07MIKLfSaeE6RlpdMmzRaL/UzGOCSRxYH+VljYI0MCUQjU1+JvSjlHu0n/b2zo3NjaajIoMFYDtIWYmzPtDlCntbio9xiMb5Qy4DWkicMo8Hp1nEXdrIh+Jxy5Gxu6X0ePln/P2teFiPzjfCNDaHzcrLPQSBzGDNp5RCI7JdExpxRK70PafG4vM7RVwfoHde/RqL6O58B+Hd0Q5XUSGkYOUSh9AN76cFgfrtFRHdCA12s6LyP9BdEGqH4dPGgGqnIo9hDbQ8+plBkQ7bUI8Dh0dOhCBmFm1G4MD5ui//Z2k46wtmaK/yF5PTZmmoQODppo2uxsdogc9Sd2ucmZGZ2U217/Zun6zVul+7n/kdDiFd3pM2d2jBiJhE4kzz6rHqLlZRM9mZ7Wz2xvNwMf5ELTaR1MDh40k000ahZvuDZeb2kLL3i+UWxv7zsENcCurmzPaaGFHpQOkRaG/OPNTV1MQdIb6VOJhN5zSNfD/mN/L1wwUTrLMtLpLS16zpDqCebnjccSuextbaZotbPT1ImhGaJI9sKou1sNI9QbwfDa7VwW87BCOh4TNia6jQ2N9IVC2pUdIhlzc2poTE9ne75Fdh/8KzEIIPqQ7zNRIG+v+UDvitVVc4+WG8FCR/OlJeO0QKF9R4fez5j4sV/lTHylHvtu5+vIEb2XJiZ0IYT7FsXEu3V6F6ldJKsa8hlALS3ZvcJKUWVbWjKpUOGwqTtD9BA9Z9BjJh/lLmByBSIgJY/9hMMLx+X1Gg+7iIly50Z/3GCwFjJMYTzaJfVXVoxTKBjU9z0e0/cFPd1qHeXK91zY1RaPHjX3zfi4aUA9NqbjWj5J8kKfiaL/7W09VtxPSJ3u7TVrEwjXHDmi33fpko5VKBOAIy0SMeNTKZHA3erP/H41CBcX9ZpdvmycArlAeAYS34jEX3WV7qtdqfLyZV0TQGJ8a8sI1kAkZGHBGC9oKg2HQXu7qYcuB/u60LLMmgBiJ93duvZDijxS7VDOAEW63t6da0tkHr34oh6bXRIedWWo8ca+YP0CgQak0EPkASn5uZkgbonyOgUNI4fwekV8kpbU938igdis3mXXXy+JlE+Wl01aGtLPMGkHg2oYjY0ZvXrkew8MmGJ1KKnUEoSeJyZMDQp6HASDOrD89Kcm5Q5ebIgF2L2CSI2an9cHGQ+oPd8XAxl69SCaAE8JJmD0TwqFTDNLNEoMBn0iY79a8JgQpr98Wc9jT49RqoGYgN9v1OhgPExNGW8JQtoQJBDRgQqqfQixQ7K2EDA0l5ezo4FY7ExM6DksRd0IHiEYQlCKsizTe2JmRvcJvYbgBcViC4uxlRWTknf5simsxn4EAmpUpNOmaDeZNHLP6MvS2WkGcORt9/eb/bFHiwIBcxz2lMlSF7H5vKEiavyisHZ11URcYCRtbhqHQ0uLHjsmdLvnW6Tw4F+u598O0gTRH8NuHE9N6blC2iaePbvhfeDAzvTC3cDiFtFbLEIyGVOki2uEY63lxFfq+ULEAj04IMIwNmbEA0qhlpGscimUFnTxou7P8ePGOVAsXz+ZNDVwSD22L4Qwdtol7/NR6XW0p8HBcXH0qKklxXg/MWEWb6GQcYzlnu9GG6zF0rViMRNdx7aXLhnZexG9Fhg3V1b0GK65pj73Va7aor1FA6I8Xm/+BtDFwHOytWUWyBgr4LDFdcE40dNj5P+XlnS+QBsOny9bWbWUSGCx+jPU4qC3FtY86+vZYlB4xqFCiggHgFGOaw+p/NVV00h1cNCkI2IOtSyRV70qu+UKeu8ND5tU51wFyWLY00qDQb2foLwrovuHVL2JCZMCn8kYEYZUaqehIqKfNzKi+4lSDazHkLZtv0fgPEQ5BzJhoPqHtF1EFu3X0S1pyU5Bw8ghgv/vI9Lxf/21xGY2JSDLIiKSGDwkMx/+a0ne9PpXerfAmLB7DYeGdAE0P68DFB4ITPDw9Nb6poRXKhAwHgsIKaDQNhzWwTAaNYtkFPfNzJiaia0tM3j19urnIxyLprXptKlZQqEfBn94ZUSMdxTRkZ6e0hdJS0smVQBpADiXiNpEIkbKFhMPpKXtsqdQoxsY0OPCe4GAOd5ikzwmnc7OnYti1LJA9SnXOMpnBFy6ZCSXkVeMiBfSynDPII0tFjMd3O0TWCymn/Xss7owhdEDgQjIeEKx6KqrdHBGmB/d1oNBUy+HWp/xcV3oXr5s6kSCQT2W4WFVnrNPcOXc1/ZtZ2b0nNgNByj7+P3G6wcjHb1cvF595mC4gXyDfyk9sHYzjnt7TeoJmvJub5vrDJU6iHxg8YCu5+U+9yiORkExor8iJnUzmTSOmULHXgnlni8YR/au7eWoPtlpxKSdLy3Issx9hnHMTm66m92Z09pqxj/7oga1D/YGrfmo9QIGUtWTk/pcr66ayLldvjuR2PkcNNJgLZauNTubbXjMzen5RlNeRKAhJjQ/r+Pn6dP12fdCxkMwaFLWkDpcDrjP0mmtLRwd1cU4nIBwVqJuE88uBH6gAjc1ZaIZEEcoNRJYrP5sednU0+FeCoWMEh32K9fZhhRkkM8ox7oGBjHqopDG/uyzZq4YGTFCC5hfFxbM2qccctNK0ZIF64HtbXWeIFKOjAz0PhwdNRHiYmnmMN7sa8fc6wFnt4hZDyBFsrXVKBUjUgqjrBFpyfWGhpETPPKIyO23S7cVkE0ZkZh0SpusS2xmU9b+4q+l5QGftL/hV18ZiHO9hiiEffZZfS0YNB65WkgIFwMKasmkKULHgGWP7NgjCuiLgHxd+7/hSRIx3pzpaf0MGEfIbcUgh+JQDBZIO0RkptCx50648LRhcQ/PKwZvhJDhcUOEoaPDNDMV0YEAym9QXYvFjOgEBuLdFscwCkdH9diwKEadEkQrCk1wuQMh6oYOHDBCAVjgbm3pRI+oltdrPD9I14Mn/9IlTVeA9xT1Pih4xSB86FC2hzKVMso5SBXy+TTPHYZra6upZcGgCqnV4WGVi6+VtxhpJZZlJmvsAxqetrcbT6hd/hXNe5FmVmjw3y0fvhSlnlwPpr2HxNiYSZ9rbTXqUTDuKhGC8Pv1uJFDv7RkItDJpHn2oEJVy4mv0vNVqTHUSAqlBcEhFInsLGIWyU53w2IVMu5Inbl8WRfpBw6Y3iJra2qkDA8bpcNap6llMkbYBfck0lNRhA9HV2+vqbUs9hzU22AtdF0w1qLHSyym+w9hGXvNTShkUhnhyFpczE6DdwqnxCtyn02kkC8vG9XRoaFswYbcOjEINI2P6z5g7i81Elio/gzZJSKmV56IfibqqkRM2j5S1FtatE4sX8TSbpTDOZNI6DHYjSuUBqB+Do3b4QhGSmwxEZxi5KaVDgyYRq/2EoJXvcqss7q6zLwN52K+usFcI3C3jAaoUaJ2FcJK09M69hw9ajJ+ysnoaHZoGNWadFrkIx8RsSwJSVJG5IosSZcsSrfMyICEJCnRz/3f0vnumyUUMonhuV7D3ELYfJ3SncCe6pNMmgjL9rZ6CSMRlR2HcgkeVBHNTX/1q7MbRU5NmUEPxZhLS6ZTNxp9Ii+4v98MtmhaishSNGo83/ZBoVCqDgwiEf0syHGjwzOiW9PT2bVFqC9qazOy2svLpt/U7KxRYxof1+NAzQ4WBflkcTHB+XzGS2/fBp6gUgdbpIPh+6NRE2Ho7NR9iMf1/oEUtYgOupZlPPk+n24PxTKv1+SKo4YMERVMGk8+qecB5xpRzJ4eY/yEQsaTiMkLzV5xbaamssUmKiWZ1O9NpTTHGs1Scc/BuIX8Nq4JGjaWMrHXqh9L7uQFI72rS+9/+70Pw7mtTa9buWl0Inoe+vt1oXPqlFF9RA3T1JQRhkCdWy3GGLf3r6k1hTz79jEyt4hZJHthCwUyqGghzeboUR1/FxZMCuTwsLmfQyFn0tRQe4B2ApDx3dw0bQwyGTXY7O0a3HRdc68LxGns4jdwUiwtmWjJlSsmQwCOoJYWExW7dKmyAvxysdf/2utkQCVRwULPJmqgUUtlby5dqE5sc1Ovf29v6U2i7eT7XNTFwNgGnZ0mJRrZCohsYA4qhn2/YPDDYYjUOEQP4eyD0SVi1gSRiDEYyiWf8QIp/FDIGCVDQ8Y5iXTWgwd1u2IO1HIis/mc8F1des8Hg3qMqEWrd5S3kdAwqjVnz+oM9gtCkpRhmZFW2ZCUtEinLEtobkvkqR9rG/dfkK9INrcQthY35W6fVSzVB/LOKGxcWjKGyKFDJpRu/1z7oAeJy0hEBxoYeem0qZM5ftwcO4wHeI88HiP5jQU5JC/zpeogFA8DLhQyhdCJhL524IDxxoXDRrELSnOYDFGICBUvSJnCewMDoq1Noy9TUybUbm+kaPeO5Z7/cic4hNc3N7Ov65Ejui/wMI6NmV4k8CAjxRC1OCMj2qfK4zFpeJgQkL/+zDPGOBUx6ViYpESMhDmMQ0ThIhEdbO2eOSjcTU8XVtUqFSwWg0HdFyyCIDO+tKTnKBIxUqzlTuy17MeSb/KC199+75ei0lcKEDaYm9Pr0tNjnsvTp9XZkW/RVQ3N0L+mlhTy7KOWYGHBeJ3t4LkXyV6s5qbZjI2ZekvIMttTjJxIU7N79HFPIhKLBsVdXTv7prjputqvSyajcwicfvaURPscgToWzIWWZaLMaLJ55Yo5L06Cht3z86buBM2ekXFRblRwt2ezvX3n+07VieX7XKTVQ9gBQAH3yBE9H2gC395u1H2RJVHs/s9n8MMJhUar6O3T3m4cnRsb+hwfP76zL2O5x5zveYUgBMZ6ey8nRDLhXN3NgVrq898oJ7yboWFUa6an874cloS0yYZ4xdIX5uay3i8WDq/FBFdOwXixVB+EdNEbBgWPgUD+PGcMetPTOqij4B6fiwnpwAH9d64GfzBoimPR5M1u/Fy6ZBaSwJ6qs7iog8/oqL43O2siVbOz+vnDwyY9BY0vkdc8O2uMIBREQ0oTxiJSHdGjZn1djQB4UxcWdCFz9OjOZp/oPWQ3WkoFRix6H+VKA4+PZ19bTGDJpBpv6GczO6vXcnRU75GZGb1WUPVpb9f7ZnFR/7+0ZCRR0ZEbSmsoEl1dNWl0WIS0tJiIFlTRoABVrXc5ldLPgagE0juRY43UseFh3Rcs8OwTO7xihXAipaWQE8Hen6QWKVG5wgZbW/r5R46UJ2xQDk6lALmVQmlBInp+Z2dNw+x8+fq5i1WMa/bIeSZj7uN8CxYnvLm59yVq9RYXjXy1HbddV/t1gaPNLvWcSun5RL+wEyf0+UB9kT1ShBTlcNjINjtpGNlr9A4e1PtgeVnnmXBYaz0L3QvFqPTZdMoAL+YosoM6ts5OPR+ofYZDttR6q3wGv/145udNVAiGFgzk1tbaZTkgrQ9CQIhW2aPFuD4+n3EQI6JTK5xwwjczNIxqTQE3QlC2pENWJSZdKsbQ35/1vpMqH+UWQBdK9Wlt1ckZKQZ+v0khKzYZYoKHdHNuATyEEF580UQa7HnySMvKLWj2eHTiKpTLjtz3cNikpwQC2R3eIxFdGCIahMU6BqO5OZMKs72tn9fWpv9GkSO2XVtTg2NgwNR0IB99YkL348gRPb4LF/Q1LFD7+3cv3M8HFi12o3Frq3AUJJHQSdXe9A6KdWgoDKPi8GGdPFZX9XxFo/r5EHxACh3qD/r6TL4+7mM034M4w/p6dtQIk1m13mVcNxE18NbWjOgGaociET2GwUFzz3m9+v2lOA2KLXxFqn+GnVbuqqWwQSmUc772yoRcLN3I3gAz37VNJncuVjHuhUL6em9v+epj1ZIv9QcOsXwLRDcqVnV3m9oZNC/F2IzUdaQAIl0LdRxw/mxv6/gxPKzjHeYMJ1MGc+uAMC5lMqYOrZJxodqxzKnjLeQo8vv1XM/NqcIjan1zj78cozz3WcVcNTen/77mGr3X7U42RHBEKr/ucFIvLJjrGwrp3LmxoZHh3Gix36/34fKy7rdTNeZuemYbCQ2jWnPmjGlElEO3xGRTWlWMYS4mLXVS+aikANrj0QcSRozHow/yyy+bxm6ZjEk3wIKz0IMFVR/U8ohkb7u1pfsA4QMsHGCMYQEHiXNEGWIx04wsd5EH0YeREZOOh6ZlWBR6vbpgQc8QqOGlUroPUNSbmTGN4dCktrvbfCdU6ba21ECAoh7EMhYW9Jbo6VFPWDCohoc9YoTGieVMdOUuprGPSBnEddje1mO5eFEH4KEhEwVEX4eREX0NdWfJpJ4nqBWi6S8mEcjKvvyy+RzcA0jT6+gwOfzV4PXquZ2bM00GkdaHCcwe4bTXp5XjNHC6H0s9lLvqKWyw2/lqbdXFaiXS526klOex0LXNXazm1sKgrsiyGnNc9vtyZETHNKQfNbKRbilA7RXtMZDii5TpUCi7HrG/X4vfv/Md/XvU96EOEWIlcPQ4QaE6INwzPl91tVxu6C1VDDxLly6JvPCCqX88fNjUHc/MZBvn5Rjl+PypKa2vhcMP6xOosuY+r5WqAIqY+Qa96TIZ/R70/EO/rLGx7Gjx5qapRRoba86xsZmgYVRrfD6RT3xC5I47drxlF2NY/fMHZONX3yS+Fp+jKh/lFkCjGerkZHZkAClhSClAEfjamg5ax49rEV8hSvFQ9fbuXBSi0LWlRQeOF17QwQJNz9AUFgp/9nOI/hqIbOUTO0CaFxoovvSSDlz2PG54FSHt6veb64WIw9qaDtKIoOUSiajhMzWl+2A3UkGpqma5lLqYtvfDSCQ0YoXC4+VlU5eE1ASE+Lu6TH+FuTm9xaNR008hkzGSxKmU/kDYYmhI5Omn9ZwePmyMos1Nkw9uVzisFKRELizotbD3TEJNVCBg6uNAuU4Dp6M69uPZCxQ7X8XqA0uRPncruz2Pxa4tFqszM8ZYDARMY20RfZaKnRsnjWq7aAnqTBvVSLdcUJMpYlQq7ecnlTKtCdDA9YUXjEffPnaNjanxhDGznF42peJ0jV69xrJKQWRlbs6kP7a16bOF9hJILRsaqtygsyzTtD4YNAI+k5P5jZBqUkUx34iYlEARI8vf2qpzcUdHduN7RAgHBrLTQIkz0DBygiJPJsQYkvElyVz+vnh//fWOLoLKGVwTCU3xgkIXFpQLCyLPPacP8bFjptM5Oid3dOiEkVsflEupHir7+UB6CQwwKNphklpaMvVPuT1Ctreze3zsJnaANDfkNqOJ6+CgqUHp7ja5v3ZvDvZzZMREi3KBeg4iK7lUq9K129/gXoC3DQps6I0DrxlqhHw+U+uCiR/S6XYBhVRK7w30DBobMwsQj0cnMtQyoSFle7v+u1Dvpkro7tb0wfFxPcb2dmM8ZzJ6L+AeSyb1ui0uFlYyKnQ96hHV2UsUKzSuVvrczVSjWAXvcXu7WUAhslHo3FTTeLgSmu05sDvn8j3zEFWwN68+fNicT6Rv+/06vmUyeg7K7WVTKoXqgHC+UeNaTbTdrdfQLlufSpl+jhsbOm57PEYhcWpKr92RI+XXW8FQscuu45yg4XpuDVmlqaJwTPr9Ou/kKoyij1E4bBrMYw6DrHijo3j7BRpGTvC97+26SVC2RH703yJveb2ju1JOkeXioi5eQ6FsrwRSyxBhQbNQe7NRiBIUGywq8VBhMvv5z00HbLviWDRq8oDRh8LrNcYWQuXT03ocOJZC3qVg0Eh6p1I737MLDnR36/chDH7oUOFBeWXFGIONUunCvbCwoP8/etTUF1mWiZBBRau/3xi7MDwRfVxcNAZnOGzUga66SiOHOA/o3QSxCsiOInqzm/RoOYRCRqkrN+I5OmoWkkjdWl/X+2Jw0NRx2NnterhhAdFM5Do89pOUdzmgoeKxY/kjG/nOTbWNh6uhma4PnHOY54LB7Pmit1ejdWhbgCgCmn9DrRP94tBbxgnqmVpZ6TV0yqCCwRKJmLkFmQwvv6y/4YBbWjINSMvd90JjEPpZ2Q2UatMM4ZgMBMy8aAdqqn19mmaeSBgHh1uiePsFGkZ7nFKLLEV0sYuc13yfk07rwGxXShFRw6BUKvFQtbWZhrCWZQpnNzfNAh4e1uVl02sAxYxYkM/Pm0Gtt3fnQGNfXEBYIN/iIl8DtbExHcQvXcoumESBbzqthhP6YTRCpcuungcD027kXryor6+s6D7gfEG6dWJCtz91Sifl2VnTePTAATW0Dh/OPqdbW6YHxKFDRtkJ/ZBqfcwwjkZGTCM+pP3kWzzalQtzC8ndpq61l9hvUt7lgHMTjeaPwuc7N7VoPLxfQER8akr/b3echEI6J8ZiRi46kzEp1cgWQNS/t9dZw7AWqZWlUK6B42R00m6wWJYRPkI6PcZkpG9HIjp2o0diqfe5fQzKPf5QSO+JiYnaGShwTKbT2ccEtrdN+4+hIf3JrYkl9YGGkRPccovIX/1VadvVgVJS2CAbiQfTTiikg148biRjARa+4XB5eda7PehIdQJYwCPKBEU5uyoc+huEw9kNTCMRneDW1vTHXiNkp9TFRSHjrrtbv3d2Vr/Hrnx28KAaDfm6h4N6qDmhKez6uhGhwEIhkdD9gugFUhcgQR4KaUHyyZOmGV4mo/fF4GD+XkTr69kRPhFjrMfjGrHJ16m8WoLBnZ+Z7/p2del+JJM7UzHdqK61V9hvUt7lUO65YfStNOyOkQMHjJNmczM72pA7X25u6lgQCOg43tur578eAgXVpFaWQiUGjtPRSbvB4vHoMcfjRiIdrTMyGVN7BIGocu5zGCeTk9lzOSTo0bexVgaK3UmNY7Jn5kA0CI3Q6ymSQ7KhYeQEt9xiilUK0dNTN8OoVKUkCCvkejICAZ0MoEKEGhX0vNnY0GjB4mL1HqN84g9QguntNdEc1LiIGOUxe5fsfPULHR1mYMqdSNCjyF7vYh8s8y0ucgdJRCs6O/WzIF5gb/DaaCWg3KawUJVCF3C/X+8VNDLc2jKLsL4+U4QMQziZ1PfyydZiwTY8rOcjN5KGVMVCC7paUmjxCFnUQqmYxa6H2/Lym4l8kexaNrRtZsqVUmb0rTTyOUZCIV2A5jq+7PMllFHhIMT1qVdqUyWplaVQqYFT6+hk7jia6xjAGL28rPOR32/S5+19tMq9zyGaND+vDjHMS2jWjjYjwWDtnh3M/5g3ISSFeVbEHYqA+x0aRk7g84n83u+JfPzjhbf5vd8zT0IdKEUpqadHjR94Luy0tekg0dGhg8n0tGm+1t2tn3f+vBYx2juyl0Mh8YeVFVWmCQbV+IGSHFLqZmZ00Y5BJ5UqX4nvyhUVH0ABJLxn8BS1tZkIUCnnGSkYuee50UpAOIe5TWHRrwNpkZC7hmrd5KSZMOxKdmg8iT5K9uJXe0pQS0u2WAXU4uwGrpMUWjxi8ovF9D6yp2IWuh71LnLfq9jThODcwE93tz4n+5VyHCiMvu1OuVG1fPOlSGMcIZWkVpZCJQZOLaOTxcZRu2MAY7TXq+uT2VmdO+AIxZhb7n2+tKR/29en5w9Ou9ZWHZMiEf38S5dqN85j/kfbiqUlnRNRr2ZP8afjrXHQMHKCdFrkK18pvs2//qvIgw/W1TgS2V0qdmBADRNILouoYWJZIqdP60Bx/rwOJJ2duj2kTTc29G8ROSmXpaX84g+9vfr98/O6cIcCGnoZRSI6IF+6ZJSDYjGt+8lHrhIf1G8gv72yoj8dHToxoMu7iEnV243dRCiqUQKqdsDM1xQ2mdT3UMeFCVJEjz8QMIp1lmVy3nHOQiHTqwieRvuCDZObfd+hGFePBVuxxWMopBNtIKD3DGqS8tHIIve9Bs777Kw++6iBi0T0vFbS12uvUI4DpdpmnfuBSqNqbjhnThi+lRo4tYpO7jaO9vRkOwaCQdMkPpHQ9OvcVLNy7nMcP8oIcp12XV26BojH9d+1HOdznafILEFq+vKyfsfWFh1vjYKGkROcPZu3waud5MSsZP6//xHvLb/qisFXZKeqF4wBe3Gqx6NF+gcPqvGC0D4U4lIp/dtyu7Mjla2Q+ENnp1FyaW01OcUiuniYmDALK69XX/N41HDLzQ/OVeKDXKdlqeINJKZXVnTwtCvhra8bo61aA6Xcv6lVpCLfomtjI7ve6OWXdeBuazMpb5DWnphQIxWd4tfXddKKRnVAh6cxd8GWe75Q4FyP+7+UxWNPT/4eVHZY5F5bEJ1GeieUp3B/7OfzWY4DpdEpum6nmaNqThi+lRo4tTqPu42jGxv5HQPHjpl0/q2tyu/z3DqmXKfd0pIaKPYaZqfGecvSDBysuRYW9HsOH9Zz4PPR8VZvaBg5wfR0wbcSEtQGr9Ih6adXxHfIXd6AYqpeIjpYrKzoAnlhIbsGB2IIpUh351JM/EFEX0MkaWzMNGh95hndH3uOMFTgnn/e1D3Ziyo3N82AbPeahcOmXwWiHMvLpgC0u1u3j8d1IK5nKlWtIxX2RdfGht6yfX0mCjQ3p1Ehv1+3O3hQvzce16ggaoxwbkR0e5wjeBq7u/Ucnj+f3bTX6zXRxnpR7eKRRe61xd7XIxYzMsR4Vvfi+azEmVLKdo1O0XU7zR5Vq7XhW6mBU4vzWOo42tOT3zFgdxBWep/nO37sM4R4kD5faP8qHZdy9//KFf0+u/NXRB2Q6bTOvV1ddBTVExpGToDuljkkJChXZEQSEpQ2WZeWQ92SCrrTG5BP1UtEH+qFBWMIwRhZWdH3dvO4F1oYIOqUT/xBRF/LZPR1GGozMzpQDA5mK5+FQmbQicU0FS8Q0P2em1PDCiF0u9csEDCvw7hKJnUiQLQEogooiK1XKpVTkYpgUI/JsnQAXl7Wf584YQpRW1tVatvvF/nJT9SI6u42hs/AgFGZW1/X62P3NBbqL1GL/hvlUO3ikUXutQXP2caGOjnswhzxuD5Pra1743zWoy7Nrc063UIzR9Vyxy447CIRXW6Uew9VY+BUex7LHUfziRxVe58XO370iBodzf+51YzzuQ7OtTVdO21s6PlbW9P5E32rpqfVGTw4uDcdRW6FhpETnDmjT9WVK1mrvyXpkoQEpUvi+mTfcL0EfM2VhrO5aRrd2Y2RlhZ9wKemTHGhnd0WBhB/mJoy6mD2AWtjwxTsQzFuZUX/nRthgrQnZLsTCdOlPJ3W11HcaPcaoVYmGDSNW9fX9Vjn53X72VmNrBw75nyIHTgZqbB/NuRoL17UcyZi+jm1tZn6sauuMsIM6G0VCOgiFv+Gp21pSX+fOJE/la7e93w1k2ozp+O4EaRiJhLqvABIy11YMD0/mpl616Vx0ZSfZo+qwehIJk0fuK0tPZ5K9r9SA6fa81ircbTa+7zQ8a+s6BqhrS3/PFHNOG93cCaT+t0wsJaX9d8DAyZVcH5et+3q0nNFx1t9oGHkBD6fyKc+JXL77a9UqyclIKvSIW2yods88ECW8EIzeAOSSX1YDx9WBTcMIPDybm+rx6O/P/sYSlkYYLtUSre9ckU/JxIxgxMiPSL6f8vS77FHmNDrqL1dB/jeXv071Bmh4B/n2e41Cgaz+wvE46bPBZrFwihE2pi9fsmpa+hkpML+2TCGPB7juYIXf2pKz/eBA7o9+iCJGLGK3l7zOoxXu0GXe04aec9XWhPWzOk4pDGwLs09NHNUzT6PQumz2nTqSg2cas6jW8bRQsc/MKDvTU/r/3P7GyEVvxonpIiZe9EfEmUIiYTOu9GoEaZBqQEdb/WBhpFT3HabyMMPi3zkIyKTk5IRr6TFJy1DfSL/6wGRt7wla/NmSMPBgzwyor8XF3UQQ92I36/GzMBA9t/ttjDAojuR0EhMd7fm105M6Hk5dEjk+HEjBQ3DxufTwckuL57JmHOINDh7H4Lc85zrNYKn+uWXTaM1GEWIJLW36wQF4wiDZjS6swFuLXAyUoHPXlvT65lM6vVFDdWVK3oe0KB2eVn/bmvL1COhFgt1WZBZ34upZ82cjuM2MhnTPyu3xxUUE5s9lY51ae6kGc+1EwZ2tYZipefRLeNovuO3LJ3PEgkdm6B+l5uKXy658yEiQhMTOs61tuo5Qe+s7W3T42h721x7J+/dZnQYOAENIye57TaRd7xD5OxZ8V6eFZ8cktTNr5VAeKdEdzN4A7CI9vmMKt3SUnZqHKIMoJSFweXL+rcwqDo6jEpVPK75tYcPm+avSMeDpywQMAsrj0cf7JkZNWIsSwce+8MeDpvzbPcaLSyYyWd72/Rp8vt1IAyHVTlmasrUPKEhHTqTd3XV/ho66WHDZ58/r/+HgdnSYiJxmYweH2RFEwk1gOPx7FqsSETT7PAZezH1rNnTcdyE16vPLDra2+Vyo1HzPDfT/ZHLXnQOkPrjtIFd70Ww28ZR+/HDUXvihJHxzpeKXy72+TCT0fkcJQnIRPF49FwsLprtQyHdh85O5wxG9ubLhoaR0/h8IrfcIkER6fhF/UwgTx+cZkjDsS/Qu7rUYOnqKt6tfreFQSZjJLHz0dqqg0I8roaLPR3P59OGsKurupBCX6OVFePpQVganmg0g7UX/sNDtbxsjDKfT40FqOShkdz4uH7f0JDul2WZmoiJCROhqjVOetjsktyplF6v6Wk9j11demyTk3ruYPTCexWN6nVfWVFj2e6xdEvKRK1p5nQcN2G/P3Llcust5+4Ue9E5QOrPXjSw3TiO5tbcFuq9V4kBah/v8Bmjoxo1isd1PYFay9VVvaadnTrndndXJrJRCuzNtxMaRnXELeHjasg9hkCg+DHstjDY2tLfGGRWVnRRPjtr3hPR19rbdXDA53R0qFfnxRfVaEI+8PCwSQUbG8tOz+nr0/3MTTtYWlIjB4KC9jS8jQ01mrq6jMEVi5mBMpUyDW/9fmfSYpz0sAUCel4yGT1vc3P6e3jY9HGIx01JHAQq4Enb3FSjCD2w7OyFe74QjZ7E9wK590coZCblZr8/RPauc4DUl71sYLvp3s9ngNr3z7KqM0DhgJ2a0vVCOKxrlGRSr2s6rdt1dIicOqVG0dCQZsw4BWsgd0LDqI64LXxcCeUew24Lg81NfT+VUmPohRfUCPL7dbHu8ej/X3pJB5CNDf0eRHCwTxsbOnjgs555xkSj0IQ2GtW/gxoWDBh7PxWk8tiFGBC1Cod1wBwaUg+Lz6d/i8+ORo13yalz74SHDSlNEJBAw1ukbaRSpth3a8so50ButL8/v1GEfW72e544x364P/ayc4DUBxrY+XFiLnTSAA2FdP0wN6dG0OqqOh9PnjSquH6/yb7p7CzY/aUmsAYyPzSM6owbw8flUu4xFFsYRCL6eRcu6CIbAzx6Ec3N6aK8o8MUIMbj+ntwUL0v6bT+TXu7/p1lmX5Era1qYNn3MdfrgwanvxAQfEVMIRzW71lfN6IK6bTu58iIfqdl6d+FQvq7Hl67Wt8v9kk3FDLS22BjQwUVOjt1m5kZ0wBvaKh0BaOVFb2Gfr8paCVkL4yJxdgPxh9xHsyjs7Mmau/1usvArtcz7FRNTD0MUESBRIzTFoIPa2tGWMqePufUed2LKZq1gIZRg9gLE3+px7DbwmBqSg2leFwfQHgvYJB0dBi5Skhwb25q3QuUY6D77/WaH7/fKLrYU9zsXh80UUNxYzhsGkwivLyyogMlxAe8Xn19c9Okk6Gnz8GDzXltMemurOhxoImtXY0PinOBgEbv0Gh3N/JNYmtrXBSSbJrxuSmVvW78kfrg8eg4OjWl/+/o0DoVKLY2inoU7+PZ2draWW9cy5oYpyO8duOro0OPy7JMvyL0pconOFXr87qXUzSrgYYRqQuFFgbJpD58Bw7ow7+2Zhqy+ny6APd6jecindZBC7UwiYSpB0qn9Xva23V7FDQmk8agaW/X/Rkc1O+HAs3wsEmbg5hCPK7f1d6u6WKDgzooX7kiculStpTnyoqpt0kkmm/BD+M1HNbrMDlpInX9/eZ41tdN9KgUWNhZHVxI7y14DUkl2MfRAweMgbC5mS0k1Oh9c2KMzzW60Pj54EFnmqzXI8KLWqPz5834jt8DAxopqsfcyRTN/NAwInUl9wFDKDcSMXLd2MbnMz2E2tr0/ysrJiKEQSIQ0EFjc1MHCjRmnZ42ubrt7TrAQDnuyJHs/Fqkzdn7qbS0qOF05IgJaYfDKqUZCun+JBK6L729pvlbsxYrwhsGKe54XI8NnjMYnuV4zFjYWRmUTyWEgHzjaChkhIAaOY46OcbnGgfIHEmnNaV7cDB7PKxVTUw9IryFDFq8Xq+5kzWQO6FhRBoKQrlerz6A6B2E/GmIG4io8WFZ2SlxnZ3609urRtPmptYUvfyyvn/0qD7oa2v6OWNj+llIEUN+rcdjapbs/VSghIfBFxGuw4d1X3IHzVxhh2YCk1A6rQ1119b0fExOqkF41VXlpWywsLMyGGUjhAA3j6NO71uucbC5qeuFzk6d75eXdd4Gta6Jcep8Li3p7xMn8rcpmJ5W5249rjlrIHdCw4g0FHsoFwbOlSu6EPT7NV0OQgi9vUa5BaIMQ0NGmtvv18W836+DZjgscuiQfod94Nna0u3b27Pza0Oh7L4F29u6j3YhAnuxosez83iauVhxaUnPWyRijE4szFdW9PyUM0iysLMyGGUjhAA3j6NO7ls+owvZItvbRi3Wbhw0Q01M7nHlGjZtbZqtYVkm9T+XWl9z1kBmQ8OINByEcjc39eEMBjXlLR43RsvYmNa2XLpkPOdbW7oNFo2plA44gYAu7iMRHUByH3AMKi0txfNrNzY0vc/+924tVqx2QIvHVRJ9bk7P4fa2aeDa01OZh8qt58rNuNk7TJyFixL30shr4+Zx1Ml9K9RTCG00IhFdB9iNg2aoiSnFmITabb2vuZvPWz1xzDCKxWJy9913y6OPPioiIm9/+9vlM5/5jHQWqdp+5JFH5Atf+II8+eSTsri4KOfOnZPTp087tYv1IZ0WOXtWY6NDQyJnzphOmUREdoZyOzvVYLnmGvUKWZYaQcvLmlfc2qrbowYmkdDBIxo1tUrz8/rZ+QYO+6Biz69FxAnpdOGwfqZdTMFtxYq1qEVJJLTv0+OPm/osNMEdGjKiEq2t5Xmo3HaumgE3e4eJM7CezL244dq4eRx1ct8KGV2dnXpdFhf1fY9H56xmqYkpxZgMh/W99fX8KfucO53FMcPo3e9+t0xOTsq3vvUtERH54Ac/KHfeead84xvfKPg36+vrcvPNN8tv//Zvy1133eXUrtWPRx4R+chHtEgDjI6KfOpTIrfd1rj9qgKnPGe7hXKTSU2xGx01RtDmpi7ko1GjaHf0qKbcLS7q3+Xbx9xBZWRERRZeesnUdYyO6u/NTf1ee12HW4oVa1WLcvGiyM9/rgsApBNubWn63Esv6Wd7PLowKNdD5ZZz1Sy42TtMag/rydyLm66Nm8dRp/atkNGFOWp83AggNVNNTKnGZGur+tMvXtS/Qbo/VHM5dzqHI4bRc889J9/61rfk8ccfl+uvv15ERP7xH/9RbrzxRjl//rycOHEi79/deeedIiJy6dIlJ3arvjzyiMjtt++UHrlyRV9/+OGmMo7q5TkrZmylUhrBmJoSef553Y/5eZW8tCz1srS36yDd2WlqMnYbrFE709enESe7UZZM6nF7vSq4gO3dUKxYi1qUZFLkuef0XPb06DlCHVcoZAbmU6cqOy63nKtmwc3eYVJ7WE/mXtx0bdw8jjq5b4WMrs1NlS3v7dXr0Wzpp/mOa23NZKq0thr1274+naeRZt3drUq5nDudwxHD6Ec/+pFEo9FXjCIRkRtuuEGi0aj88Ic/LGgYVUIymZRkMvnK/1dWVmr22RWTTmukKJ8eI5JH77lH5B3vaIq0Ojd4zmIx9RBtb2vn73hcT93WlhFBsCxzygMB3a+Njd0Haww4XV1mMZpIZHeiRmoeFOoaXaxYq1qU5WU9NhiK6BEVDBrjd2pKVerQaDd3P3Y7/kafq2bDzd5hUjtYT+Ze3Hht0GAbYkClNtgulWrGZ6fGeDcbhNVgP66FBWOEIyJ04YJuB8U9+3nd2NCfUnsJkvJxxDCamZmR/v7+Ha/39/fLzMxMTb/rwQcflAceeKCmn1k1Z89mp8/lYlmqLnD2rMgtt9RttyqlkZ4zdH5+9lmRy5d1cGhpUW/R9LT++9prdcBYWNDB8qqrdL82NkobrHPrOhIJrWVKJnUSam01x5nJZBuCjVqw1KoWxf45uKaJhGmcm07rawjtI4WrkggiF3elsVcXAyQb1pO5F7ddGyczNmr52U6M8XvVsQYn1/Kynu+hIc14WVvTtU5Hhxo/oVD28Xo8dJg4TVmZ6vfff794PJ6iP0888YSIiHjyaBlblpX39Wr46Ec/KvF4/JWfiYmJmn5+RUxP13a7BlKO56zWIFI1Pq6L89FR/Z7tbTWCPB4dNPDa0JDZ51yPXjHvmr2uQ0SV2SD33dKik0UwqIMYJpFGk7vPuZRai9LWpumDGxt6vJmMHmdvr4bwg0FdpAcCOlAHg+a6xGL6/2jU9F9AZJFUBxYDhw5pCuehQ+X1kCLup1bPMKk9bro2To63zTSW7zaPNyNLS+onHxrS+dXjURGo9nZddywv7/wbrEnoMHGOsiJGH/7wh+Vd73pX0W0OHTokTz/9tMzOzu54b35+XgYGBsrbw10IBoMSdNuTghV6rbZrII3ynCWTGilaWNAJqLVVF+fBoA4cGxuaRtfTo4bM6Kgu6Le2dF9CodL3C3UdMzP69y+9pN+5sWEMQhgJbvHW1KoWJRJRwYqf/Uz/DaMzENBj3dzUcH5vr0nhclPu/V7HbUMbqR2sJ3Mvbro2To63HMsbRyGnM3o1QSUXTmdEyzweOkycpizDqLe3V3p7e3fd7sYbb5R4PC4/+clP5LrrrhMRkR//+McSj8flpptuqmxPm4kzZ3SlfuVK/jojj0ffP3Om/vtWJvVWyUJEZnFRw8kej0mJC4V0gZ5Mmh5GoZAaTb29Zj+8XrNfa2u6uPf7deFfiNZW9c4sLOj/o1H9jqkpHbgOHNDX3ZTeUqtalFOntM7opZf03G5uGk/hoUMir361SR90Y+49Ic0K68ncixuujZPjLcfyxlLI6YxeTcvL6qicntbfMIzSaZGDB3lNnMSRGqNTp07Jm970JrnrrrvkC1/4goioXPdb3/rWLOGFkydPyoMPPii/9Vu/JSIiS0tLcvnyZZmamhIRkfPnz4uIyODgoAyiCq0Z8PlUkvv223VlbzeOkEr4yU82hfBCPT1ndpGHlhY1Vnw+XbRPTenivLNTjZ2uLpNr3N2t/47F9P1gUNPv4nGR//N/TFHj4cOq5pKvaBHFjK2taiDE4/o58JZtbqqx5Kb0llrVooRCaqejV9T2tt6yiCYdPmw+y22594Q0M6wncy9uuDZOjrccyxtLMadzZ6c6aS9d0jUI4hErK6avoL2/IqktjvUxeuihh+Tuu++WW2+9VUS0wetnP/vZrG3Onz8v8Xj8lf8/+uij8r73ve+V/yNt77777pP777/fqV11httuU0nufH2MPvnJppLqrpfnzB7WX1nR7/D7tWHr9LS+Fo2qB2t93XS+np7WfQuFdEE/P68DysaGCTun02osTUyIvO512caRXQYTA9TyspH8TqVMSHtjw13pLbUoTF1a0r+56SY9D9vbet5hENvTKdhnh5DasleLy/cCjb42To63HMsbSzGncyhk6n0jEV0Xeb1qIHV26rqHaY7O4bGsfLlezcvKyopEo1GJx+MSKZY7VS/SaVWfm57WmqIzZ5oiUpSL032Mkkk1ZixLjY+1Na0dWl/X71hb04jGkSP63Zcuma7QHo8aTNGoLuh/9jPtvTM2pjVIwaB+fjyuf3PmTLYY4Oambh+N6mflqtL5fDp4dXfroLSXmi7ivKOBXC5bW7rNoUNmQXDxot4L3d07FwmxmBqOHLAJIaR6pqbMuJpLteNtrT+bxn15FGuFMj+vKfzB4M5zmm9eJsUpxzZwLGJEfoHP1xSS3LvhtOcskzH6/FtbapAMD6s9ubBgRBdWV3Xg6O3V9wMBo2GRyajhs76up72tTVVsRPR3OKxRo6ef1roZPBu5njN01rb3MUqn1RBAH6O9QjnpFHbjeH5er01fn6nvYl0EIYTUFiczNmr12fVqAL/XKJSuibUJlOpyYZqjs9AwImXhlHfC69WBIZEw+bQtLWr8tLWpV6WlRdPqOjtNCDo30rGwoK8PDuqAHwjo33k8+ru3VzMbl5bM4JMvpA3jKJk00ZHDh5059kZSajrF1pae20RCz1tbm/5/fl4NyKEho1zHiZAQQmqDk7VOtfhsNzSArxaIDonUXxI8n9NZRDM5mObYGGgYEVcTDIr09+ughcaufX36/4WFnZEOJIZub+tAv7VlDKNwOL/3RaSw5wyiDE2grF4RpYprrK/vlHUdG9Nrs7Skn8H0udrCtBRCiIizGRvVfnYzS36jgfzkpK4XRHQuGx2tf9+43HPuFrn4/QgNI+IKMhkdCHw+rQVqbdXUufV1kdlZI1c5NaUGS1tb/khHZ6dKXY6Pa81QZ6caROm0+ayRkZ0pAm5QIGoUu6VTtLVpzVU+WddgUOu4kknKutYKpqUQQvLh5PhayWc3s+R3IiFy4YKuFXw+ncdEVOTphRd0Tjx6tHFjrhvk4vcrNIyIK/B61RhqbdUHf21NDaTFRR0Q+vvVUAqFTIi+pUW3tRtGkYgaOC+9pP/2ejWKtL2t2yaTGnXKV3tXzHO2l733uxmFlkVZ13qxF9JSCCH7g2aW/F5aUkdpKKROVNDbq2uPubnGCgntZ2dto6FhRFyBPaULtT3T07oo7+vTgaqjQ39EdLtw2BhKWESurekg90u/pANJLKbGTCajg8q112pztGIeLPvr+8V7v5tRSFnX+tDMaSmEkPrhBmdds0p+J5PqdM1kNMMkl9ZWXUssLhpl20bQaLn4/QoNI+Ia7KFjv1+jPG1tptmqvfdQW5sOFoODGgmCRyWV0tdOnFCPz+XLxgg6cEDrYkRK82DtR+99vkG3nk1+9zPNnJZCCKkPbnLW1XNuqKVxkMnoXO716lojF79f30ul3BHt4nhfX2gYEddgDx1D7Qz9iTo7swd9hOgDAdP0FYNdKKQDycCA6vzbG5ZC/78UDxa99wbmOztPM6elEEKcJ9dZl8nonDY72zhnndNzgxOGoNer+5nJ6Pogd8xFTXNLi/uiXcR5aBgRV4HQMcLboZBJn7OTG6KHRyUc1hA4PFi5f1uqB4ve+2yY7+w8zZqWQgipD3DWhcP677U1E0VZXlbV1SNH6rtPTs4NTmVtQDRoYUH3115jJKKveb2NTaMjjYOGEXElkYjWFsVi+UPoxQycWniw6L3fCfOdnYUpi4SQQsBZ5/erSmgyadRbt7c15fyll3Qxn7vQdxqn5gYnsza6uzWrZHxc1wcQZFpZ0WMYG2MmxH6FhhFxLa2t2uTs4kXTyDUUUqMkGi08aNXCg0XvfWG4MHcOpiwSQvIBZ93mphogduOnpUUNoitXVDCg3oYRqOXc4HTWRiik0bVQSPsYLS7q643qY0TcAw0j4koSCR2oQiH15CQSmjawuqqLQwxohajWg1Wq915EJypGT0gtYMoiISQfXq8aRsvL+ZXUIFaEthTNPh/VI2sDxtHIiM7jIpqm2OznjlQHDSPiSpaWNDXADmqGAgEdEO0qdYWoZoAr5r33eNRYu3Sp8cpAZG/BlEVCSC7BoJGRzjf3YU70+fZGinc9szaCQY6xxEDDiBSlEYuzZFKLIldX9btbW9Uw2d7WwT+Z1LzqUgsjKz2GQt77cFgNps3N/SPjTeoPJ2pCiJ3eXp1/kC6H+qKNDR0v2trUabcXUrxZc0kaBQ0jkpdG9krIZPS7Mxn1gNkltqNR7U+USGhfomKDYi2OIZ/3fnFRDSDKeBNCCKkX0ajIVVepYEAyadK40dIC89JeMRZYc0kaAQ0jsoNGNzZNpfS7W1rUCIrHTV8Bj0ff39rSiNHwcH5Dp9bHgImGMt6EEEIaxfCwiGWpehp69nm9e9NYYM0laQQ0jMgOGt3YFE3VxseNQbS9rd+NYsz+fv13ocZ2Th0DZbwJIYQ0ChgL4bAaC4nE3jYWWHNJ6g0NI5KFGyIiXq8aQgsLmkPd2anRHkR8lpfVsPF6dTJobc1ubOfkMVDGmxBCSCPZj8bCXj8+4h5oGJEs3BIRSSRUkrSzU1Pp5uZMrZDfr0ZJV5dODCsrakihsZ2Tx8CCUEIIIW6A8wwhtYd+bZKFPSKSj3pERFBQ2t+vRgwMDb/fpBG0tGiedXe3Rozm502DNqePAekKsZjWOlmW/o7F9l6ONyGEEELIfoGGEckCEZH19fzvr6/r+057qlpaRPr6tLnr9rZGi1IpjQhBphQEAmrkLC2Z9DgnjwHGGSJW8bj+7uqiVDchhBBCSLPCVDqyg0ZLZIbDargkEmocBYOaSre0pOlyKysaJUIq29aW/t/rNelxTh/DfszxJoQQQgjZyzBiRHbQ6IhIMCgyOqp1QvG4pr319envmRkj1e3xqJHk82k9EtTs6nkMwaAacjSKCCGEEEKaG0aMSF4aHREZHtaI0eysGkKhkBogaGAXCunrkYhuHwiosWTfx0YfAyGEEEIIaR5oGJGiNMqQCIVUfruzU0UVWlu1rmh9Xf/d3a0RIxg9/f2F0+NoDBFCCCGEkN2gYURcCyI+PT1q/GxtqZE0OaliDCJaizQ6qtvVOsWPkSZCCCGEkP0DDSPiemCUhMOqSDcyoil1eK3WRksiITI+ro1kPR79zo6OvdlVnBBCCCGEKDSMSNMRDDoXwZmZEfnxj/W316uGV2enRq02NynHTQghhBCyV6FhRMgvWF4W+f73VfBhbEyNr2RSm8dubOg24bCm7RFCCCGEkL0F5bpJU5FMauQmmaz9Zz//vMjCgsjhwyoBvrWlv4eHVfRhcVFrm5z4bkIIIYQQ0lgYMSJNQSKhDV5XV7W/kc9X27qflRWNFIVCGjlKJIzwQjisSnjLy9oPCU1kCSGEkHpCUSBCnIWGEXE9iYTIlSv6u61NG7mmUiKxWO3qfra3NV1uc1O/JxBQefBMRqNFfr++blmmiSwhhBBSD5x2DhJCFBpGxPUsLemk0NVlXgsE9CcW0/errfvx+3WySST0t9ebHTFaXVVjrLOTXjpCCCH1ox7OQUKIQt83cTXJpBolbW35329rq03dTzCoxtHqqtYWJZNqePl8mkI3Pq4Tz+Bgdd9DCCGElIPdORgIaBuJQED/j0gSIaQ20DAiriaT0QhOS0v+91ta9P1q634yGTWy2tv1M0Mh9citramxFI2qUl0gUN33EEIIIaVSL+cgIURhKh1xNV6vRm1SqfxGSSql71db95NKqUH0S7+k3jd46Fpb1SAaGFAvXSqlqXWEEEKI05TiHNzYoCgQIbWChhFxNcGgFpjGYvkNo/V1TSeotu4HUaJMRuTUKY0UocC1vV3T6bzewpMTIYQQUmvq5RwkhCh8lIjrgepOLKb1P5alv2dn9f1CKQbl4PXq9/h8Ksnt8ejrW1va4NXn0/c5+RBCCKkXcA6ur+d/f31d36coECG1gREjp0mnRc6eFZmeFhkaEjlzRlfZpGQ8HjV+trY0l3p7W3+L6IQwM6OTQzWypcGgSG+vfs78vIotrK0Zg2lgQFPqOPkQQgipJ93dqj4Xi2Wr0q2v65zX3d3oPSRk70DDyEkeeUTkIx8RmZw0r42OinzqUyK33da4/WoSEgmRqSk9fTCEPB41Vjo7VSGulrKlra0aLZqa0slncFBT61ZWRBYWTONXyqISQgipF6GQzm3oY7Sxof7Vri72MSKk1tAwcopHHhG5/XbN+7Jz5Yq+/vDDNI6KkEiIXLigkRufT6SnR1+/cEEnhmBQjRbIltaip9HGhv7u7TV9jFpaRA4c0Nfj8dr0TCKEEELKIRTSuSeZND32mMFASO1hxYQTpNMaKco1ikTMa/fco9uRvCwtaQ1RKKSGCopOQyGRSMREcOxUI1uaTIosLqohNDamExB++vo0QpXJ6DaURSWEENIIgkFVRqVRRIgz0DBygrNns9PncrEskYkJ3Y7sAEZKJqPpbSCT0fdaWvR3LJZtpFTT0yiT0ZQ8r1cbvQYCJmq0taWveb26DWVRCSGEEEL2Hkylc4Lp6dput8/INVJE1ABaWNAfGCgej+pZwHNWjWwppLgzGS1o3dzU30hZCAT0s5FmRwghhBBC9hZc4jnB0FBtt9tn2I2U7W01iubmNHITiWjAze/XOqS5Of0tUp1saTCodUyplMjlyyq4EAhoD6NAQJXqFhc1XY8pDIQQQgghew8aRk5w5oyqz6EZTi4ejxaynDlT3/1qEmCkeL0qiBCPq8HS0aEKPOhjNDCgxtP8vKbVVStb2t2t3722pgaZZen3rq6qodbRUbtjJIQQQggh7oKGkRP4fCrJLbLTOML/P/lJ9jMqAnoHra6qkJ/Xq8bQ2ppGcdBTKJ1Wo6i1tTqpbhG9ND09IldfbVTuYjH9nqNHRU6eVEOJ4guEEEIIIXsP1hg5xW23qSR3vj5Gn/wkpbp3IRQSOXJE/728rAaSx6NG0aFDajR5PGoYra1pz6FqezlkMpqid/SoGl6bm/odoZAaR5al0SuKLxBCCCGE7D1oGDnJbbeJvOMdqj43Pa01RWfOMFJUIqGQGilQmgsEjJECtrZUurQWggher16aVEq/I7eWqBpxB0IIIYQQ4m5oGDmNzydyyy2N3oumBfVGsZhINKppbJubprnd+rp2/66FIEIwqHVEsZjpm2Snlt/lVtg8kBBCCCH7FRpGxPV0d2s63fnzZtGO3wMD1Qku5PuuzU01jtraVHQhlVKjqFpxBzeTSGhT3dVVjdD5fEbsotoURUIIIYSQZoCGEWkKLKu81yslFFIRBxgJGxtqJHR17V0jIZFQgYtEItsYjMXUSKxW1IIQQggh5cMsjvpDw4i4nqUl/X3ixM5BIhbT94eHa/d9oZB+3n4ZkJaW1Cjq6jKvBQJGma/W55cQQgghhWEWR+OgYURcTTKpA0Nbm/4/10Bpa9P3k8naGy972RgCuec3FyfPLyGEEEKyYRZHY6G+FnE1mYx6S1pa8r/f0mJU60j58PwSQggh7sGexREIaNuQQED/j0gScQ4aRsTV2CW0RYwqHZqsUkK7OnLPby48v4QQQkh9KCeLgzgDU+mIq4GE9syM/n9tTT0mqZQOEKGQyIEDTPOqFEqUE0IIIe6glCyOjQ1mcTgJDSPielpbRebmRBYXTcRoeVmNpM5Okde/3pmCxPl5bSAbCIj09dX2s93EfpUoJ4QQQtyEPYsjn7OSWRzOQ8OIuJpEQuTCBTWMXn5ZZGJCB4TWVl3Ex2Iijz2mi/hf/mU1lKplZkbkqaf0u2AYjY2JnD4tMjhY/ee7jf0oUU4IIYS4DWZxNB4aRsS1wCi6dEkHA8sSGRoyYeRQSCQc1rDziy/qQPHqV1e3kJ+ZEfnOdzQiNTioxtf6un7+/LzIG9+4d42j/SRRTgghhLgRZnE0FgbjiGtZWjJCC2trOkAEgxotam8X8ft1EZ/JqIE0OysyPV3ddz71lBpFx4+LRCIaOYlE9P/Ly/r+XiYY1HNJo4gQQgipP8ji6OrS9U88rr+7uijVXQ8YMSKuBMosgYAaRx6PRoaQ2iaiEaXWVmMctbSIrKxU3nNnfl7T5wpFhAYH9f35+b1dc0QIIYSQxsEsjsbBiBFxJVBmCYf1x/6az6fRIsvS/3u9+hMK6WuVqrVsbelPMZlMbEMIIYQQ4iTM4qg/NIyIK4EySzot0tur6WyJhEaP0mmjTuf1agTJ59OCxXC4crWWQEB/1tfzv7++brYhhBBCCCF7CxpGxJVAmWV7W6SnR0UXxsY0IjQ1pSlzHR1m26EhTaXr6Kjcs9LXp9+Bnkm5zMzo+0yjI4QQQgjZe7DGiLgWKLMkkxoxamnRn/PnjTJdNCpy4oT+jkarV2s5fVpriF54IVuVbmZGpcBPn67BgRFCCCGEENfhWMQoFovJnXfeKdFoVKLRqNx5552yvLxccPtUKiV/9md/Jtdcc420tbXJ8PCwvOc975GpqSmndrE+pNMi3/ueyFe+or/T6UbvUdMAZZbBQVVjQTHimTMiv/ZrIjfcIPIrv6JRnMHB2qi1DA6qJPexY6pCd/Gi/j52bO9KdRNCCCGEEBGPZVmWEx/85je/WSYnJ+Uf/uEfRETkgx/8oBw6dEi+8Y1v5N0+Ho/L7bffLnfddZdce+21EovF5J577pHt7W154oknSv7elZUViUajEo/HJRKJ1ORYKuaRR0Q+8hGRyUnz2uioyKc+JXLbbY3bryYEyiyplEaNUEfkpFrL/LxRwWP6HCGEEEJI81GObeCIYfTcc8/J1VdfLY8//rhcf/31IiLy+OOPy4033ijPP/+8nDhxoqTP+elPfyrXXXedjI+Py4EDB0r6G9cYRo88InL77VoUY8fj0d8PP0zjiBBCCCGEEAcpxzZwJJXuRz/6kUSj0VeMIhGRG264QaLRqPzwhz8s+XPi8bh4PB7p7OwsuE0ymZSVlZWsn4aTTmukKJ/NidfuuYdpdYQQQgghhLgERwyjmZkZ6e/v3/F6f3+/zBSS/MohkUjIvffeK+9+97uLWncPPvjgK3VM0WhUxsbGKt7vmnH2bHb6XC6WpZ1Cz56t3z4RQgghhBBCClKWYXT//feLx+Mp+oN6IA9SxmxYlpX39VxSqZS8613vkkwmI5///OeLbvvRj35U4vH4Kz8TExPlHJIzTE/XdjtCCCGEEEKIo5Ql1/3hD39Y3vWudxXd5tChQ/L000/L7Ozsjvfm5+dlYGCg6N+nUim544475OLFi/Lf//3fu+YCBoNBCbqtJfDQUG23I4QQQgghhDhKWYZRb2+v9Pb27rrdjTfeKPF4XH7yk5/IddddJyIiP/7xjyUej8tNN91U8O9gFL344ovy3e9+V3p6esrZPfdw5oyqz125kr/OyOPR98+cqf++EUIIIYQQQnbgSI3RqVOn5E1vepPcdddd8vjjj8vjjz8ud911l7z1rW/NUqQ7efKkfP3rXxcRke3tbbn99tvliSeekIceekjS6bTMzMzIzMyMbG1tObGbzuHzqSS3iFGhA/j/Jz+p2xFCCCGEEEIajmMNXh966CG55ppr5NZbb5Vbb71VXvWqV8m//Mu/ZG1z/vx5icfjIiIyOTkpjz76qExOTsrp06dlaGjolZ9ylOxcw223qST3yEj266OjlOomhBBCCCHEZTjW4LVRuKaPEUinVX1uelpris6cYaSIEEIIIYSQOlCObVBWjRGpAJ9P5JZbGr0XhBBCCCGEkCI4lkpHCCGEEEIIIc0CDSNCCCGEEELIvoeGESGEEEIIIWTfQ8OIEEIIIYQQsu+hYUQIIYQQQgjZ99AwIoQQQgghhOx7aBgRQgghhBBC9j00jAghhBBCCCH7HhpGhBBCCCGEkH0PDSNCCCGEEELIvoeGESGEEEIIIWTfQ8OIEEIIIYQQsu+hYUQIIYQQQgjZ99AwIoQQQgghhOx7aBgRQgghhBBC9j00jAghhBBCCCH7HhpGhBBCCCGEkH0PDSNCCCGEEELIvoeGESGEEEIIIWTfQ8OIEEIIIYQQsu+hYUQIIYQQQgjZ99AwIoQQQgghhOx7aBgRQgghhBBC9j00jAghhBBCCCH7HhpGhBBCCCGEkH0PDSNCCCGEEELIvoeGESGEEEIIIWTfQ8OIEEIIIYQQsu+hYUQIIYQQQgjZ9/gbvQO1xrIsERFZWVlp8J4QQgghhBBCGglsAtgIxdhzhtHq6qqIiIyNjTV4TwghhBBCCCFuYHV1VaLRaNFtPFYp5lMTkclkZGpqSjo6OsTj8TR6d2RlZUXGxsZkYmJCIpFIo3eHNAG8Z0i58J4h5cD7hZQL7xlSLm66ZyzLktXVVRkeHhavt3gV0Z6LGHm9XhkdHW30buwgEok0/MYgzQXvGVIuvGdIOfB+IeXCe4aUi1vumd0iRYDiC4QQQgghhJB9Dw0jQgghhBBCyL6HhpHDBINBue+++yQYDDZ6V0iTwHuGlAvvGVIOvF9IufCeIeXSrPfMnhNfIIQQQgghhJByYcSIEEIIIYQQsu+hYUQIIYQQQgjZ99AwIoQQQgghhOx7aBgRQgghhBBC9j00jAghhBBCCCH7HhpGNeDzn/+8HD58WEKhkLzmNa+Rs2fPFt3+sccek9e85jUSCoXkyJEj8vd///d12lPiBsq5Xx555E42BzoAAAdWSURBVBF54xvfKH19fRKJROTGG2+U//zP/6zj3hI3UO4YA/7nf/5H/H6/nD592tkdJK6j3HsmmUzKxz72MTl48KAEg0E5evSo/NM//VOd9pa4gXLvmYceekiuvfZaaW1tlaGhIXnf+94ni4uLddpb0mi+//3vy9ve9jYZHh4Wj8cj//7v/77r3zTD+peGUZV89atflXvuuUc+9rGPyblz5+TMmTPy5je/WS5fvpx3+4sXL8pb3vIWOXPmjJw7d07+/M//XO6++275t3/7tzrvOWkE5d4v3//+9+WNb3yjfPOb35Qnn3xSXv/618vb3vY2OXfuXJ33nDSKcu8ZEI/H5T3veY/8+q//ep32lLiFSu6ZO+64Q/7rv/5LvvjFL8r58+flK1/5ipw8ebKOe00aSbn3zA9+8AN5z3veI+9///vlmWeeka997Wvy05/+VD7wgQ/Uec9Jo1hfX5drr71WPvvZz5a0fdOsfy1SFdddd531oQ99KOu1kydPWvfee2/e7f/0T//UOnnyZNZrv//7v2/dcMMNju0jcQ/l3i/5uPrqq60HHnig1rtGXEql98w73/lO6y/+4i+s++67z7r22msd3EPiNsq9Z/7jP/7Dikaj1uLiYj12j7iQcu+Zj3/849aRI0eyXvv0pz9tjY6OOraPxL2IiPX1r3+96DbNsv5lxKgKtra25Mknn5Rbb7016/Vbb71VfvjDH+b9mx/96Ec7tv+N3/gNeeKJJySVSjm2r6TxVHK/5JLJZGR1dVW6u7ud2EXiMiq9Z770pS/Jyy+/LPfdd5/Tu0hcRiX3zKOPPiqvfe1r5W/+5m9kZGREjh8/Ln/8x38sm5ub9dhl0mAquWduuukmmZyclG9+85tiWZbMzs7Kww8/LL/5m79Zj10mTUizrH/9jd6BZmZhYUHS6bQMDAxkvT4wMCAzMzN5/2ZmZibv9tvb27KwsCBDQ0OO7S9pLJXcL7n87d/+rayvr8sdd9zhxC4Sl1HJPfPiiy/KvffeK2fPnhW/n0P8fqOSe+bChQvygx/8QEKhkHz961+XhYUF+YM/+ANZWlpindE+oJJ75qabbpKHHnpI3vnOd0oikZDt7W15+9vfLp/5zGfqscukCWmW9S8jRjXA4/Fk/d+yrB2v7bZ9vtfJ3qTc+wV85Stfkfvvv1+++tWvSn9/v1O7R1xIqfdMOp2Wd7/73fLAAw/I8ePH67V7xIWUM85kMhnxeDzy0EMPyXXXXSdvectb5BOf+IT88z//M6NG+4hy7plnn31W7r77bvnLv/xLefLJJ+Vb3/qWXLx4UT70oQ/VY1dJk9IM61+6E6ugt7dXfD7fDo/K3NzcDqsYDA4O5t3e7/dLT0+PY/tKGk8l9wv46le/Ku9///vla1/7mrzhDW9wcjeJiyj3nlldXZUnnnhCzp07Jx/+8IdFRBe9lmWJ3++Xb3/72/Jrv/Zrddl30hgqGWeGhoZkZGREotHoK6+dOnVKLMuSyclJOXbsmKP7TBpLJffMgw8+KDfffLP8yZ/8iYiIvOpVr5K2tjY5c+aM/NVf/ZVrvP/EPTTL+pcRoyoIBALymte8Rr7zne9kvf6d73xHbrrpprx/c+ONN+7Y/tvf/ra89rWvlZaWFsf2lTSeSu4XEY0U/e7v/q58+ctfZv72PqPceyYSicjPf/5zeeqpp175+dCHPiQnTpyQp556Sq6//vp67TppEJWMMzfffLNMTU3J2traK6+98MIL4vV6ZXR01NH9JY2nkntmY2NDvN7sJaTP5xMREwUgxE7TrH8bJPqwZ/jXf/1Xq6WlxfriF79oPfvss9Y999xjtbW1WZcuXbIsy7Luvfde684773xl+wsXLlitra3WH/7hH1rPPvus9cUvftFqaWmxHn744UYdAqkj5d4vX/7yly2/32997nOfs6anp1/5WV5ebtQhkDpT7j2TC1Xp9h/l3jOrq6vW6Oiodfvtt1vPPPOM9dhjj1nHjh2zPvCBDzTqEEidKfee+dKXvmT5/X7r85//vPXyyy9bP/jBD6zXvva11nXXXdeoQyB1ZnV11Tp37px17tw5S0SsT3ziE9a5c+es8fFxy7Kad/1Lw6gGfO5zn7MOHjxoBQIB69WvfrX12GOPvfLee9/7Xut1r3td1vbf+973rF/+5V+2AoGAdejQIevv/u7v6rzHpJGUc7+87nWvs0Rkx8973/ve+u84aRjljjF2aBjtT8q9Z5577jnrDW94gxUOh63R0VHrj/7oj6yNjY067zVpJOXeM5/+9Ketq6++2gqHw9bQ0JD1O7/zO9bk5GSd95o0iu9+97tF1yfNuv71WBZjnoQQQgghhJD9DWuMCCGEEEIIIfseGkaEEEIIIYSQfQ8NI0IIIYQQQsi+h4YRIYQQQgghZN9Dw4gQQgghhBCy76FhRAghhBBCCNn30DAihBBCCCGE7HtoGBFCCCGEEEL2PTSMCCGEEEIIIfseGkaEEEIIIYSQfQ8NI0IIIYQQQsi+5/8HnMSLNPsZskoAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\"\"\"clean the outlier\"\"\"\n",
    "comparison = comparison[comparison['cum_y_val_prediction'] < 0.25]\n",
    "comparison = comparison[comparison['cum_y_val_prediction'] > -0.25]\n",
    "x = np.linspace(0, 1, len(comparison))\n",
    "\"\"\"compute the R^2 between the prediction and the true value\"\"\"\n",
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(comparison['cum_y_val_true'], comparison['cum_y_val_prediction']))\n",
    "\"\"\"compute the pearson correlation between the prediction and the true value\"\"\"\n",
    "from scipy.stats import pearsonr\n",
    "print(pearsonr(comparison['cum_y_val_true'], comparison['cum_y_val_prediction']))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(x, comparison['cum_y_val_prediction'], color = 'red')\n",
    "plt.scatter(x, comparison['cum_y_val_true'], color = 'blue', alpha = 0.1)\n",
    "plt.ylim(-0.25, 0.25)\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ending score for metric train_r2 is: -1.1081e-01\n",
      "The ending score for metric val_cum_r2 is: -8.1735e-01\n",
      "The ending score for metric val_cum_pearson is: -4.0594e-02\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plot_performance(performance_ev, metrics_selected=['train_r2', 'val_cum_r2', 'val_cum_pearson'])\n",
    "plt.ylim(-1, 1)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
